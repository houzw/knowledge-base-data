[
{"name": "BandMath", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_BandMath.html", "label": "Band Math", "category": "Miscellaneous", "definition": "Outputs a monoband image which is the result of a mathematical operation on several multi-band images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_BandMath - il verySmallFSATSW_r . tif verySmallFSATSW_nir . tif verySmallFSATSW . tif - out apTvUtBandMathOutput . tif - exp 'cos( im1b1 ) > cos( im2b1 ) ? im3b1 : im3b2'", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the BandMath application BandMath = otbApplication . Registry . CreateApplication ( \"BandMath\" ) # The following lines set all the application parameters: BandMath . SetParameterStringList ( \"il\" , [ 'verySmallFSATSW_r.tif' , 'verySmallFSATSW_nir.tif' , 'verySmallFSATSW.tif' ]) BandMath . SetParameterString ( \"out\" , \"apTvUtBandMathOutput.tif\" ) BandMath . SetParameterString ( \"exp\" , \"'cos( im1b1 ) > cos( im2b1 ) ? im3b1 : im3b2'\" ) # The following line execute the application BandMath . ExecuteAndWriteOutput ()"], "command": "otbcli_BandMath", "parameters": [{"flag": "il", "parameterName": "Input image-list", "dataType": "Input image list", "explanation": ["Image-list of operands to the mathematical expression."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image which is the result of the mathematical expressions on input image-list operands."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "exp", "parameterName": "Expression", "dataType": "String", "explanation": ["The muParser mathematical expression to apply on input images."]}], "description": "\n   \n This application performs a mathematical operation on several multi-band images and outputs the result into a monoband image. The given expression is computed at each pixel position. Evaluation of the mathematical formula is done by the muParser libraries. \n The formula can be written using: \n \n \n numerical values ( 2.3, -5, 3.1e4, ...) \n variables containing pixel values (e.g. : \u2018im2b3\u2019 is the pixel value in 2nd image, 3rd band) \n binary operators: \n \u2018+\u2019 addition, \u2018-\u2018 subtraction, \u2018*\u2019 multiplication, \u2018/\u2019 division \n \u2018^\u2019 raise x to the power of y \n \u2018<\u2019 less than, \u2018>\u2019 greater than, \u2018<=\u2019 less or equal, \u2018>=\u2019 greater or equal \n \u2018==\u2019 equal, \u2018!=\u2019 not equal \n \u2018||\u2019 logical or, \u2018&&\u2019 logical and \n \n \n if-then-else operator: \u2018(condition ? value_true : value_false)\u2019 \n functions : exp(), log(), sin(), cos(), min(), max(), ... \n \n \n The full list of features and operators is available on the muParser website [1]. \n"},
{"name": "PixelValue", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_PixelValue.html", "label": "Pixel Value", "category": "Miscellaneous", "definition": "Get the value of a pixel.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_PixelValue - in QB_Toulouse_Ortho_XS . tif - coordx 50 - coordy 100 - cl Channel1", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the PixelValue application PixelValue = otbApplication . Registry . CreateApplication ( \"PixelValue\" ) # The following lines set all the application parameters: PixelValue . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) PixelValue . SetParameterFloat ( \"coordx\" , 50 ) PixelValue . SetParameterFloat ( \"coordy\" , 100 ) # The following line execute the application PixelValue . ExecuteAndWriteOutput ()"], "command": "otbcli_PixelValue", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "coordx", "parameterName": "X coordinate", "dataType": "Float", "explanation": []}, {"flag": "coordy", "parameterName": "Y coordinate", "dataType": "Float", "explanation": []}, {"flag": "mode", "parameterName": "Coordinate system used to designate the pixel", "dataType": "Choices", "availableChoices": [{"choice": "index", "description": ["This mode uses the given coordinates as index to locate the pixel."]}, {"choice": "physical", "description": ["This mode interprets the given coordinates in the image physical space."]}, {"choice": "epsg", "description": ["This mode interprets the given coordinates in the specified geographical coordinate system by the EPSG code."]}], "explanation": []}, {"flag": "mode.epsg.code", "parameterName": "EPSG code", "dataType": "Int", "explanation": ["This code is used to define a geographical coordinate system. If no system is specified, WGS84 (EPSG : 4326) is used by default."]}, {"flag": "cl", "parameterName": "Channels", "dataType": "List", "explanation": []}, {"flag": "value", "parameterName": "Pixel Value", "dataType": "String", "explanation": []}], "description": "\n   \n This application gives the value of a selected pixel. There are three ways to designate a pixel, with its index, its physical coordinate (in the physical space attached to the image), and with geographical coordinate system. Coordinates will be interpreted differently depending on which mode is chosen. \n"},
{"name": "ObtainUTMZoneFromGeoPoint", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ObtainUTMZoneFromGeoPoint.html", "label": "Obtain UTM Zone From Geo Point", "category": "Miscellaneous", "definition": "UTM zone determination from a geographic point.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ObtainUTMZoneFromGeoPoint - lat 10.0 - lon 124.0", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ObtainUTMZoneFromGeoPoint application ObtainUTMZoneFromGeoPoint = otbApplication . Registry . CreateApplication ( \"ObtainUTMZoneFromGeoPoint\" ) # The following lines set all the application parameters: ObtainUTMZoneFromGeoPoint . SetParameterFloat ( \"lat\" , 10.0 ) ObtainUTMZoneFromGeoPoint . SetParameterFloat ( \"lon\" , 124.0 ) # The following line execute the application ObtainUTMZoneFromGeoPoint . ExecuteAndWriteOutput ()"], "command": "otbcli_ObtainUTMZoneFromGeoPoint", "parameters": [{"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "lat", "parameterName": "Latitude", "dataType": "Float", "explanation": ["Latitude value of desired point."]}, {"flag": "lon", "parameterName": "Longitude", "dataType": "Float", "explanation": ["Longitude value of desired point."]}, {"flag": "utm", "parameterName": "UTMZone", "dataType": "Int", "explanation": ["UTM Zone."]}], "description": "\n   \n This application returns the UTM zone of an input geographic point. \n"},
{"name": "OSMDownloader", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_OSMDownloader.html", "label": "Open Street Map layers import", "category": "Miscellaneous", "definition": "Download vector data from OSM and store it to file", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_OSMDownloader - support qb_RoadExtract . tif - key highway - out apTvUtOSMDownloader . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the OSMDownloader application OSMDownloader = otbApplication . Registry . CreateApplication ( \"OSMDownloader\" ) # The following lines set all the application parameters: OSMDownloader . SetParameterString ( \"support\" , \"qb_RoadExtract.tif\" ) OSMDownloader . SetParameterString ( \"key\" , \"highway\" ) OSMDownloader . SetParameterString ( \"out\" , \"apTvUtOSMDownloader.shp\" ) # The following line execute the application OSMDownloader . ExecuteAndWriteOutput ()"], "command": "otbcli_OSMDownloader", "parameters": [{"flag": "out", "parameterName": "Output vector data", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "support", "parameterName": "Support image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "key", "parameterName": "OSM tag key", "dataType": "String", "explanation": []}, {"flag": "value", "parameterName": "OSM tag value", "dataType": "String", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "printclasses", "parameterName": "Displays available key/value classes", "dataType": "Boolean", "explanation": []}], "description": "\n   \n The application connects to Open Street Map server, downloads the data corresponding to the spatial extent of the support image, and filters the geometries based on OSM tags to produce a vector data file. \n This application can be used to download reference data to perform the training of a machine learning model (see for instance [1]). \n By default, the entire layer is downloaded. The application has a special mode to provide the list of available classes in the layers. The downloaded features are filtered by giving an OSM tag \u2018key\u2019. In addition, the user can also choose what \u2018value\u2019 this key should have. More information about the OSM project at [2]. \n"},
{"name": "HaralickTextureExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_HaralickTextureExtraction.html", "label": "Haralick Texture Extraction", "category": "Feature Extraction", "definition": "Computes Haralick textural features on the selected channel of the input image", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_HaralickTextureExtraction - in qb_RoadExtract . tif - channel 2 - parameters . xrad 3 - parameters . yrad 3 - texture simple - out HaralickTextures . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the HaralickTextureExtraction application HaralickTextureExtraction = otbApplication . Registry . CreateApplication ( \"HaralickTextureExtraction\" ) # The following lines set all the application parameters: HaralickTextureExtraction . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) HaralickTextureExtraction . SetParameterInt ( \"channel\" , 2 ) HaralickTextureExtraction . SetParameterInt ( \"parameters.xrad\" , 3 ) HaralickTextureExtraction . SetParameterInt ( \"parameters.yrad\" , 3 ) HaralickTextureExtraction . SetParameterString ( \"texture\" , \"simple\" ) HaralickTextureExtraction . SetParameterString ( \"out\" , \"HaralickTextures.tif\" ) # The following line execute the application HaralickTextureExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_HaralickTextureExtraction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "step", "parameterName": "Computation step", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "parameters.xrad", "parameterName": "X Radius", "dataType": "Int", "explanation": ["X Radius."]}, {"flag": "parameters.yrad", "parameterName": "Y Radius", "dataType": "Int", "explanation": ["Y Radius."]}, {"flag": "parameters.xoff", "parameterName": "X Offset", "dataType": "Int", "explanation": ["X Offset."]}, {"flag": "parameters.yoff", "parameterName": "Y Offset", "dataType": "Int", "explanation": ["Y Offset."]}, {"flag": "parameters.min", "parameterName": "Image Minimum", "dataType": "Float", "explanation": ["Image Minimum."]}, {"flag": "parameters.max", "parameterName": "Image Maximum", "dataType": "Float", "explanation": ["Image Maximum."]}, {"flag": "parameters.nbbin", "parameterName": "Histogram number of bin", "dataType": "Int", "explanation": ["Histogram number of bin."]}, {"flag": "texture", "parameterName": "Texture Set Selection", "dataType": "Choices", "availableChoices": [{"choice": "simple", "description": ["This group of parameters defines the 8 local Haralick texture feature output image. The image channels are: Energy, Entropy, Correlation, Inverse Difference Moment, Inertia, Cluster Shade, Cluster Prominence and Haralick Correlation."]}, {"choice": "advanced", "description": ["This group of parameters defines the 10 advanced texture feature output image. The image channels are: Mean, Variance, Dissimilarity, Sum Average, Sum Variance, Sum Entropy, Difference of Entropies, Difference of Variances, IC1 and IC2."]}, {"choice": "higher", "description": ["This group of parameters defines the 11 higher order texture feature output image. The image channels are: Short Run Emphasis, Long Run Emphasis, Grey-Level Nonuniformity, Run Length Nonuniformity, Run Percentage, Low Grey-Level Run Emphasis, High Grey-Level Run Emphasis, Short Run Low Grey-Level Emphasis, Short Run High Grey-Level Emphasis, Long Run Low Grey-Level Emphasis and Long Run High Grey-Level Emphasis."]}], "explanation": []}], "description": "\n   \n \n This application computes three sets of Haralick features [1][2]. \n \n simple:\u00a0a set of 8 local Haralick features: Energy (texture uniformity) , Entropy (measure of randomness of intensity image), Correlation (how correlated a pixel is to its neighborhood), Inverse Difference Moment (measures the texture homogeneity), Inertia (intensity contrast between a pixel and its neighborhood), Cluster Shade, Cluster Prominence, Haralick Correlation; \n advanced: a set of 10 advanced Haralick features : Mean, Variance (measures the texture heterogeneity), Dissimilarity, Sum Average, Sum Variance, Sum Entropy, Difference of Entropies, Difference of Variances, IC1, IC2; \n higher: a set of 11 higher Haralick features : Short Run Emphasis (measures the texture sharpness), Long Run Emphasis (measures the texture roughness), Grey-Level Nonuniformity, Run Length Nonuniformity, Run Percentage (measures the texture sharpness homogeneity), Low Grey-Level Run Emphasis, High Grey-Level Run Emphasis, Short Run Low Grey-Level Emphasis, Short Run High Grey-Level Emphasis, Long Run Low Grey-Level Emphasis and Long Run High Grey-Level Emphasis. \n \n \n \n"},
{"name": "GrayScaleMorphologicalOperation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_GrayScaleMorphologicalOperation.html", "label": "Grayscale Morphological Operation", "category": "Feature Extraction", "definition": "Performs morphological operations on a grayscale input image", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_GrayScaleMorphologicalOperation - in qb_RoadExtract . tif - out opened . tif - channel 1 - structype . ball . xradius 5 - structype . ball . yradius 5 - filter erode", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the GrayScaleMorphologicalOperation application GrayScaleMorphologicalOperation = otbApplication . Registry . CreateApplication ( \"GrayScaleMorphologicalOperation\" ) # The following lines set all the application parameters: GrayScaleMorphologicalOperation . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) GrayScaleMorphologicalOperation . SetParameterString ( \"out\" , \"opened.tif\" ) GrayScaleMorphologicalOperation . SetParameterInt ( \"channel\" , 1 ) GrayScaleMorphologicalOperation . SetParameterInt ( \"structype.ball.xradius\" , 5 ) GrayScaleMorphologicalOperation . SetParameterInt ( \"structype.ball.yradius\" , 5 ) GrayScaleMorphologicalOperation . SetParameterString ( \"filter\" , \"erode\" ) # The following line execute the application GrayScaleMorphologicalOperation . ExecuteAndWriteOutput ()"], "command": "otbcli_GrayScaleMorphologicalOperation", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Feature Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "structype", "parameterName": "Structuring Element Type", "dataType": "Choices", "availableChoices": [{"choice": "ball", "description": []}, {"choice": "cross", "description": []}], "explanation": []}, {"flag": "structype.ball.xradius", "parameterName": "The Structuring Element X Radius", "dataType": "Int", "explanation": ["The Structuring Element X Radius."]}, {"flag": "structype.ball.yradius", "parameterName": "The Structuring Element Y Radius", "dataType": "Int", "explanation": ["The Structuring Element Y Radius."]}, {"flag": "filter", "parameterName": "Morphological Operation", "dataType": "Choices", "availableChoices": [{"choice": "dilate", "description": []}, {"choice": "erode", "description": []}, {"choice": "opening", "description": []}, {"choice": "closing", "description": []}], "explanation": []}], "description": "\n   \n This application performs grayscale morphological operations on a mono band image \n"},
{"name": "ComputePolylineFeatureFromImage", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ComputePolylineFeatureFromImage.html", "label": "Compute Polyline Feature From Image", "category": "Feature Extraction", "definition": "This application computes the chosen descriptors for each studied polyline contained in the input VectorData.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ComputePolylineFeatureFromImage - in NDVI . TIF - vd roads_ground_truth . shp - expr \"(b1 > 0.4)\" - field NONDVI - out PolylineFeatureFromImage_LI_NONDVI_gt . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ComputePolylineFeatureFromImage application ComputePolylineFeatureFromImage = otbApplication . Registry . CreateApplication ( \"ComputePolylineFeatureFromImage\" ) # The following lines set all the application parameters: ComputePolylineFeatureFromImage . SetParameterString ( \"in\" , \"NDVI.TIF\" ) ComputePolylineFeatureFromImage . SetParameterString ( \"vd\" , \"roads_ground_truth.shp\" ) ComputePolylineFeatureFromImage . SetParameterString ( \"expr\" , \"(b1 > 0.4)\" ) ComputePolylineFeatureFromImage . SetParameterString ( \"field\" , \"NONDVI\" ) ComputePolylineFeatureFromImage . SetParameterString ( \"out\" , \"PolylineFeatureFromImage_LI_NONDVI_gt.shp\" ) # The following line execute the application ComputePolylineFeatureFromImage . ExecuteAndWriteOutput ()"], "command": "otbcli_ComputePolylineFeatureFromImage", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "vd", "parameterName": "Vector Data", "dataType": "Input vector data", "explanation": [], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "out", "parameterName": "Output Vector Data", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "expr", "parameterName": "Feature expression", "dataType": "String", "explanation": []}, {"flag": "field", "parameterName": "Feature name", "dataType": "String", "explanation": []}], "description": "\n   \n The first step in the classifier fusion based validation is to compute the chosen descriptors for each studied polyline. \n"},
{"name": "EdgeExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_EdgeExtraction.html", "label": "Edge Feature Extraction", "category": "Feature Extraction", "definition": "This application computes edge features on every pixel of the input image selected channel", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_EdgeExtraction - in qb_RoadExtract . tif - channel 1 - out Edges . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the EdgeExtraction application EdgeExtraction = otbApplication . Registry . CreateApplication ( \"EdgeExtraction\" ) # The following lines set all the application parameters: EdgeExtraction . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) EdgeExtraction . SetParameterInt ( \"channel\" , 1 ) EdgeExtraction . SetParameterString ( \"out\" , \"Edges.tif\" ) # The following line execute the application EdgeExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_EdgeExtraction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Feature Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "filter", "parameterName": "Edge feature", "dataType": "Choices", "availableChoices": [{"choice": "gradient", "description": ["This filter computes the gradient magnitude of the image at each pixel."]}, {"choice": "sobel", "description": ["This filter uses the Sobel operator to calculate the image gradient and then finds the magnitude of this gradient vector."]}, {"choice": "touzi", "description": ["This filter is more suited for radar images. It has a spatial parameter to avoid speckle noise perturbations. The larger the radius is, less sensible to the speckle noise the filter is, but micro edge will be missed."]}], "explanation": []}, {"flag": "filter.touzi.xradius", "parameterName": "The X radius of the neighborhood.", "dataType": "Int", "explanation": []}, {"flag": "filter.touzi.yradius", "parameterName": "The Y radius of the neighborhood.", "dataType": "Int", "explanation": []}], "description": "\n   \n This application computes edge features on a selected channel of the input.It uses different filter such as gradient, Sobel and Touzi \n"},
{"name": "BinaryMorphologicalOperation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_BinaryMorphologicalOperation.html", "label": "Binary Morphological Operation", "category": "Feature Extraction", "definition": "Performs morphological operations on an input image channel", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_BinaryMorphologicalOperation - in qb_RoadExtract . tif - out opened . tif - channel 1 - structype . ball . xradius 5 - structype . ball . yradius 5 - filter erode", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the BinaryMorphologicalOperation application BinaryMorphologicalOperation = otbApplication . Registry . CreateApplication ( \"BinaryMorphologicalOperation\" ) # The following lines set all the application parameters: BinaryMorphologicalOperation . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) BinaryMorphologicalOperation . SetParameterString ( \"out\" , \"opened.tif\" ) BinaryMorphologicalOperation . SetParameterInt ( \"channel\" , 1 ) BinaryMorphologicalOperation . SetParameterInt ( \"structype.ball.xradius\" , 5 ) BinaryMorphologicalOperation . SetParameterInt ( \"structype.ball.yradius\" , 5 ) BinaryMorphologicalOperation . SetParameterString ( \"filter\" , \"erode\" ) # The following line execute the application BinaryMorphologicalOperation . ExecuteAndWriteOutput ()"], "command": "otbcli_BinaryMorphologicalOperation", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "structype", "parameterName": "Type of structuring element", "dataType": "Choices", "availableChoices": [{"choice": "ball", "description": []}, {"choice": "cross", "description": []}], "explanation": []}, {"flag": "structype.ball.xradius", "parameterName": "Structuring element X radius", "dataType": "Int", "explanation": ["The structuring element radius along the X axis."]}, {"flag": "structype.ball.yradius", "parameterName": "Structuring element Y radiuss", "dataType": "Int", "explanation": ["The structuring element radius along the y axis."]}, {"flag": "filter", "parameterName": "Morphological Operation", "dataType": "Choices", "availableChoices": [{"choice": "dilate", "description": []}, {"choice": "erode", "description": []}, {"choice": "opening", "description": []}, {"choice": "closing", "description": []}], "explanation": []}, {"flag": "filter.dilate.foreval", "parameterName": "Foreground value", "dataType": "Float", "explanation": ["Set the foreground value, default is 1.0."]}, {"flag": "filter.dilate.backval", "parameterName": "Background value", "dataType": "Float", "explanation": ["Set the background value, default is 0.0."]}, {"flag": "filter.erode.foreval", "parameterName": "Foreground value", "dataType": "Float", "explanation": ["Set the foreground value, default is 1.0."]}, {"flag": "filter.erode.backval", "parameterName": "Background value", "dataType": "Float", "explanation": ["Set the background value, default is 0.0."]}, {"flag": "filter.opening.foreval", "parameterName": "Foreground value", "dataType": "Float", "explanation": ["Set the foreground value, default is 1.0."]}, {"flag": "filter.opening.backval", "parameterName": "Background value", "dataType": "Float", "explanation": ["Set the background value, default is 0.0."]}, {"flag": "filter.closing.foreval", "parameterName": "Foreground value", "dataType": "Float", "explanation": ["Set the foreground value, default is 1.0."]}], "description": "\n   \n This application performs binary morphological operations on a mono band image or a channel of the input. \n"},
{"name": "VertexComponentAnalysis", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VertexComponentAnalysis.html", "label": "Vertex Component Analysis", "category": "Miscellaneous", "definition": "Given a set of mixed spectral vectors, estimatereference substances also known as endmembers using the VertexComponent Analysis algorithm.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VertexComponentAnalysis - in cupriteSubHsi . tif - ne 5 - outendm VertexComponentAnalysis . tif double", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VertexComponentAnalysis application VertexComponentAnalysis = otbApplication . Registry . CreateApplication ( \"VertexComponentAnalysis\" ) # The following lines set all the application parameters: VertexComponentAnalysis . SetParameterString ( \"in\" , \"cupriteSubHsi.tif\" ) VertexComponentAnalysis . SetParameterInt ( \"ne\" , 5 ) VertexComponentAnalysis . SetParameterString ( \"outendm\" , \"VertexComponentAnalysis.tif\" ) VertexComponentAnalysis . SetParameterOutputImagePixelType ( \"outendm\" , 7 ) # The following line execute the application VertexComponentAnalysis . ExecuteAndWriteOutput ()"], "command": "otbcli_VertexComponentAnalysis", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["Input hyperspectral data cube."], "isInputFile": true}, {"flag": "outendm", "parameterName": "Output Endmembers", "dataType": "Output image", "explanation": ["Endmembers, stored in aone-line multi-spectral image.Each pixel corresponds to oneendmembers and each band values corresponds to the spectralsignature of the corresponding endmember."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ne", "parameterName": "Number of endmembers", "dataType": "Int", "explanation": ["The number of endmembers to extract from the hyperspectral image."]}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": ["Set specific seed. with integer value."]}], "description": "\n   \n Apply the Vertex Component Analysis [1] toan hyperspectral image to extract endmembers. Given a set of mixedspectral vectors (multispectral or hyperspectral), the applicationestimates the spectral signature of reference substances also knownas endmembers. \n"},
{"name": "DSFuzzyModelEstimation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DSFuzzyModelEstimation.html", "label": "Fuzzy Model estimation", "category": "Feature Extraction", "definition": "Estimate feature fuzzy model parameters using 2 vector data (ground truth samples and wrong samples).", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DSFuzzyModelEstimation - psin cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt . shp - nsin cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_wr . shp - belsup \"ROADSA\" - plasup \"NONDVI\" \"ROADSA\" \"NOBUIL\" - initmod Dempster - Shafer / DSFuzzyModel_Init . xml - maxnbit 4 - optobs true - out DSFuzzyModelEstimation . xml", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DSFuzzyModelEstimation application DSFuzzyModelEstimation = otbApplication . Registry . CreateApplication ( \"DSFuzzyModelEstimation\" ) # The following lines set all the application parameters: DSFuzzyModelEstimation . SetParameterString ( \"psin\" , \"cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt.shp\" ) DSFuzzyModelEstimation . SetParameterString ( \"nsin\" , \"cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_wr.shp\" ) DSFuzzyModelEstimation . SetParameterStringList ( \"belsup\" , [ '\"ROADSA\"' ]) DSFuzzyModelEstimation . SetParameterStringList ( \"plasup\" , [ '\"NONDVI\"' , '\"ROADSA\"' , '\"NOBUIL\"' ]) DSFuzzyModelEstimation . SetParameterString ( \"initmod\" , \"Dempster-Shafer/DSFuzzyModel_Init.xml\" ) DSFuzzyModelEstimation . SetParameterInt ( \"maxnbit\" , 4 ) DSFuzzyModelEstimation . SetParameterString ( \"optobs\" , \"true\" ) DSFuzzyModelEstimation . SetParameterString ( \"out\" , \"DSFuzzyModelEstimation.xml\" ) # The following line execute the application DSFuzzyModelEstimation . ExecuteAndWriteOutput ()"], "command": "otbcli_DSFuzzyModelEstimation", "parameters": [{"flag": "psin", "parameterName": "Input Positive Vector Data", "dataType": "Input vector data", "explanation": ["Ground truth vector data for positive samples."], "isInputFile": true}, {"flag": "nsin", "parameterName": "Input Negative Vector Data", "dataType": "Input vector data", "explanation": ["Ground truth vector data for negative samples."], "isInputFile": true}, {"flag": "initmod", "parameterName": "initialization model", "dataType": "Input File name", "explanation": ["Initialization model (xml file) to be used. If the xml initialization model is set, the descriptor list is not used (specified using the option -desclist)."], "isInputFile": true}, {"flag": "out", "parameterName": "Output filename", "dataType": "Output File name", "explanation": ["Output model file name (xml file) contains the optimal model to perform information fusion."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "belsup", "parameterName": "Belief Support", "dataType": "String list", "explanation": ["Dempster Shafer study hypothesis to compute belief."]}, {"flag": "plasup", "parameterName": "Plausibility Support", "dataType": "String list", "explanation": ["Dempster Shafer study hypothesis to compute plausibility."]}, {"flag": "cri", "parameterName": "Criterion", "dataType": "String", "explanation": ["Dempster Shafer criterion (by default (belief+plausibility)/2)."]}, {"flag": "wgt", "parameterName": "Weighting", "dataType": "Float", "explanation": ["Coefficient between 0 and 1 to promote undetection or false detections (default 0.5)."]}, {"flag": "desclist", "parameterName": "Descriptor list", "dataType": "String list", "explanation": ["List of the descriptors to be used in the model (must be specified to perform an automatic initialization)."]}, {"flag": "maxnbit", "parameterName": "Maximum number of iterations", "dataType": "Int", "explanation": ["Maximum number of optimizer iteration (default 200)."]}, {"flag": "optobs", "parameterName": "Optimizer Observer", "dataType": "Boolean", "explanation": ["Activate the optimizer observer."]}], "description": "\n   \n Estimate feature fuzzy model parameters using 2 vector data (ground truth samples and wrong samples). \n"},
{"name": "KmzExport", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_KmzExport.html", "label": "Image to KMZ Export", "category": "Miscellaneous", "definition": "Export the input image in a KMZ product.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_KmzExport - in qb_RoadExtract2 . tif - out otbKmzExport . kmz - logo otb_big . png", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the KmzExport application KmzExport = otbApplication . Registry . CreateApplication ( \"KmzExport\" ) # The following lines set all the application parameters: KmzExport . SetParameterString ( \"in\" , \"qb_RoadExtract2.tif\" ) KmzExport . SetParameterString ( \"out\" , \"otbKmzExport.kmz\" ) KmzExport . SetParameterString ( \"logo\" , \"otb_big.png\" ) # The following line execute the application KmzExport . ExecuteAndWriteOutput ()"], "command": "otbcli_KmzExport", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output .kmz product", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "logo", "parameterName": "Image logo", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "legend", "parameterName": "Image legend", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "tilesize", "parameterName": "Tile Size", "dataType": "Int", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n This application exports the input image in a kmz product that can be display in the Google Earth software. The user can set the size of the product size, a logo and a legend to the product. Furthemore, to obtain a product that fits the relief, a DEM can be used. \n"},
{"name": "HyperspectralUnmixing", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_HyperspectralUnmixing.html", "label": "Hyperspectral data unmixing", "category": "Miscellaneous", "definition": "Estimate abundance maps from an hyperspectral image and a set of endmembers.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_HyperspectralUnmixing - in cupriteSubHsi . tif - ie cupriteEndmembers . tif - out HyperspectralUnmixing . tif double - ua ucls", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the HyperspectralUnmixing application HyperspectralUnmixing = otbApplication . Registry . CreateApplication ( \"HyperspectralUnmixing\" ) # The following lines set all the application parameters: HyperspectralUnmixing . SetParameterString ( \"in\" , \"cupriteSubHsi.tif\" ) HyperspectralUnmixing . SetParameterString ( \"ie\" , \"cupriteEndmembers.tif\" ) HyperspectralUnmixing . SetParameterString ( \"out\" , \"HyperspectralUnmixing.tif\" ) HyperspectralUnmixing . SetParameterOutputImagePixelType ( \"out\" , 7 ) HyperspectralUnmixing . SetParameterString ( \"ua\" , \"ucls\" ) # The following line execute the application HyperspectralUnmixing . ExecuteAndWriteOutput ()"], "command": "otbcli_HyperspectralUnmixing", "parameters": [{"flag": "in", "parameterName": "Input Image Filename", "dataType": "Input image", "explanation": ["The hyperspectral data cube input."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output abundance map. The abundance fraction are stored in a multispectral image where band N corresponds to the fraction of endmembers N in each pixel."], "isOutputFile": true}, {"flag": "ie", "parameterName": "Input endmembers", "dataType": "Input image", "explanation": ["The endmembers (estimated pure pixels) to use for unmixing. Must be stored as a multispectral image, where each pixel is interpreted as an endmember."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ua", "parameterName": "Unmixing algorithm", "dataType": "Choices", "availableChoices": [{"choice": "ucls", "description": ["Unconstrained Least Square."]}, {"choice": "ncls", "description": ["Non-negative constrained Least Square."]}, {"choice": "isra", "description": ["Image Space Reconstruction Algorithm."]}, {"choice": "mdmdnmf", "description": ["Minimum Dispersion Constrained Non Negative Matrix Factorization."]}], "explanation": ["The algorithm to use for unmixing. Available choices are:"]}], "description": "\n   \n The application applies a linear unmixing algorithmto an hyperspectral data cube. This method supposes that the mixture betweenaterials in the scene is macroscopic and simulates a linear mixing model ofspectra. \n The Linear Mixing Model (LMM) acknowledges that reflectancespectrum associated with each pixel is a linear combination of purematerials in the recovery area, commonly known as endmembers. Endmembers canbe estimated using the VertexComponentAnalysis application. \n \n The application allows estimating the abundance maps with several algorithms : \n \n Unconstrained Least Square (ucls) \n Image Space Reconstruction Algorithm (isra) \n Non-negative constrained \n Least Square (ncls) \n Minimum Dispersion Constrained Non Negative Matrix Factorization (MDMDNMF). \n \n \n \n"},
{"name": "MultivariateAlterationDetector", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MultivariateAlterationDetector.html", "label": "Multivariate Alteration Detector", "category": "Change Detection", "definition": "Change detection by Multivariate Alteration Detector (MAD) algorithm", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MultivariateAlterationDetector - in1 Spot5 - Gloucester - before . tif - in2 Spot5 - Gloucester - after . tif - out detectedChangeImage . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MultivariateAlterationDetector application MultivariateAlterationDetector = otbApplication . Registry . CreateApplication ( \"MultivariateAlterationDetector\" ) # The following lines set all the application parameters: MultivariateAlterationDetector . SetParameterString ( \"in1\" , \"Spot5-Gloucester-before.tif\" ) MultivariateAlterationDetector . SetParameterString ( \"in2\" , \"Spot5-Gloucester-after.tif\" ) MultivariateAlterationDetector . SetParameterString ( \"out\" , \"detectedChangeImage.tif\" ) # The following line execute the application MultivariateAlterationDetector . ExecuteAndWriteOutput ()"], "command": "otbcli_MultivariateAlterationDetector", "parameters": [{"flag": "in1", "parameterName": "Input Image 1", "dataType": "Input image", "explanation": ["Multiband image of the scene before perturbations."], "isInputFile": true}, {"flag": "in2", "parameterName": "Input Image 2", "dataType": "Input image", "explanation": ["Mutliband image of the scene after perturbations."], "isInputFile": true}, {"flag": "out", "parameterName": "Change Map", "dataType": "Output image", "explanation": ["Multiband image containing change maps. Each map will be in the range [-1,1], so a floating point output type is advised."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application performs change detection between two multispectral images using the Multivariate Alteration Detector (MAD) [1] algorithm. \n \n The MAD algorithm produces a set of N change maps (where N is the maximum number of bands in first and second input images), with the following properties: \n \n Change maps are differences of a pair of linear combinations of  bands from image 1 and bands from image 2 chosen to maximize the  correlation, \n Each change map is orthogonal to the others. \n \n \n \n This is a statistical method which can handle different modalities and even different bands and number of bands between images. \n The application will output all change maps into a single multiband image. If numbers of bands in image 1 and 2 are equal, then change maps are sorted by increasing correlation. If number of bands is different, the change maps are sorted by decreasing correlation. \n The application will also print the following information:\n- Mean1 and Mean2 which are the mean values of bands for both input images,\n- V1 and V2 which are the two linear transform that are applied to input image 1 and input image 2 to build the change map,\n- Rho, the vector of correlation associated to each change map. \n The OTB filter used in this application has been implemented from the Matlab code kindly made available by the authors here [2]. Both cases (same and different number of bands) have been validated by comparing the output image to the output produced by the Matlab  code, and the reference images for testing have been generated from  the Matlab code using Octave. \n"},
{"name": "CompareImages", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_CompareImages.html", "label": "Images comparison", "category": "Miscellaneous", "definition": "Estimator between 2 images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_CompareImages - ref . in GomaApres . png - ref . channel 1 - meas . in GomaAvant . png - meas . channel 2 - roi . startx 20 - roi . starty 30 - roi . sizex 150 - roi . sizey 200", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the CompareImages application CompareImages = otbApplication . Registry . CreateApplication ( \"CompareImages\" ) # The following lines set all the application parameters: CompareImages . SetParameterString ( \"ref.in\" , \"GomaApres.png\" ) CompareImages . SetParameterInt ( \"ref.channel\" , 1 ) CompareImages . SetParameterString ( \"meas.in\" , \"GomaAvant.png\" ) CompareImages . SetParameterInt ( \"meas.channel\" , 2 ) CompareImages . SetParameterInt ( \"roi.startx\" , 20 ) CompareImages . SetParameterInt ( \"roi.starty\" , 30 ) CompareImages . SetParameterInt ( \"roi.sizex\" , 150 ) CompareImages . SetParameterInt ( \"roi.sizey\" , 200 ) # The following line execute the application CompareImages . ExecuteAndWriteOutput ()"], "command": "otbcli_CompareImages", "parameters": [{"flag": "ref.in", "parameterName": "Reference image", "dataType": "Input image", "explanation": ["Image used as reference in the comparison."], "isInputFile": true}, {"flag": "meas.in", "parameterName": "Measured image", "dataType": "Input image", "explanation": ["Image used as measured in the comparison."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ref.channel", "parameterName": "Reference image channel", "dataType": "Int", "explanation": ["Used channel for the reference image."]}, {"flag": "meas.channel", "parameterName": "Measured image channel", "dataType": "Int", "explanation": ["Used channel for the measured image."]}, {"flag": "roi.startx", "parameterName": "Start X", "dataType": "Int", "explanation": ["ROI start x position."]}, {"flag": "roi.starty", "parameterName": "Start Y", "dataType": "Int", "explanation": ["ROI start y position."]}, {"flag": "roi.sizex", "parameterName": "Size X", "dataType": "Int", "explanation": ["Size along x in pixels."]}, {"flag": "roi.sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": ["Size along y in pixels."]}, {"flag": "mse", "parameterName": "MSE", "dataType": "Float", "explanation": []}, {"flag": "mae", "parameterName": "MAE", "dataType": "Float", "explanation": []}, {"flag": "psnr", "parameterName": "PSNR", "dataType": "Float", "explanation": []}, {"flag": "count", "parameterName": "count", "dataType": "Float", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application computes MSE (Mean Squared Error), MAE (Mean Absolute Error) and PSNR (Peak Signal to Noise Ratio) between the channel of two images (reference and measurement). The user has to set the used channel and can specify a ROI. \n"},
{"name": "BandMathX", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_BandMathX.html", "label": "Band Math X", "category": "Miscellaneous", "definition": "This application performs mathematical operations on several multiband images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_BandMathX - il verySmallFSATSW_r . tif verySmallFSATSW_nir . tif verySmallFSATSW . tif - out apTvUtBandMathOutput . tif - exp 'cos( im1b1 ) + im2b1 * im3b1 - im3b2 + ndvi( im3b3, im3b4 )'", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the BandMathX application BandMathX = otbApplication . Registry . CreateApplication ( \"BandMathX\" ) # The following lines set all the application parameters: BandMathX . SetParameterStringList ( \"il\" , [ 'verySmallFSATSW_r.tif' , 'verySmallFSATSW_nir.tif' , 'verySmallFSATSW.tif' ]) BandMathX . SetParameterString ( \"out\" , \"apTvUtBandMathOutput.tif\" ) BandMathX . SetParameterString ( \"exp\" , \"'cos( im1b1 ) + im2b1 * im3b1 - im3b2 + ndvi( im3b3, im3b4 )'\" ) # The following line execute the application BandMathX . ExecuteAndWriteOutput ()"], "command": "otbcli_BandMathX", "parameters": [{"flag": "il", "parameterName": "Input image-list", "dataType": "Input image list", "explanation": ["Image-list to perform computation on."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image."], "isOutputFile": true}, {"flag": "incontext", "parameterName": "Import context", "dataType": "Input File name", "explanation": ["A txt file containing user\u2019s constants and expressions."], "isInputFile": true}, {"flag": "outcontext", "parameterName": "Export context", "dataType": "Output File name", "explanation": ["A txt file where to save user\u2019s constants and expressions."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "exp", "parameterName": "Expressions", "dataType": "String", "explanation": ["Mathematical expression to apply."]}], "description": "\n   \n This application performs a mathematical operation on several multi-band images and outputs the result into an image (multi- or mono-band, as opposed to the BandMath OTB-application). The mathematical formula is done by the muParserX libraries. \n The list of features and the syntax of muParserX is available at [1]. \n As opposed to muParser (and thus the BandMath OTB-application [2]), muParserX supports vector expressions which allows outputting multi-band images. \n Hereafter is a brief reference of the muParserX syntax \n"},
{"name": "SARCalibration", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SARCalibration.html", "label": "SAR Radiometric calibration", "category": "Calibration", "definition": "Perform radiometric calibration of SAR images. Following sensors are supported: TerraSAR-X, Sentinel1 and Radarsat-2.Both Single Look Complex(SLC) and detected products are supported as input.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SARCalibration - in RSAT_imagery_HH . tif - out SarRadiometricCalibration . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SARCalibration application SARCalibration = otbApplication . Registry . CreateApplication ( \"SARCalibration\" ) # The following lines set all the application parameters: SARCalibration . SetParameterString ( \"in\" , \"RSAT_imagery_HH.tif\" ) SARCalibration . SetParameterString ( \"out\" , \"SarRadiometricCalibration.tif\" ) # The following line execute the application SARCalibration . ExecuteAndWriteOutput ()"], "command": "otbcli_SARCalibration", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["Input complex image."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output calibrated image. This image contains the backscatter (sigmaNought) of the input image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "noise", "parameterName": "Disable Noise", "dataType": "Boolean", "explanation": ["Flag to disable noise. For 5.2.0 release, the noise values are only read by TerraSARX product."]}, {"flag": "lut", "parameterName": "Lookup table sigma /gamma/ beta/ DN.", "dataType": "Choices", "availableChoices": [{"choice": "sigma", "description": ["Use Sigma nought lookup value from product metadata."]}, {"choice": "gamma", "description": ["Use Gamma nought lookup value from product metadata."]}, {"choice": "beta", "description": ["Use Beta nought lookup value from product metadata."]}, {"choice": "dn", "description": ["Use DN value lookup value from product metadata."]}], "explanation": ["Lookup table values are not available with all SAR products. Products that provide lookup table with metadata are: Sentinel1, Radarsat2. Available choices are:"]}], "description": "\n   \n The objective of SAR calibration is to provide imagery in which the pixel values can be directly related to the radar backscatter of the scene. This application allows computing Sigma Naught (Radiometric Calibration) for TerraSAR-X, Sentinel1 L1 and Radarsat-2 sensors. Metadata are automatically retrieved from image products.The application supports complex and non-complex images (SLC or detected products). \n"},
{"name": "OpticalCalibration", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_OpticalCalibration.html", "label": "Optical calibration", "category": "Calibration", "definition": "Perform optical calibration TOA/TOC (Top Of Atmosphere/Top Of Canopy). Supported sensors: QuickBird, Ikonos, WorldView2, Formosat, Spot5, Pleiades, Spot6, Spot7. For other sensors the application also allows providing calibration parameters manually.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_OpticalCalibration - in QB_1_ortho . tif - level toa - out OpticalCalibration . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the OpticalCalibration application OpticalCalibration = otbApplication . Registry . CreateApplication ( \"OpticalCalibration\" ) # The following lines set all the application parameters: OpticalCalibration . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) OpticalCalibration . SetParameterString ( \"level\" , \"toa\" ) OpticalCalibration . SetParameterString ( \"out\" , \"OpticalCalibration.tif\" ) # The following line execute the application OpticalCalibration . ExecuteAndWriteOutput ()"], "command": "otbcli_OpticalCalibration", "parameters": [{"flag": "in", "parameterName": "Input", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "acqui.gainbias", "parameterName": "Gains or biases", "dataType": "Input File name", "explanation": ["Gains or biases."], "isInputFile": true}, {"flag": "acqui.solarilluminations", "parameterName": "Solar illuminations", "dataType": "Input File name", "explanation": ["Solar illuminations (one value per band)."], "isInputFile": true}, {"flag": "atmo.aeronet", "parameterName": "Aeronet File", "dataType": "Input File name", "explanation": ["Aeronet file containing atmospheric parameters."], "isInputFile": true}, {"flag": "atmo.rsr", "parameterName": "Relative Spectral Response File", "dataType": "Input File name", "explanation": ["Sensor relative spectral response file By default the application gets this information in the metadata."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "level", "parameterName": "Calibration Level", "dataType": "Choices", "availableChoices": [{"choice": "toa", "description": []}, {"choice": "toatoim", "description": []}, {"choice": "toc", "description": []}], "explanation": []}, {"flag": "milli", "parameterName": "Convert to milli reflectance", "dataType": "Boolean", "explanation": []}, {"flag": "clamp", "parameterName": "Clamp of reflectivity values between [0, 1]", "dataType": "Boolean", "explanation": []}, {"flag": "acqui.minute", "parameterName": "Minute", "dataType": "Int", "explanation": ["Minute (0-59)."]}, {"flag": "acqui.hour", "parameterName": "Hour", "dataType": "Int", "explanation": ["Hour (0-23)."]}, {"flag": "acqui.day", "parameterName": "Day", "dataType": "Int", "explanation": ["Day (1-31)."]}, {"flag": "acqui.month", "parameterName": "Month", "dataType": "Int", "explanation": ["Month (1-12)."]}, {"flag": "acqui.year", "parameterName": "Year", "dataType": "Int", "explanation": ["Year."]}, {"flag": "acqui.fluxnormcoeff", "parameterName": "Flux Normalization", "dataType": "Float", "explanation": ["Flux Normalization Coefficient."]}, {"flag": "acqui.sun.elev", "parameterName": "Sun elevation angle (deg)", "dataType": "Float", "explanation": ["Sun elevation angle (in degrees)."]}, {"flag": "acqui.sun.azim", "parameterName": "Sun azimuth angle (deg)", "dataType": "Float", "explanation": ["Sun azimuth angle (in degrees)."]}, {"flag": "acqui.view.elev", "parameterName": "Viewing elevation angle (deg)", "dataType": "Float", "explanation": ["Viewing elevation angle (in degrees)."]}, {"flag": "acqui.view.azim", "parameterName": "Viewing azimuth angle (deg)", "dataType": "Float", "explanation": ["Viewing azimuth angle (in degrees)."]}, {"flag": "atmo.aerosol", "parameterName": "Aerosol Model", "dataType": "Choices", "availableChoices": [{"choice": "noaersol", "description": []}, {"choice": "continental", "description": []}, {"choice": "maritime", "description": []}, {"choice": "urban", "description": []}, {"choice": "desertic", "description": []}], "explanation": [" Available choices are:"]}, {"flag": "atmo.oz", "parameterName": "Ozone Amount", "dataType": "Float", "explanation": ["Ozone Amount."]}, {"flag": "atmo.wa", "parameterName": "Water Vapor Amount", "dataType": "Float", "explanation": ["Water Vapor Amount (in saturation fraction of water)."]}, {"flag": "atmo.pressure", "parameterName": "Atmospheric Pressure", "dataType": "Float", "explanation": ["Atmospheric Pressure (in hPa)."]}, {"flag": "atmo.opt", "parameterName": "Aerosol Optical Thickness", "dataType": "Float", "explanation": ["Aerosol Optical Thickness."]}, {"flag": "atmo.radius", "parameterName": "Window radius (adjacency effects)", "dataType": "Int", "explanation": ["Window radius for adjacency effects correctionsSetting this parameters will enable the correction ofadjacency effects."]}, {"flag": "atmo.pixsize", "parameterName": "Pixel size (in km)", "dataType": "Float", "explanation": ["Pixel size (in km )used tocompute adjacency effects, it doesn\u2019t have tomatch the image spacing."]}], "description": "\n   \n The application allows converting pixel values from DN (for Digital Numbers) to reflectance. Calibrated values are called surface reflectivity and its values lie in the range [0, 1].\nThe first level is called Top Of Atmosphere (TOA) reflectivity. It takes into account the sensor gain, sensor spectral response and the solar illuminations.\nThe second level is called Top Of Canopy (TOC) reflectivity. In addition to sensor gain and solar illuminations, it takes into account the optical thickness of the atmosphere, the atmospheric pressure, the water vapor amount, the ozone amount, as well as the composition and amount of aerosol gasses.\nIt is also possible to indicate an AERONET file which contains atmospheric parameters (version 1 and version 2 of Aeronet file are supported. Note that computing TOC reflectivity will internally compute first TOA and then TOC reflectance. \n \n If the sensor is not supported by the metadata interface factory of OTB, users still have the possibility to give the needed parameters to the application.\nFor TOA conversion, these parameters are :\n- day and month of acquisition, or flux normalization coefficient;\n- sun elevation angle;\n- gains and biases, one pair of values for each band (passed by a file);\n- solar illuminations, one value for each band (passed by a file). \n For the conversion from DN (for Digital Numbers) to spectral radiance (or \u2018TOA radiance\u2019) L, the following formula is used : \n \n L(b) = DN(b)/gain(b)+bias(b)    (in W/m2/steradians/micrometers)        with b being a band ID. \n \n These values are provided by the user thanks to a simple txt file with two lines, one for the gains and one for the biases.\nEach value must be separated with colons (:), with eventual spaces. Blank lines are not allowed. If a line begins with the \u2018#\u2019 symbol, then it is considered as comments.\nNote that sometimes, the values provided by certain metadata files assume the formula L(b) = gain(b)*DC(b)+bias(b).\nIn this case, be sure to provide the inverse gain values so that the application can correctly interpret them. \n In order to convert TOA radiance to TOA reflectance, the following formula is used : \n \n R(b) = (pi*L(b)*d*d) / (ESUN(b)*cos(\u03b8)) (no dimension)  where : \n \n \n L(b) is the spectral radiance for band b \n pi is the famous mathematical constant (3.14159...) \n d is the earth-sun distance (in astronomical units) and depends on the acquisition\u2019s day and month \n ESUN(b) is the mean TOA solar irradiance (or solar illumination) in W/m2/micrometers \n \u03b8 is the solar zenith angle in degrees. \n \n Note that the application asks for the solar elevation angle, and will perform the conversion to the zenith angle itself (zenith_angle = 90 - elevation_angle , units : degrees).\nNote also that ESUN(b) not only depends on the band b, but also on the spectral sensitivity of the sensor in this particular band. In other words, the influence of spectral sensitivities is included within the ESUN different values.\nThese values are provided by the user thanks to a txt file following the same convention as before.\nInstead of providing the date of acquisition, the user can also provide a flux normalization coefficient \u2018fn\u2019. The formula used instead will be the following : \n \n R(b) = (pi*L(b)) / (ESUN(b)*fn*fn*cos(\u03b8)) \n \n Whatever the formula used (2 or 3), the user should pay attention to the interpretation of the parameters he will provide to the application, by taking into account the original formula that the metadata files assumes. \n Below, we give two examples of txt files containing information about gains/biases and solar illuminations : \n \n gainbias.txt : \n \n # Gain values for each band. Each value must be separated with colons (:), with eventual spaces. Blank lines not allowed.\n10.4416 : 9.529 : 8.5175 : 14.0063\n# Bias values for each band.\n0.0 : 0.0 : 0.0 : 0.0 \n \n solarillumination.txt : \n \n # Solar illumination values in watt/m2/micron (\u2018micron\u2019 means actually \u2018for each band\u2019).\n# Each value must be separated with colons (:), with eventual spaces. Blank lines not allowed.\n1540.494123 : 1826.087443 : 1982.671954 : 1094.747446 \n Finally, the \u2018Logs\u2019 tab provides useful messages that can help the user in knowing the process different status. \n"},
{"name": "GridBasedImageResampling", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_GridBasedImageResampling.html", "label": "Grid Based Image Resampling", "category": "Geometry", "definition": "Resamples an image according to a resampling grid", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_GridBasedImageResampling - io . in ROI_IKO_PAN_LesHalles_sub . tif - io . out ROI_IKO_PAN_LesHalles_sub_resampled . tif uint8 - grid . in ROI_IKO_PAN_LesHalles_sub_deformation_field . tif - out . sizex 256 - out . sizey 256 - grid . type def", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the GridBasedImageResampling application GridBasedImageResampling = otbApplication . Registry . CreateApplication ( \"GridBasedImageResampling\" ) # The following lines set all the application parameters: GridBasedImageResampling . SetParameterString ( \"io.in\" , \"ROI_IKO_PAN_LesHalles_sub.tif\" ) GridBasedImageResampling . SetParameterString ( \"io.out\" , \"ROI_IKO_PAN_LesHalles_sub_resampled.tif\" ) GridBasedImageResampling . SetParameterOutputImagePixelType ( \"io.out\" , 1 ) GridBasedImageResampling . SetParameterString ( \"grid.in\" , \"ROI_IKO_PAN_LesHalles_sub_deformation_field.tif\" ) GridBasedImageResampling . SetParameterInt ( \"out.sizex\" , 256 ) GridBasedImageResampling . SetParameterInt ( \"out.sizey\" , 256 ) GridBasedImageResampling . SetParameterString ( \"grid.type\" , \"def\" ) # The following line execute the application GridBasedImageResampling . ExecuteAndWriteOutput ()"], "command": "otbcli_GridBasedImageResampling", "parameters": [{"flag": "io.in", "parameterName": "Input image", "dataType": "Input image", "explanation": ["The input image to resample."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The resampled output image."], "isOutputFile": true}, {"flag": "grid.in", "parameterName": "Input resampling grid", "dataType": "Input image", "explanation": ["The resampling grid."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "grid.type", "parameterName": "Grid Type", "dataType": "Choices", "availableChoices": [{"choice": "def", "description": ["A deformation grid contains at each grid position the offset to apply to this position in order to get to the corresponding point in the input image to resample."]}, {"choice": "loc", "description": ["A localisation grid contains at each grid position the corresponding position in the input image to resample."]}], "explanation": ["allows one to choose between two grid types. Available choices are:"]}, {"flag": "out.ulx", "parameterName": "Upper Left X", "dataType": "Float", "explanation": ["X Coordinate of the upper-left pixel of the output resampled image."]}, {"flag": "out.uly", "parameterName": "Upper Left Y", "dataType": "Float", "explanation": ["Y Coordinate of the upper-left pixel of the output resampled image."]}, {"flag": "out.sizex", "parameterName": "Size X", "dataType": "Int", "explanation": ["Size of the output resampled image along X (in pixels)."]}, {"flag": "out.sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": ["Size of the output resampled image along Y (in pixels)."]}, {"flag": "out.spacingx", "parameterName": "Pixel Size X", "dataType": "Float", "explanation": ["Size of each pixel along X axis."]}, {"flag": "out.spacingy", "parameterName": "Pixel Size Y", "dataType": "Float", "explanation": ["Size of each pixel along Y axis."]}, {"flag": "out.default", "parameterName": "Default value", "dataType": "Float", "explanation": ["The default value to give to pixel that falls outside of the input image."]}, {"flag": "interpolator", "parameterName": "Interpolation", "dataType": "Choices", "availableChoices": [{"choice": "nn", "description": ["Nearest neighbor interpolation leads to poor image quality, but it is very fast."]}, {"choice": "linear", "description": ["Linear interpolation leads to average image quality but is quite fast."]}, {"choice": "bco", "description": []}], "explanation": []}, {"flag": "interpolator.bco.radius", "parameterName": "Radius for bicubic interpolation", "dataType": "Int", "explanation": ["This parameter allows controlling the size of the bicubic interpolation filter. If the target pixel size is higher than the input pixel size, increasing this parameter will reduce aliasing artifacts."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application allows performing image resampling from an input resampling grid. \n"},
{"name": "Rescale", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Rescale.html", "label": "Rescale Image", "category": "Deprecated", "definition": "Rescale the image between two given values.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Rescale - in QB_Toulouse_Ortho_PAN . tif - out rescaledImage . png uchar - outmin 0 - outmax 255", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Rescale application Rescale = otbApplication . Registry . CreateApplication ( \"Rescale\" ) # The following lines set all the application parameters: Rescale . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_PAN.tif\" ) Rescale . SetParameterString ( \"out\" , \"rescaledImage.png\" ) Rescale . SetParameterOutputImagePixelType ( \"out\" , 1 ) Rescale . SetParameterFloat ( \"outmin\" , 0 ) Rescale . SetParameterFloat ( \"outmax\" , 255 ) # The following line execute the application Rescale . ExecuteAndWriteOutput ()"], "command": "otbcli_Rescale", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The image to scale."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The rescaled image filename."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "outmin", "parameterName": "Output min value", "dataType": "Float", "explanation": ["Minimum value of the output image."]}, {"flag": "outmax", "parameterName": "Output max value", "dataType": "Float", "explanation": ["Maximum value of the output image."]}], "description": "\n   \n This application scales the given image pixel intensity between two given values.\nBy default min (resp. max) value is set to 0 (resp. 255).\nInput minimum and maximum values is automatically computed for all image bands. \n"},
{"name": "Convert", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Convert.html", "label": "Image Conversion", "category": "Deprecated", "definition": "Convert an image to a different format, optionally rescaling the data and/or changing the pixel type.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Convert - in QB_Toulouse_Ortho_XS . tif - out otbConvertWithScalingOutput . png - type linear - channels rgb", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Convert application Convert = otbApplication . Registry . CreateApplication ( \"Convert\" ) # The following lines set all the application parameters: Convert . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) Convert . SetParameterString ( \"out\" , \"otbConvertWithScalingOutput.png\" ) Convert . SetParameterString ( \"type\" , \"linear\" ) Convert . SetParameterString ( \"channels\" , \"rgb\" ) # The following line execute the application Convert . ExecuteAndWriteOutput ()"], "command": "otbcli_Convert", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "mask", "parameterName": "Input mask", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "type", "parameterName": "Rescale type", "dataType": "Choices", "availableChoices": [{"choice": "none", "description": []}, {"choice": "linear", "description": []}, {"choice": "log2", "description": []}], "explanation": []}, {"flag": "type.linear.gamma", "parameterName": "Gamma correction factor", "dataType": "Float", "explanation": ["Gamma correction factor."]}, {"flag": "hcp.high", "parameterName": "High Cut Quantile", "dataType": "Float", "explanation": ["Quantiles to cut from histogram high values before computing min/max rescaling (in percent, 2 by default)."]}, {"flag": "hcp.low", "parameterName": "Low Cut Quantile", "dataType": "Float", "explanation": ["Quantiles to cut from histogram low values before computing min/max rescaling (in percent, 2 by default)."]}, {"flag": "channels", "parameterName": "Channels selection", "dataType": "Choices", "availableChoices": [{"choice": "all", "description": ["Select all bands in the input image, (1,...,n)."]}, {"choice": "grayscale", "description": ["Display single channel as standard color image."]}, {"choice": "rgb", "description": ["Select 3 bands in the input image (multi-bands), by default (1,2,3)."]}], "explanation": []}, {"flag": "channels.grayscale.channel", "parameterName": "Grayscale channel", "dataType": "Int", "explanation": []}, {"flag": "channels.rgb.red", "parameterName": "Red Channel", "dataType": "Int", "explanation": ["Red channel index."]}, {"flag": "channels.rgb.green", "parameterName": "Green Channel", "dataType": "Int", "explanation": ["Green channel index."]}, {"flag": "channels.rgb.blue", "parameterName": "Blue Channel", "dataType": "Int", "explanation": ["Blue channel index."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application performs an image pixel type conversion (short, ushort, uchar, int, uint, float and double types are handled). The output image is written in the specified format (ie. that corresponds to the given extension). \n The conversion can include a rescale of the data range, by default it\u2019s set from 2% to 98% of the data values. The rescale can be linear or log2.\nThe choice of the output channels can be done with the extended filename, but less easy to handle. To do this, a \u2018channels\u2019 parameter allows you to select the desired bands at the output. There are 3 modes, the available choices are:\n* grayscale :  to display mono image as standard color image\n* rgb : select 3 bands in the input image (multi-bands)\n* all : keep all bands. \n \n"},
{"name": "Smoothing", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Smoothing.html", "label": "Smoothing", "category": "Image Filtering", "definition": "Apply a smoothing filter to an image", "authors": null, "limitations": null, "example": ["", ""], "command": null, "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "type", "parameterName": "Smoothing Type", "dataType": "Choices", "availableChoices": [{"choice": "mean", "description": []}, {"choice": "gaussian", "description": []}, {"choice": "anidif", "description": []}], "explanation": []}, {"flag": "type.mean.radius", "parameterName": "Radius", "dataType": "Int", "explanation": ["Standard deviation of the gaussian kernel used to filter the image."]}, {"flag": "type.gaussian.radius", "parameterName": "Radius", "dataType": "Float", "explanation": ["Standard deviation of the gaussian kernel used to filter the image."]}, {"flag": "type.anidif.timestep", "parameterName": "Time Step", "dataType": "Float", "explanation": ["Time step that will be used to discretize the diffusion equation."]}, {"flag": "type.anidif.nbiter", "parameterName": "Nb Iterations", "dataType": "Int", "explanation": ["Number of iterations needed to get the result."]}, {"flag": "type.anidif.conductance", "parameterName": "Conductance", "dataType": "Float", "explanation": ["Controls the sensitivity of the conductance term in the diffusion equation. The lower it is the stronger the features will be preserved."]}], "description": "\n   \n This application applies a smoothing filter to an image. Three methodes can be used : a gaussian filter , a mean filter , or an anisotropic diffusion using the Perona-Malik algorithm. \n"},
{"name": "Despeckle", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Despeckle.html", "label": "Despeckle", "category": "Image Filtering", "definition": "Perform speckle noise reduction on SAR image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Despeckle - in sar . tif - filter lee - filter . lee . rad 5 - out despeckle . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Despeckle application Despeckle = otbApplication . Registry . CreateApplication ( \"Despeckle\" ) # The following lines set all the application parameters: Despeckle . SetParameterString ( \"in\" , \"sar.tif\" ) Despeckle . SetParameterString ( \"filter\" , \"lee\" ) Despeckle . SetParameterInt ( \"filter.lee.rad\" , 5 ) Despeckle . SetParameterString ( \"out\" , \"despeckle.tif\" ) # The following line execute the application Despeckle . ExecuteAndWriteOutput ()"], "command": "otbcli_Despeckle", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "filter", "parameterName": "Speckle filtering method", "dataType": "Choices", "availableChoices": [{"choice": "lee", "description": ["Lee filter."]}, {"choice": "frost", "description": ["Frost filter."]}, {"choice": "gammamap", "description": ["GammaMap filter."]}, {"choice": "kuan", "description": ["Kuan filter."]}], "explanation": []}, {"flag": "filter.lee.rad", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius in pixel."]}, {"flag": "filter.lee.nblooks", "parameterName": "Number of looks", "dataType": "Float", "explanation": ["Number of looks in the input image."]}, {"flag": "filter.frost.rad", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius in pixel."]}, {"flag": "filter.frost.deramp", "parameterName": "Deramp factor", "dataType": "Float", "explanation": ["factor use to control the exponential function used to weight effect of the distance between the central pixel and its neighborhood. Increasing the deramp parameter will lead to take more into account pixels farther from the center and therefore increase the smoothing effects."]}, {"flag": "filter.gammamap.rad", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius in pixel."]}, {"flag": "filter.gammamap.nblooks", "parameterName": "Number of looks", "dataType": "Float", "explanation": ["Number of looks in the input image."]}, {"flag": "filter.kuan.rad", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius in pixel."]}, {"flag": "filter.kuan.nblooks", "parameterName": "Number of looks", "dataType": "Float", "explanation": ["Number of looks in the input image."]}], "description": "\n   \n SAR images are affected by speckle noise that inherently exists in and which degrades the image quality. It is caused by the coherent nature of back-scattered waves from multiple distributed targets. It is locally strong and it increases the mean Grey level of a local area. \n Reducing the speckle noise enhances radiometric resolution but tend to decrease the spatial resolution.Several different methods are used to eliminate speckle noise, based upon different mathematical models of the phenomenon. The application includes four methods: Lee [1], Frost [2], GammaMAP [3] and Kuan [4]. \n \n We sum up below the basic principle of this four methods: \n \n Lee : Estimate the signal by mean square error minimization (MMSE) on a sliding window. \n Frost : Also derived from the MMSE criteria with a weighted sum of the values within the window. The weighting factors decrease with distance from the pixel of interest. \n GammaMAP  : Derived under the assumption of the image follows a Gamma distribution. \n Kuan : Also derived from the MMSE criteria under the assumption of non stationary mean and variance. It is quite similar to Lee filter in form. \n \n \n \n"},
{"name": "DomainTransform", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DomainTransform.html", "label": "DomainTransform", "category": "Image Filtering", "definition": "Domain Transform application for wavelet and fourier", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DomainTransform - in input . tif - mode . wavelet . form haar - out output_wavelet_haar . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DomainTransform application DomainTransform = otbApplication . Registry . CreateApplication ( \"DomainTransform\" ) # The following lines set all the application parameters: DomainTransform . SetParameterString ( \"in\" , \"input.tif\" ) DomainTransform . SetParameterString ( \"mode.wavelet.form\" , \"haar\" ) DomainTransform . SetParameterString ( \"out\" , \"output_wavelet_haar.tif\" ) # The following line execute the application DomainTransform . ExecuteAndWriteOutput ()"], "command": "otbcli_DomainTransform", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "mode", "parameterName": "Mode", "dataType": "Choices", "availableChoices": [{"choice": "fft", "description": ["FFT transform."]}, {"choice": "wavelet", "description": ["Wavelet transform."]}], "explanation": []}, {"flag": "mode.fft.shift", "parameterName": "Shift fft transform", "dataType": "Boolean", "explanation": ["Shift transform of fft filter."]}, {"flag": "mode.wavelet.form", "parameterName": "Select wavelet form", "dataType": "Choices", "availableChoices": [{"choice": "haar", "description": []}, {"choice": "db4", "description": []}, {"choice": "db6", "description": []}, {"choice": "db8", "description": []}, {"choice": "db12", "description": []}, {"choice": "db20", "description": []}, {"choice": "sb24", "description": []}, {"choice": "sb44", "description": []}, {"choice": "sym8", "description": []}], "explanation": [" Available choices are:"]}, {"flag": "mode.wavelet.nlevels", "parameterName": "Number of decomposition levels", "dataType": "Int", "explanation": ["Number of decomposition levels."]}, {"flag": "direction", "parameterName": "Direction", "dataType": "Choices", "availableChoices": [{"choice": "forward", "description": []}, {"choice": "inverse", "description": []}], "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n Domain Transform application for wavelet and fourier \n"},
{"name": "DimensionalityReduction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DimensionalityReduction.html", "label": "Dimensionality reduction", "category": "Image Filtering", "definition": "Perform Dimension reduction of the input image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DimensionalityReduction - in cupriteSubHsi . tif - out FilterOutput . tif - method pca", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DimensionalityReduction application DimensionalityReduction = otbApplication . Registry . CreateApplication ( \"DimensionalityReduction\" ) # The following lines set all the application parameters: DimensionalityReduction . SetParameterString ( \"in\" , \"cupriteSubHsi.tif\" ) DimensionalityReduction . SetParameterString ( \"out\" , \"FilterOutput.tif\" ) DimensionalityReduction . SetParameterString ( \"method\" , \"pca\" ) # The following line execute the application DimensionalityReduction . ExecuteAndWriteOutput ()"], "command": "otbcli_DimensionalityReduction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "outinv", "parameterName": "Inverse Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "outmatrix", "parameterName": "Transformation matrix output (text format)", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "rescale.outmin", "parameterName": "Output min value", "dataType": "Float", "explanation": ["Minimum value of the output image."]}, {"flag": "rescale.outmax", "parameterName": "Output max value", "dataType": "Float", "explanation": ["Maximum value of the output image."]}, {"flag": "method", "parameterName": "Algorithm", "dataType": "Choices", "availableChoices": [{"choice": "pca", "description": ["Principal Component Analysis."]}, {"choice": "napca", "description": ["Noise Adjusted Principal Component Analysis."]}, {"choice": "maf", "description": ["Maximum Autocorrelation Factor."]}, {"choice": "ica", "description": ["Independent Component Analysis."]}], "explanation": []}, {"flag": "method.napca.radiusx", "parameterName": "Set the x radius of the sliding window.", "dataType": "Int", "explanation": []}, {"flag": "method.napca.radiusy", "parameterName": "Set the y radius of the sliding window.", "dataType": "Int", "explanation": []}, {"flag": "method.ica.iter", "parameterName": "number of iterations", "dataType": "Int", "explanation": []}, {"flag": "method.ica.mu", "parameterName": "Give the increment weight of W in [0, 1]", "dataType": "Float", "explanation": []}, {"flag": "nbcomp", "parameterName": "Number of Components.", "dataType": "Int", "explanation": []}, {"flag": "normalize", "parameterName": "Normalize.", "dataType": "Boolean", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n Performs dimensionality reduction on input image. PCA,NA-PCA,MAF,ICA methods are available. It is also possible to compute the inverse transform to reconstruct the image. It is also possible to optionally export the transformation matrix to a text file. \n"},
{"name": "MeanShiftSmoothing", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MeanShiftSmoothing.html", "label": "MeanShift Smoothing", "category": "Image Filtering", "definition": "This application smooths an image using the MeanShift algorithm.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MeanShiftSmoothing - in maur_rgb . png - fout smooth . tif - foutpos position . tif - spatialr 16 - ranger 16 - thres 0.1 - maxiter 100", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MeanShiftSmoothing application MeanShiftSmoothing = otbApplication . Registry . CreateApplication ( \"MeanShiftSmoothing\" ) # The following lines set all the application parameters: MeanShiftSmoothing . SetParameterString ( \"in\" , \"maur_rgb.png\" ) MeanShiftSmoothing . SetParameterString ( \"fout\" , \"smooth.tif\" ) MeanShiftSmoothing . SetParameterString ( \"foutpos\" , \"position.tif\" ) MeanShiftSmoothing . SetParameterInt ( \"spatialr\" , 16 ) MeanShiftSmoothing . SetParameterFloat ( \"ranger\" , 16 ) MeanShiftSmoothing . SetParameterFloat ( \"thres\" , 0.1 ) MeanShiftSmoothing . SetParameterInt ( \"maxiter\" , 100 ) # The following line execute the application MeanShiftSmoothing . ExecuteAndWriteOutput ()"], "command": "otbcli_MeanShiftSmoothing", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image can be any single or multiband image. Beware of pontential imbalance between bands ranges as it may alter euclidean distance."], "isInputFile": true}, {"flag": "fout", "parameterName": "Spectral filtered output", "dataType": "Output image", "explanation": ["This output image contains the final average spectral signatures of each pixel. The output type should be at least as wide as the input image type. Floating point encoding is advised. This output can be used as input image (in) of the LSMSSegmentation application [4,5]."], "isOutputFile": true}, {"flag": "foutpos", "parameterName": "Spatial filtered displacement output", "dataType": "Output image", "explanation": [" This output image contains the 2D displacement between the input pixel spatial position and the final position after convergence. Floating point encoding is mandatory. This output can be used as input image (in) of the LSMSSegmentation application [4,5]."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "spatialr", "parameterName": "Spatial radius", "dataType": "Int", "explanation": ["Radius of the spatial neighborhood for averaging. Higher values will result in more smoothing and higher processing time."]}, {"flag": "ranger", "parameterName": "Range radius", "dataType": "Float", "explanation": ["Threshold on spectral signature euclidean distance (expressed in radiometry unit) to consider neighborhood pixel for averaging. Higher values will be less edge-preserving (more similar to simple average in neighborhood), whereas lower values will result in less noise smoothing. Note that this parameter has no effect on processing time."]}, {"flag": "thres", "parameterName": "Mode convergence threshold", "dataType": "Float", "explanation": ["Algorithm will stop if update of average spectral signature and spatial position is below this threshold."]}, {"flag": "maxiter", "parameterName": "Maximum number of iterations", "dataType": "Int", "explanation": ["Algorithm will stop if convergence threshold is not met after the maximum number of iterations."]}, {"flag": "rangeramp", "parameterName": "Range radius ramp coefficient", "dataType": "Float", "explanation": ["Vary the range radius linearly with the central pixel intensity (experimental)."]}, {"flag": "modesearch", "parameterName": "Mode search.", "dataType": "Boolean", "explanation": ["If activated pixel iterative convergence is stopped if the path crosses an already converged pixel. Be careful, with this option, the result will slightly depend on thread number and the results will not be stable (see [4] for more details)."]}], "description": "\n   \n MeanShift [1,2,3] is an iterative edge-preserving image smoothing algorithm often used in image processing and as a first step for image segmentation. The MeanShift algorithm can be applied to multispectral images. \n At first iteration, for any given pixel of the input image, the filtered value correspond to the average spectral signature of neighborhood pixels that are both spatially closer than the spatial radius parameter (spatialr) and with spectral signature that have an euclidean distance to the input pixel lower than the range radius (ranger), that is, pixels that are both close in space and in spectral signatures. Subsequent iterations will repeat this process by considering that the pixel signature corresponds to the average spectral signature computed during previous iteration, and that the pixel position corresponds to the average position of pixels used to compute the average signature.The algorithm stops when the maximum number of iterations (maxiter) is reached, or when the position and spectral signature does not change much between iterations, according to the convergence threshold (thres). If the modesearch option is used then convergence will also stops if the spatial position reaches a pixel that has already converged. This will speed-up convergence, at the expense of stability of the result. \n The application outputs the image of the final averaged spectral signatures (fout), and can also optionally output the 2D displacement field between input pixel position and final pixel position after convergence (foutpos). \n Note that computing an euclidean distance between spectral signatures may be inaccurate and that techniques such as color space transform or image normalisation could be applied before using this application. Also note that most satellite images noise model is not gaussian, since noise variance linearly depends on radiance (the higher the radiance, the higher the noise variance). To account for such noise model, the application provides the range radius ramp option (rangeramp), which will vary the range radius linearly with the central pixel intensity. Default value is 1. (no ramp). \n This application is the first step of the large scale MeanShift method depicted in [4]. Both outputs (fout and foutpos) can be passed to the large scale MeanShift segmentation application [5]. If the application is used for large scale MeanShift, modesearch option should be off. \n"},
{"name": "ContrastEnhancement", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ContrastEnhancement.html", "label": "Contrast Enhancement", "category": "Image Filtering", "definition": "This application is the implementation of the histogram equalization algorithm. It can be used to enhance contrast in an image or to reduce the dynamic of the image without losing too much contrast. It offers several options as a no data value, a contrast limitation factor, a local version of the algorithm and also a mode to equalize the luminance of the image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ContrastEnhancement - in colours . tif - out equalizedcolors . tif float - bins 256 - spatial . local . w 500 - spatial . local . h 500 - mode lum", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ContrastEnhancement application ContrastEnhancement = otbApplication . Registry . CreateApplication ( \"ContrastEnhancement\" ) # The following lines set all the application parameters: ContrastEnhancement . SetParameterString ( \"in\" , \"colours.tif\" ) ContrastEnhancement . SetParameterString ( \"out\" , \"equalizedcolors.tif\" ) ContrastEnhancement . SetParameterOutputImagePixelType ( \"out\" , 6 ) ContrastEnhancement . SetParameterInt ( \"bins\" , 256 ) ContrastEnhancement . SetParameterInt ( \"spatial.local.w\" , 500 ) ContrastEnhancement . SetParameterInt ( \"spatial.local.h\" , 500 ) ContrastEnhancement . SetParameterString ( \"mode\" , \"lum\" ) # The following line execute the application ContrastEnhancement . ExecuteAndWriteOutput ()"], "command": "otbcli_ContrastEnhancement", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "bins", "parameterName": "Number of bins", "dataType": "Int", "explanation": []}, {"flag": "hfact", "parameterName": "Contrast Limitation", "dataType": "Float", "explanation": []}, {"flag": "nodata", "parameterName": "Nodata Value", "dataType": "Float", "explanation": []}, {"flag": "spatial", "parameterName": "Spatial parameters for the histogram computation", "dataType": "Choices", "availableChoices": [{"choice": "local", "description": ["The histograms will be computed on each thumbnail. Each of the histogram will be equalized and the corresponding gain will be interpolated."]}, {"choice": "global", "description": ["Min/max computation will result in the same minimum and maximum for all the bands."]}], "explanation": []}, {"flag": "spatial.local.h", "parameterName": "Thumbnail height", "dataType": "Int", "explanation": ["Height of the thumbnail over which the histogram will be computed. The value is in pixels."]}, {"flag": "spatial.local.w", "parameterName": "Thumbnail width", "dataType": "Int", "explanation": ["Width of the thumbnail over which the histogram will be computed. The value is in pixels."]}, {"flag": "minmax", "parameterName": "Minimum and maximum settings", "dataType": "Choices", "availableChoices": [{"choice": "auto", "description": ["Minimum and maximum value will be computed on the image (nodata value won\u2019t be taken into account) . Each band will have a minimum and a maximum."]}, {"choice": "manual", "description": ["Minimum and maximum value will be set by the user."]}], "explanation": []}, {"flag": "minmax.auto.global", "parameterName": "Global", "dataType": "Boolean", "explanation": ["Min/max computation will result in the same minimum and maximum for all the bands."]}, {"flag": "minmax.manual.min", "parameterName": "Minimum value", "dataType": "Float", "explanation": []}, {"flag": "minmax.manual.max", "parameterName": "Maximum value", "dataType": "Float", "explanation": []}, {"flag": "mode", "parameterName": "What to equalized", "dataType": "Choices", "availableChoices": [{"choice": "each", "description": ["Each channel is equalized independently."]}, {"choice": "lum", "description": ["The relative luminance is computed according to the coefficients.Then the histogram is equalized and the gain is applied to each of the channels. The channel gain will depend on the weight (coef) of the channel in the luminance. Note that default values come from color space theories on how human eyes perceive colors)."]}], "explanation": []}, {"flag": "mode.lum.red.ch", "parameterName": "Red channel", "dataType": "Int", "explanation": []}, {"flag": "mode.lum.red.coef", "parameterName": "Value for luminance computation for the red channel", "dataType": "Float", "explanation": []}, {"flag": "mode.lum.green.ch", "parameterName": "Green channel", "dataType": "Int", "explanation": []}, {"flag": "mode.lum.green.coef", "parameterName": "Value for luminance computation of the green channel", "dataType": "Float", "explanation": []}, {"flag": "mode.lum.blue.ch", "parameterName": "Blue channel", "dataType": "Int", "explanation": []}, {"flag": "mode.lum.blue.coef", "parameterName": "Value for luminance computation of the blue channel", "dataType": "Float", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application is the implementation of the histogram equalization algorithm. The idea of the algorithm is to use the whole available dynamic. In order to do so it computes a histogram over the image and then use the whole dynamic: meaning flattening the histogram. That gives us gain for each bin that transform the original histogram into the flat one. This gain is then apply on the original image.\nThe application proposes several options to allow a finer result:\n- There is an option to limit contrast. We choose to limit the contrast by modifying the original histogram. To do so we clip the histogram at a given height and redistribute equally among the bins the clipped population. Then we add a local version of the algorithm.\n- It is possible to apply the algorithm on tiles of the image, instead of on the whole image. That gives us gain depending on the value of the pixel and its position in the image. In order to smoothen the result we interpolate the gain between tiles. \n"},
{"name": "VectorDataTransform", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDataTransform.html", "label": "Vector Data Transformation", "category": "Vector Data Manipulation", "definition": "Apply a transform to each vertex of the input VectorData", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDataTransform - vd qb_RoadExtract_easyClassification . shp - in qb_RoadExtract . tif - out VectorDataTransform . shp - transform . ro 5", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDataTransform application VectorDataTransform = otbApplication . Registry . CreateApplication ( \"VectorDataTransform\" ) # The following lines set all the application parameters: VectorDataTransform . SetParameterString ( \"vd\" , \"qb_RoadExtract_easyClassification.shp\" ) VectorDataTransform . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) VectorDataTransform . SetParameterString ( \"out\" , \"VectorDataTransform.shp\" ) VectorDataTransform . SetParameterFloat ( \"transform.ro\" , 5 ) # The following line execute the application VectorDataTransform . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDataTransform", "parameters": [{"flag": "vd", "parameterName": "Input Vector data", "dataType": "Input vector data", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Vector data", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "in", "parameterName": "Support image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "transform.tx", "parameterName": "X Translation", "dataType": "Float", "explanation": ["Translation in the X direction (in pixels)."]}, {"flag": "transform.ty", "parameterName": "Y Translation", "dataType": "Float", "explanation": ["Translation in the Y direction (in pixels)."]}, {"flag": "transform.ro", "parameterName": "Rotation Angle", "dataType": "Float", "explanation": ["Angle of the rotation (in degrees)."]}, {"flag": "transform.centerx", "parameterName": "Center X", "dataType": "Float", "explanation": ["X coordinate of the rotation and scaling center (in physical units)."]}, {"flag": "transform.centery", "parameterName": "Center Y", "dataType": "Float", "explanation": ["Y coordinate of the rotation and scaling center (in physical units)."]}, {"flag": "transform.scale", "parameterName": "Scale", "dataType": "Float", "explanation": ["The scale coefficient to apply."]}], "description": "\n   \n This application iterates over each vertex in the input vector data file and performs a transformation on this vertex. \n It is the equivalent of [1] that transforms images. For instance, if you extract the envelope of an image with [2], and you transform this image with [1], you may want to use this application to operate the same transform on the envelope. \n The applied transformation is a 2D similarity. It manages translation, rotation, scaling, and can be centered or not. Note that the support image is used to define the reference coordinate system in which the transform is applied. For instance the input vector data can have WGS84 coordinates, the support image is in UTM, so a translation of 1 pixel along X corresponds to the X pixel size of the input image along the X axis of the UTM coordinates frame. This image can also be in sensor geometry. \n"},
{"name": "VectorDataSetField", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDataSetField.html", "label": "Vector data set field", "category": "Vector Data Manipulation", "definition": "Set a field in vector data.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDataSetField - in qb_RoadExtract_classification . shp - out VectorDataSetField . shp - fn Info - fv Sample polygon", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDataSetField application VectorDataSetField = otbApplication . Registry . CreateApplication ( \"VectorDataSetField\" ) # The following lines set all the application parameters: VectorDataSetField . SetParameterString ( \"in\" , \"qb_RoadExtract_classification.shp\" ) VectorDataSetField . SetParameterString ( \"out\" , \"VectorDataSetField.shp\" ) VectorDataSetField . SetParameterString ( \"fn\" , \"Info\" ) VectorDataSetField . SetParameterString ( \"fv\" , \"Sample polygon\" ) # The following line execute the application VectorDataSetField . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDataSetField", "parameters": [{"flag": "in", "parameterName": "Input", "dataType": "Input vector data", "explanation": ["Input Vector Data."], "isInputFile": true}, {"flag": "out", "parameterName": "Output", "dataType": "Output vector data", "explanation": ["Output Vector Data."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "fn", "parameterName": "Field", "dataType": "String", "explanation": ["Field name."]}, {"flag": "fv", "parameterName": "Value", "dataType": "String", "explanation": ["Field value."]}], "description": "\n   \n Set a specified field to a specified value on all features of a vector data. \n"},
{"name": "VectorDataReprojection", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDataReprojection.html", "label": "Vector Data reprojection", "category": "Vector Data Manipulation", "definition": "Reproject a vector data using support image projection reference, or a user specified map projection", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDataReprojection - in . vd VectorData_QB1 . shp - out . proj image - out . proj . image . in ROI_QB_MUL_1 . tif - out . vd reprojected_vd . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDataReprojection application VectorDataReprojection = otbApplication . Registry . CreateApplication ( \"VectorDataReprojection\" ) # The following lines set all the application parameters: VectorDataReprojection . SetParameterString ( \"in.vd\" , \"VectorData_QB1.shp\" ) VectorDataReprojection . SetParameterString ( \"out.proj\" , \"image\" ) VectorDataReprojection . SetParameterString ( \"out.proj.image.in\" , \"ROI_QB_MUL_1.tif\" ) VectorDataReprojection . SetParameterString ( \"out.vd\" , \"reprojected_vd.shp\" ) # The following line execute the application VectorDataReprojection . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDataReprojection", "parameters": [{"flag": "in.vd", "parameterName": "Input vector data", "dataType": "Input File name", "explanation": ["The input vector data to reproject."], "isInputFile": true}, {"flag": "in.kwl", "parameterName": "Use image keywords list", "dataType": "Input image", "explanation": ["Optional input image to fill vector data with image kwl."], "isInputFile": true}, {"flag": "out.vd", "parameterName": "Output vector data", "dataType": "Output File name", "explanation": ["The reprojected vector data."], "isOutputFile": true}, {"flag": "out.proj.image.in", "parameterName": "Image used to get projection map", "dataType": "Input image", "explanation": ["Projection map will be found using image metadata."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "out.proj", "parameterName": "Output Projection choice", "dataType": "Choices", "availableChoices": [{"choice": "image", "description": ["Vector data will be reprojected in image projection ref."]}, {"choice": "user", "description": []}], "explanation": [" Available choices are:"]}, {"flag": "out.proj.user.map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": ["Defines the map projection to be used. Available choices are:"]}, {"flag": "out.proj.user.map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "out.proj.user.map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "out.proj.user.map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n \n This application allows reprojecting a vector data using support image projection reference, or a user given map projection.\nIf given, image keywordlist can be added to reprojected vectordata. \n"},
{"name": "VectorDataExtractROI", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDataExtractROI.html", "label": "VectorData Extract ROI", "category": "Vector Data Manipulation", "definition": "Perform an extract ROI on the input vector data according to the input image extent", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDataExtractROI - io . in qb_RoadExtract . tif - io . vd qb_RoadExtract_classification . shp - io . out apTvUtVectorDataExtractROIApplicationTest . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDataExtractROI application VectorDataExtractROI = otbApplication . Registry . CreateApplication ( \"VectorDataExtractROI\" ) # The following lines set all the application parameters: VectorDataExtractROI . SetParameterString ( \"io.in\" , \"qb_RoadExtract.tif\" ) VectorDataExtractROI . SetParameterString ( \"io.vd\" , \"qb_RoadExtract_classification.shp\" ) VectorDataExtractROI . SetParameterString ( \"io.out\" , \"apTvUtVectorDataExtractROIApplicationTest.shp\" ) # The following line execute the application VectorDataExtractROI . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDataExtractROI", "parameters": [{"flag": "io.vd", "parameterName": "Input Vector data", "dataType": "Input vector data", "explanation": ["Input vector data."], "isInputFile": true}, {"flag": "io.in", "parameterName": "Support image", "dataType": "Input image", "explanation": ["Support image that specifies the extracted region."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output Vector data", "dataType": "Output vector data", "explanation": ["Output extracted vector data."], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n This application extracts the vector data features belonging to a region specified by the support image envelope. Any features intersecting the support region is copied to output. The output geometries are NOT cropped. \n"},
{"name": "Rasterization", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Rasterization.html", "label": "Rasterization", "category": "Vector Data Manipulation", "definition": "Rasterize a vector dataset.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Rasterization - in qb_RoadExtract_classification . shp - out rasterImage . tif - spx 1. - spy 1.", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Rasterization application Rasterization = otbApplication . Registry . CreateApplication ( \"Rasterization\" ) # The following lines set all the application parameters: Rasterization . SetParameterString ( \"in\" , \"qb_RoadExtract_classification.shp\" ) Rasterization . SetParameterString ( \"out\" , \"rasterImage.tif\" ) Rasterization . SetParameterFloat ( \"spx\" , 1. ) Rasterization . SetParameterFloat ( \"spy\" , 1. ) # The following line execute the application Rasterization . ExecuteAndWriteOutput ()"], "command": "otbcli_Rasterization", "parameters": [{"flag": "in", "parameterName": "Input vector dataset", "dataType": "Input vector data", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "im", "parameterName": "Input reference image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "szx", "parameterName": "Output size x", "dataType": "Int", "explanation": []}, {"flag": "szy", "parameterName": "Output size y", "dataType": "Int", "explanation": []}, {"flag": "epsg", "parameterName": "Output EPSG code", "dataType": "Int", "explanation": []}, {"flag": "orx", "parameterName": "Output Upper-left x", "dataType": "Float", "explanation": []}, {"flag": "ory", "parameterName": "Output Upper-left y", "dataType": "Float", "explanation": []}, {"flag": "spx", "parameterName": "Spacing (GSD) x", "dataType": "Float", "explanation": []}, {"flag": "spy", "parameterName": "Spacing (GSD) y", "dataType": "Float", "explanation": []}, {"flag": "background", "parameterName": "Background value", "dataType": "Float", "explanation": []}, {"flag": "mode", "parameterName": "Rasterization mode", "dataType": "Choices", "availableChoices": [{"choice": "binary", "description": ["In this mode, pixels within a geometry will hold the user-defined foreground value."]}, {"choice": "attribute", "description": ["In this mode, pixels within a geometry will hold the value of a user-defined field extracted from this geometry."]}], "explanation": []}, {"flag": "mode.binary.foreground", "parameterName": "Foreground value", "dataType": "Float", "explanation": ["Value for pixels inside a geometry."]}, {"flag": "mode.attribute.field", "parameterName": "The attribute field to burn", "dataType": "String", "explanation": ["Name of the attribute field to burn."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application allows reprojecting and rasterize a vector dataset. The grid of the rasterized output can be set by using a reference image, or by setting all parmeters (origin, size, spacing) by hand. In the latter case, at least the spacing (ground sampling distance) is needed (other parameters are computed automatically). The rasterized output can also be in a different projection reference system than the input dataset. \n There are two rasterize mode available in the application. The first is the binary mode: it allows rendering all pixels belonging to a geometry of the input dataset in the foreground color, while rendering the other in background color. The second one allows rendering pixels belonging to a geometry woth respect to an attribute of this geometry. The field of the attribute to render can be set by the user. In the second mode, the background value is still used for unassociated pixels. \n \n"},
{"name": "Segmentation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Segmentation.html", "label": "Segmentation", "category": "Segmentation", "definition": "Performs segmentation of an image, and output either a raster or a vector file. In vector mode, large input datasets are supported.", "authors": null, "limitations": null, "example": ["", ""], "command": null, "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "mode.vector.out", "parameterName": "Output vector file", "dataType": "Output File name", "explanation": ["The output vector file or database (name can be anything understood by OGR)."], "isOutputFile": true}, {"flag": "mode.vector.inmask", "parameterName": "Mask Image", "dataType": "Input image", "explanation": ["Only pixels whose mask value is strictly positive will be segmented."], "isInputFile": true}, {"flag": "mode.raster.out", "parameterName": "Output labeled image", "dataType": "Output image", "explanation": ["The output labeled image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "filter", "parameterName": "Segmentation algorithm", "dataType": "Choices", "availableChoices": [{"choice": "meanshift", "description": ["OTB implementation of the Mean-Shift algorithm (multi-threaded)."]}, {"choice": "cc", "description": ["Simple pixel-based connected-components algorithm with a user-defined connection condition."]}, {"choice": "watershed", "description": ["The traditional watershed algorithm. The height function is the gradient magnitude of the amplitude (square root of the sum of squared bands)."]}, {"choice": "mprofiles", "description": ["Segmentation based on morphological profiles, as described in Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach for the morphological segmentation of high resolution satellite imagery. IEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2, February 2001, p. 309-320."]}], "explanation": []}, {"flag": "filter.meanshift.spatialr", "parameterName": "Spatial radius", "dataType": "Int", "explanation": ["Spatial radius of the neighborhood."]}, {"flag": "filter.meanshift.ranger", "parameterName": "Range radius", "dataType": "Float", "explanation": ["Range radius defining the radius (expressed in radiometry unit) in the multispectral space."]}, {"flag": "filter.meanshift.thres", "parameterName": "Mode convergence threshold", "dataType": "Float", "explanation": ["Algorithm iterative scheme will stop if mean-shift vector is below this threshold or if iteration number reached maximum number of iterations."]}, {"flag": "filter.meanshift.maxiter", "parameterName": "Maximum number of iterations", "dataType": "Int", "explanation": ["Algorithm iterative scheme will stop if convergence hasn\u2019t been reached after the maximum number of iterations."]}, {"flag": "filter.meanshift.minsize", "parameterName": "Minimum region size", "dataType": "Int", "explanation": ["Minimum size of a region (in pixel unit) in segmentation. Smaller clusters will be merged to the neighboring cluster with the closest radiometry. If set to 0 no pruning is done."]}, {"flag": "filter.cc.expr", "parameterName": "Condition", "dataType": "String", "explanation": ["User defined connection condition, written as a mathematical expression. Available variables are p(i)b(i), intensity_p(i) and distance (example of expression : distance < 10 )."]}, {"flag": "filter.watershed.threshold", "parameterName": "Depth Threshold", "dataType": "Float", "explanation": ["Depth threshold Units in percentage of the maximum depth in the image."]}, {"flag": "filter.watershed.level", "parameterName": "Flood Level", "dataType": "Float", "explanation": ["flood level for generating the merge tree from the initial segmentation (between 0 and 1)."]}, {"flag": "filter.mprofiles.size", "parameterName": "Profile Size", "dataType": "Int", "explanation": ["Size of the profiles."]}, {"flag": "filter.mprofiles.start", "parameterName": "Initial radius", "dataType": "Int", "explanation": ["Initial radius of the structuring element (in pixels)."]}, {"flag": "filter.mprofiles.step", "parameterName": "Radius step.", "dataType": "Int", "explanation": ["Radius step along the profile (in pixels)."]}, {"flag": "filter.mprofiles.sigma", "parameterName": "Threshold of the final decision rule", "dataType": "Float", "explanation": ["Profiles values under the threshold will be ignored."]}, {"flag": "mode", "parameterName": "Processing mode", "dataType": "Choices", "availableChoices": [{"choice": "vector", "description": ["In this mode, the application will output a vector file or database, and process the input image piecewise. This allows performing segmentation of very large images."]}, {"choice": "raster", "description": ["In this mode, the application will output a standard labeled raster. This mode can not handle large data."]}], "explanation": []}, {"flag": "mode.vector.outmode", "parameterName": "Writing mode for the output vector file", "dataType": "Choices", "availableChoices": [{"choice": "ulco", "description": ["The output vector file is opened in update mode if existing. If the output layer already exists, the application stops, leaving it untouched."]}, {"choice": "ovw", "description": ["If the output vector file already exists, it is completely destroyed (including all its layers) and recreated from scratch."]}, {"choice": "ulovw", "description": ["The output vector file is opened in update mode if existing. If the output layer already exists, it si completely destroyed and recreated from scratch."]}, {"choice": "ulu", "description": ["The output vector file is opened in update mode if existing. If the output layer already exists, the new geometries are appended to the layer."]}], "explanation": ["This allows one to set the writing behaviour for the output vector file. Please note that the actual behaviour depends on the file format. Available choices are:"]}, {"flag": "mode.vector.neighbor", "parameterName": "8-neighbor connectivity", "dataType": "Boolean", "explanation": ["Activate 8-Neighborhood connectivity (default is 4)."]}, {"flag": "mode.vector.stitch", "parameterName": "Stitch polygons", "dataType": "Boolean", "explanation": ["Scan polygons on each side of tiles and stitch polygons which connect by more than one pixel."]}, {"flag": "mode.vector.minsize", "parameterName": "Minimum object size", "dataType": "Int", "explanation": ["Objects whose size is below the minimum object size (area in pixels) will be ignored during vectorization."]}, {"flag": "mode.vector.simplify", "parameterName": "Simplify polygons", "dataType": "Float", "explanation": ["Simplify polygons according to a given tolerance (in pixel). This option allows reducing the size of the output file or database."]}, {"flag": "mode.vector.layername", "parameterName": "Layer name", "dataType": "String", "explanation": ["Name of the layer in the vector file or database (default is Layer)."]}, {"flag": "mode.vector.fieldname", "parameterName": "Geometry index field name", "dataType": "String", "explanation": ["Name of the field holding the geometry index in the output vector file or database."]}, {"flag": "mode.vector.tilesize", "parameterName": "Tiles size", "dataType": "Int", "explanation": ["User defined tiles size for tile-based segmentation. Optimal tile size is selected according to available RAM if null."]}, {"flag": "mode.vector.startlabel", "parameterName": "Starting geometry index", "dataType": "Int", "explanation": ["Starting value of the geometry index field."]}, {"flag": "mode.vector.ogroptions", "parameterName": "OGR options for layer creation", "dataType": "String list", "explanation": ["A list of layer creation options in the form KEY=VALUE that will be passed directly to OGR without any validity checking. Options may depend on the file format, and can be found in OGR documentation."]}], "description": "\n   \n This application allows one to perform various segmentation algorithms on a multispectral image.Available segmentation algorithms are two different versions of Mean-Shift segmentation algorithm (one being multi-threaded), simple pixel based connected components according to a user-defined criterion, and watershed from the gradient of the intensity (norm of spectral bands vector). The application has two different modes that affects the nature of its output. \n In raster mode, the output of the application is a classical image of unique labels identifying the segmented regions. The labeled output can be passed to the ColorMapping application to render regions with contrasted colours. Please note that this mode loads the whole input image into memory, and as such can not handle large images. \n \n To segment large data, one can use the vector mode. In this case, the output of the application is a vector file or database. The input image is split into tiles (whose size can be set using the tilesize parameter), and each tile is loaded, segmented with the chosen algorithm, vectorized, and written into the output file or database. This piece-wise behavior ensure that memory will never get overloaded, and that images of any size can be processed. There are few more options in the vector mode. The simplify option allows simplifying the geometry (i.e. remove nodes in polygons) according to a user-defined tolerance. The stitch option tries to stitch together the polygons corresponding to segmented region that may have been split by the tiling scheme. \n"},
{"name": "ConcatenateVectorData", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ConcatenateVectorData.html", "label": "Concatenate Vector Data", "category": "Vector Data Manipulation", "definition": "Concatenate vector data files", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ConcatenateVectorData - vd ToulousePoints - examples . shp ToulouseRoad - examples . shp - out ConcatenatedVectorData . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ConcatenateVectorData application ConcatenateVectorData = otbApplication . Registry . CreateApplication ( \"ConcatenateVectorData\" ) # The following lines set all the application parameters: ConcatenateVectorData . SetParameterStringList ( \"vd\" , [ 'ToulousePoints-examples.shp' , 'ToulouseRoad-examples.shp' ]) ConcatenateVectorData . SetParameterString ( \"out\" , \"ConcatenatedVectorData.shp\" ) # The following line execute the application ConcatenateVectorData . ExecuteAndWriteOutput ()"], "command": "otbcli_ConcatenateVectorData", "parameters": [{"flag": "vd", "parameterName": "Input vector files", "dataType": "Input vector data list", "explanation": ["Vector data files to be concatenated."], "isInputFile": true}, {"flag": "out", "parameterName": "Concatenated output", "dataType": "Output vector data", "explanation": ["Output conctenated vector data file."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [], "description": "\n   \n This application concatenates a list of vector data files to produce a unique vector data output file. \n This application will gather all the geometries from the input files and write them into an output vector data file. Any format supported by OGR can be used. Ideally, all inputs should have the same set of fields and the same spatial reference system. \n"},
{"name": "LargeScaleMeanShift", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LargeScaleMeanShift.html", "label": "Large", "category": "Segmentation", "definition": "Large-scale segmentation using MeanShift", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_LargeScaleMeanShift - in QB_1_ortho . tif - spatialr 4 - ranger 80 - minsize 16 - mode . vector . out regions . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LargeScaleMeanShift application LargeScaleMeanShift = otbApplication . Registry . CreateApplication ( \"LargeScaleMeanShift\" ) # The following lines set all the application parameters: LargeScaleMeanShift . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) LargeScaleMeanShift . SetParameterInt ( \"spatialr\" , 4 ) LargeScaleMeanShift . SetParameterFloat ( \"ranger\" , 80 ) LargeScaleMeanShift . SetParameterInt ( \"minsize\" , 16 ) LargeScaleMeanShift . SetParameterString ( \"mode.vector.out\" , \"regions.shp\" ) # The following line execute the application LargeScaleMeanShift . ExecuteAndWriteOutput ()"], "command": "otbcli_LargeScaleMeanShift", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "mode.vector.imfield", "parameterName": "Support image for field computation", "dataType": "Input image", "explanation": ["This is an optional support image that can be used to compute field values in each region. Otherwise, the input image is used as support."], "isInputFile": true}, {"flag": "mode.vector.out", "parameterName": "Output GIS vector file", "dataType": "Output File name", "explanation": ["The output GIS vector file, representing the vectorized version of the segmented image where the features of the polygons are the radiometric means and variances."], "isOutputFile": true}, {"flag": "mode.raster.out", "parameterName": "The output raster image", "dataType": "Output image", "explanation": ["It corresponds to the output of the small region merging step."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "spatialr", "parameterName": "Spatial radius", "dataType": "Int", "explanation": []}, {"flag": "ranger", "parameterName": "Range radius", "dataType": "Float", "explanation": []}, {"flag": "minsize", "parameterName": "Minimum Segment Size", "dataType": "Int", "explanation": []}, {"flag": "tilesizex", "parameterName": "Size of tiles in pixel (X-axis)", "dataType": "Int", "explanation": []}, {"flag": "tilesizey", "parameterName": "Size of tiles in pixel (Y-axis)", "dataType": "Int", "explanation": []}, {"flag": "mode", "parameterName": "Output mode", "dataType": "Choices", "availableChoices": [{"choice": "vector", "description": ["In this mode, the application will produce a vector file or database and compute field values for each region."]}, {"choice": "raster", "description": ["In this mode, the application will produce a standard labeled raster."]}], "explanation": []}, {"flag": "cleanup", "parameterName": "Temporary files cleaning", "dataType": "Boolean", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application chains together the 4 steps of the MeanShit framework, that is the MeanShiftSmoothing [1], the LSMSSegmentation [2], the LSMSSmallRegionsMerging [3] and the LSMSVectorization [4]. \n This application can be a preliminary step for an object-based analysis. \n It generates a vector data file containing the regions extracted with the MeanShift algorithm. The spatial and range radius parameters allow adapting the sensitivity of the algorithm depending on the image dynamic and resolution. There is a step to remove small regions whose size (in pixels) is less than the given \u2018minsize\u2019 parameter. These regions are merged to a similar neighbor region. In the output vectors, there are additional fields to describe each region. In particular the mean and standard deviation (for each band) is computed for each region using the input image as support. If an optional \u2018imfield\u2019 image is given, it will be used as support image instead. \n"},
{"name": "OGRLayerClassifier", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_OGRLayerClassifier.html", "label": "OGRLayerClassifier", "category": "Segmentation", "definition": "Classify an OGR layer based on a machine learning model and a list of features to consider.", "authors": "This application has been written by David Youssefi during internship at CNES.", "limitations": null, "example": ["otbcli_OGRLayerClassifier - inshp vectorData . shp - instats meanVar . xml - insvm svmModel . svm - feat perimeter - cfield predicted", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the OGRLayerClassifier application OGRLayerClassifier = otbApplication . Registry . CreateApplication ( \"OGRLayerClassifier\" ) # The following lines set all the application parameters: OGRLayerClassifier . SetParameterString ( \"inshp\" , \"vectorData.shp\" ) OGRLayerClassifier . SetParameterString ( \"instats\" , \"meanVar.xml\" ) OGRLayerClassifier . SetParameterString ( \"insvm\" , \"svmModel.svm\" ) # The following line execute the application OGRLayerClassifier . ExecuteAndWriteOutput ()"], "command": "otbcli_OGRLayerClassifier", "parameters": [{"flag": "inshp", "parameterName": "Name of the input shapefile", "dataType": "Input vector data", "explanation": ["Name of the input shapefile."], "isInputFile": true}, {"flag": "instats", "parameterName": "XML file containing mean and variance of each feature.", "dataType": "Input File name", "explanation": ["XML file containing mean and variance of each feature."], "isInputFile": true}, {"flag": "insvm", "parameterName": "Input model filename.", "dataType": "Output File name", "explanation": ["Input model filename."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "feat", "parameterName": "Features", "dataType": "List", "explanation": ["Features to be calculated."]}, {"flag": "cfield", "parameterName": "Field containing the predicted class.", "dataType": "String", "explanation": ["Field containing the predicted class."]}], "description": "\n   \n This application will apply a trained machine learning model on the selected feature to get a classification of each geometry contained in an OGR layer. The list of feature must match the list used for training. The predicted label is written in the user defined field for each geometry. \n"},
{"name": "LSMSVectorization", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LSMSVectorization.html", "label": "Exact Large", "category": "Segmentation", "definition": "This application performs the fourth step of the exact Large-Scale Mean-Shift segmentation workflow [1].", "authors": "This application has been written by David Youssefi.", "limitations": null, "example": ["otbcli_LSMSVectorization - in maur_rgb . png - inseg merged . tif - out vector . shp - tilesizex 256 - tilesizey 256", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LSMSVectorization application LSMSVectorization = otbApplication . Registry . CreateApplication ( \"LSMSVectorization\" ) # The following lines set all the application parameters: LSMSVectorization . SetParameterString ( \"in\" , \"maur_rgb.png\" ) LSMSVectorization . SetParameterString ( \"inseg\" , \"merged.tif\" ) LSMSVectorization . SetParameterString ( \"out\" , \"vector.shp\" ) LSMSVectorization . SetParameterInt ( \"tilesizex\" , 256 ) LSMSVectorization . SetParameterInt ( \"tilesizey\" , 256 ) # The following line execute the application LSMSVectorization . ExecuteAndWriteOutput ()"], "command": "otbcli_LSMSVectorization", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image, containing initial spectral signatures corresponding to the segmented image (inseg)."], "isInputFile": true}, {"flag": "inseg", "parameterName": "Segmented image", "dataType": "Input image", "explanation": ["Segmented image where each pixel value is the unique integer label of the segment it belongs to."], "isInputFile": true}, {"flag": "out", "parameterName": "Output GIS vector file", "dataType": "Output File name", "explanation": ["The output GIS vector file, representing the vectorized version of the segmented image where the features of the polygons are the radiometric means and variances."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "tilesizex", "parameterName": "Size of tiles in pixel (X-axis)", "dataType": "Int", "explanation": ["Size of tiles along the X-axis for tile-wise processing."]}, {"flag": "tilesizey", "parameterName": "Size of tiles in pixel (Y-axis)", "dataType": "Int", "explanation": ["Size of tiles along the Y-axis for tile-wise processing."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n Given a segmentation result (label image), that may come from the LSMSSegmentation [2] application (out parameter) or have been processed for small regions merging [3] (out parameter), it will convert it to a GIS vector file containing one polygon per segment. Each polygon contains additional fields: mean and variance of each channels from input image (in parameter), segmentation image label, number of pixels in the polygon. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results. \n"},
{"name": "LSMSSmallRegionsMerging", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LSMSSmallRegionsMerging.html", "label": "Exact Large", "category": "Segmentation", "definition": "This application performs the third (optional) step of the exact Large-Scale Mean-Shift segmentation workflow [1].", "authors": "This application has been written by David Youssefi.", "limitations": null, "example": ["otbcli_LSMSSmallRegionsMerging - in smooth . tif - inseg segmentation . tif - out merged . tif - minsize 20 - tilesizex 256 - tilesizey 256", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LSMSSmallRegionsMerging application LSMSSmallRegionsMerging = otbApplication . Registry . CreateApplication ( \"LSMSSmallRegionsMerging\" ) # The following lines set all the application parameters: LSMSSmallRegionsMerging . SetParameterString ( \"in\" , \"smooth.tif\" ) LSMSSmallRegionsMerging . SetParameterString ( \"inseg\" , \"segmentation.tif\" ) LSMSSmallRegionsMerging . SetParameterString ( \"out\" , \"merged.tif\" ) LSMSSmallRegionsMerging . SetParameterInt ( \"minsize\" , 20 ) LSMSSmallRegionsMerging . SetParameterInt ( \"tilesizex\" , 256 ) LSMSSmallRegionsMerging . SetParameterInt ( \"tilesizey\" , 256 ) # The following line execute the application LSMSSmallRegionsMerging . ExecuteAndWriteOutput ()"], "command": "otbcli_LSMSSmallRegionsMerging", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": ["The input image, containing initial spectral signatures corresponding to the segmented image (inseg)."], "isInputFile": true}, {"flag": "inseg", "parameterName": "Segmented image", "dataType": "Input image", "explanation": ["Segmented image where each pixel value is the unique integer label of the segment it belongs to."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output image. The output image is the segmented image where the minimal segments have been merged. An ecoding of uint32 is advised."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "minsize", "parameterName": "Minimum Segment Size", "dataType": "Int", "explanation": ["Minimum Segment Size. If, after the segmentation, a segment is of size lower than this criterion, the segment is merged with the segment that has the closest sepctral signature."]}, {"flag": "tilesizex", "parameterName": "Size of tiles in pixel (X-axis)", "dataType": "Int", "explanation": ["Size of tiles along the X-axis for tile-wise processing."]}, {"flag": "tilesizey", "parameterName": "Size of tiles in pixel (Y-axis)", "dataType": "Int", "explanation": ["Size of tiles along the Y-axis for tile-wise processing."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n Given a segmentation result (can be the out output parameter of the LSMSSegmentation application [2]) and the original image, it will merge segments whose size in pixels is lower than minsize parameter with the adjacent segments with the adjacent segment with closest radiometry and acceptable size. \n Small segments will be processed by increasing size: first all segments for which area is equal to 1 pixel will be merged with adjacent segments, then all segments of area equal to 2 pixels will be processed, until segments of area minsize. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results. \n The output of this application can be passed to the LSMSVectorization application [3] to complete the LSMS workflow. \n"},
{"name": "LSMSSegmentation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LSMSSegmentation.html", "label": "Exact Large", "category": "Segmentation", "definition": "This application performs the second step of the exact Large-Scale Mean-Shift segmentation workflow (LSMS) [1].", "authors": "This application has been written by David Youssefi.", "limitations": null, "example": ["otbcli_LSMSSegmentation - in smooth . tif - inpos position . tif - out segmentation . tif - spatialr 5 - ranger 15 - minsize 0 - tilesizex 256 - tilesizey 256", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LSMSSegmentation application LSMSSegmentation = otbApplication . Registry . CreateApplication ( \"LSMSSegmentation\" ) # The following lines set all the application parameters: LSMSSegmentation . SetParameterString ( \"in\" , \"smooth.tif\" ) LSMSSegmentation . SetParameterString ( \"inpos\" , \"position.tif\" ) LSMSSegmentation . SetParameterString ( \"out\" , \"segmentation.tif\" ) LSMSSegmentation . SetParameterFloat ( \"spatialr\" , 5 ) LSMSSegmentation . SetParameterFloat ( \"ranger\" , 15 ) LSMSSegmentation . SetParameterInt ( \"minsize\" , 0 ) LSMSSegmentation . SetParameterInt ( \"tilesizex\" , 256 ) LSMSSegmentation . SetParameterInt ( \"tilesizey\" , 256 ) # The following line execute the application LSMSSegmentation . ExecuteAndWriteOutput ()"], "command": "otbcli_LSMSSegmentation", "parameters": [{"flag": "in", "parameterName": "Filtered image", "dataType": "Input image", "explanation": ["The filtered image, corresponding to the fout output parameter of the MeanShiftSmoothing application."], "isInputFile": true}, {"flag": "inpos", "parameterName": "Filtered position image", "dataType": "Input image", "explanation": [" The filtered position image, corresponding to the foutpos output parameter of the MeanShiftSmoothing application."], "isInputFile": true}, {"flag": "out", "parameterName": "Output labeled Image", "dataType": "Output image", "explanation": ["This output contains the segmented image, where each pixel value is the unique integer label of the segment it belongs to. It is recommended to set the pixel type to uint32."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "spatialr", "parameterName": "Spatial radius", "dataType": "Float", "explanation": ["Threshold on Spatial distance to consider pixels in the same segment. A good value is half the spatial radius used in the MeanShiftSmoothing application (spatialr parameter)."]}, {"flag": "ranger", "parameterName": "Range radius", "dataType": "Float", "explanation": ["Threshold on spectral signature euclidean distance (expressed in radiometry unit) to consider pixels in the same segment. A good value is half the range radius used in the MeanShiftSmoothing application (ranger parameter)."]}, {"flag": "minsize", "parameterName": "Minimum Segment Size", "dataType": "Int", "explanation": ["Minimum Segment Size. If, after the segmentation, a segment is of size lower than this criterion, the segment is discarded."]}, {"flag": "tilesizex", "parameterName": "Size of tiles in pixel (X-axis)", "dataType": "Int", "explanation": ["Size of tiles along the X-axis for tile-wise processing."]}, {"flag": "tilesizey", "parameterName": "Size of tiles in pixel (Y-axis)", "dataType": "Int", "explanation": ["Size of tiles along the Y-axis for tile-wise processing."]}, {"flag": "tmpdir", "parameterName": "Directory where to write temporary files", "dataType": "Directory", "explanation": ["This applications need to write temporary files for each tile. This parameter allows choosing the path where to write those files. If disabled, the current path will be used."]}, {"flag": "cleanup", "parameterName": "Temporary files cleaning", "dataType": "Boolean", "explanation": ["If activated, the application will try to remove all temporary files it created."]}], "description": "\n   \n This application will produce a labeled image where neighbor pixels whose range distance is below range radius (and optionally spatial distance below spatial radius) will be grouped together into the same cluster. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results. \n Filtered range image and spatial image should be created with the MeanShiftSmoothing application outputs (fout and foutpos) [2], with modesearch parameter disabled. If spatial image is not set, the application will only process the range image and spatial radius parameter will not be taken into account. \n Please note that this application will generate a lot of temporary files (as many as the number of tiles), and will therefore require twice the size of the final result in term of disk space. The cleanup option (activated by default) allows removing all temporary file as soon as they are not needed anymore (if cleanup is activated, tmpdir set and tmpdir does not exists before running the application, it will be removed as well during cleanup). The tmpdir option allows defining a directory where to write the temporary files. \n Please also note that the output image type should be set to uint32 to ensure that there are enough labels available. \n The output of this application can be passed to the LSMSSmallRegionMerging [3] or LSMSVectorization [4] applications to complete the LSMS workflow. \n"},
{"name": "HooverCompareSegmentation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_HooverCompareSegmentation.html", "label": "Hoover compare segmentation", "category": "Segmentation", "definition": "Compare two segmentations with Hoover metrics", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_HooverCompareSegmentation - ingt maur_GT . tif - inms maur_labelled . tif - outgt maur_colored_GT . tif uint8", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the HooverCompareSegmentation application HooverCompareSegmentation = otbApplication . Registry . CreateApplication ( \"HooverCompareSegmentation\" ) # The following lines set all the application parameters: HooverCompareSegmentation . SetParameterString ( \"ingt\" , \"maur_GT.tif\" ) HooverCompareSegmentation . SetParameterString ( \"inms\" , \"maur_labelled.tif\" ) HooverCompareSegmentation . SetParameterString ( \"outgt\" , \"maur_colored_GT.tif\" ) HooverCompareSegmentation . SetParameterOutputImagePixelType ( \"outgt\" , 1 ) # The following line execute the application HooverCompareSegmentation . ExecuteAndWriteOutput ()"], "command": "otbcli_HooverCompareSegmentation", "parameters": [{"flag": "ingt", "parameterName": "Input ground truth", "dataType": "Input image", "explanation": ["A partial ground truth segmentation image."], "isInputFile": true}, {"flag": "inms", "parameterName": "Input machine segmentation", "dataType": "Input image", "explanation": ["A machine segmentation image."], "isInputFile": true}, {"flag": "outgt", "parameterName": "Colored ground truth output", "dataType": "Output image", "explanation": ["The colored ground truth output image."], "isOutputFile": true}, {"flag": "outms", "parameterName": "Colored machine segmentation output", "dataType": "Output image", "explanation": ["The colored machine segmentation output image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "bg", "parameterName": "Background label", "dataType": "Int", "explanation": ["Label value of the background in the input segmentations."]}, {"flag": "th", "parameterName": "Overlapping threshold", "dataType": "Float", "explanation": ["Overlapping threshold used to find Hoover instances."]}, {"flag": "rc", "parameterName": "Correct detection score", "dataType": "Float", "explanation": ["Overall score for correct detection (RC)."]}, {"flag": "rf", "parameterName": "Over-segmentation score", "dataType": "Float", "explanation": ["Overall score for over segmentation (RF)."]}, {"flag": "ra", "parameterName": "Under-segmentation score", "dataType": "Float", "explanation": ["Overall score for under segmentation (RA)."]}, {"flag": "rm", "parameterName": "Missed detection score", "dataType": "Float", "explanation": ["Overall score for missed detection (RM)."]}], "description": "\n   \n \n This application compares a machine segmentation (MS) with a partial ground truth segmentation (GT). The Hoover metrics are used to estimate scores for correct detection, over-segmentation, under-segmentation and missed detection. \n The application can output the overall Hoover scores along with coloredimages of the MS and GT segmentation showing the state of each region (correct detection, over-segmentation, under-segmentation, missed)\nThe Hoover metrics are described in : Hoover et al., \u201cAn experimental comparison of range image segmentation algorithms\u201d, IEEE PAMI vol. 18, no. 7, July 1996. \n \n"},
{"name": "ConnectedComponentSegmentation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ConnectedComponentSegmentation.html", "label": "Connected Component Segmentation", "category": "Segmentation", "definition": "Connected component segmentation and object based image filtering of the input image according to user-defined criterions.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ConnectedComponentSegmentation - in ROI_QB_MUL_4 . tif - mask \"((b1>80)*intensity>95)\" - expr \"distance<10\" - minsize 15 - obia \"SHAPE_Elongation>8\" - out ConnectedComponentSegmentation . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ConnectedComponentSegmentation application ConnectedComponentSegmentation = otbApplication . Registry . CreateApplication ( \"ConnectedComponentSegmentation\" ) # The following lines set all the application parameters: ConnectedComponentSegmentation . SetParameterString ( \"in\" , \"ROI_QB_MUL_4.tif\" ) ConnectedComponentSegmentation . SetParameterString ( \"mask\" , \"((b1>80)*intensity>95)\" ) ConnectedComponentSegmentation . SetParameterString ( \"expr\" , \"distance<10\" ) ConnectedComponentSegmentation . SetParameterInt ( \"minsize\" , 15 ) ConnectedComponentSegmentation . SetParameterString ( \"obia\" , \"SHAPE_Elongation>8\" ) ConnectedComponentSegmentation . SetParameterString ( \"out\" , \"ConnectedComponentSegmentation.shp\" ) # The following line execute the application ConnectedComponentSegmentation . ExecuteAndWriteOutput ()"], "command": "otbcli_ConnectedComponentSegmentation", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Shape", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "mask", "parameterName": "Mask expression", "dataType": "String", "explanation": []}, {"flag": "expr", "parameterName": "Connected Component Expression", "dataType": "String", "explanation": []}, {"flag": "minsize", "parameterName": "Minimum Object Size", "dataType": "Int", "explanation": []}, {"flag": "obia", "parameterName": "OBIA Expression", "dataType": "String", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application allows one to perform a masking, connected components segmentation and object based image filtering. First and optionally, a mask can be built based on user-defined criterions to select pixels of the image which will be segmented. Then a connected component segmentation is performed with a user defined criterion to decide whether two neighbouring pixels belong to the same segment or not. After this segmentation step, an object based image filtering is applied using another user-defined criterion reasoning on segment properties, like shape or radiometric attributes. Criterions are mathematical expressions analysed by the MuParser library ( http://muparser.sourceforge.net/ ). For instance, expression \u201c((b1>80) and intensity>95)\u201d will merge two neighbouring pixel in a single segment if their intensity is more than 95 and their value in the first image band is more than 80. See parameters documentation for a list of available attributes. The output of the object based image filtering is vectorized and can be written in shapefile or KML format. If the input image is in raw geometry, resulting polygons will be transformed to WGS84 using sensor modelling before writing, to ensure consistency with GIS software. For this purpose, a Digital Elevation Model can be provided to the application. The whole processing is done on a per-tile basis for large images, so this application can handle images of arbitrary size. \n"},
{"name": "ComputeOGRLayersFeaturesStatistics", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ComputeOGRLayersFeaturesStatistics.html", "label": "ComputeOGRLayersFeaturesStatistics", "category": "Segmentation", "definition": "Compute statistics of the features in a set of OGR Layers", "authors": "This application has been written by David Youssefi during internship at CNES.", "limitations": null, "example": ["otbcli_ComputeOGRLayersFeaturesStatistics - inshp vectorData . shp - outstats results . xml - feat perimeter", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ComputeOGRLayersFeaturesStatistics application ComputeOGRLayersFeaturesStatistics = otbApplication . Registry . CreateApplication ( \"ComputeOGRLayersFeaturesStatistics\" ) # The following lines set all the application parameters: ComputeOGRLayersFeaturesStatistics . SetParameterString ( \"inshp\" , \"vectorData.shp\" ) ComputeOGRLayersFeaturesStatistics . SetParameterString ( \"outstats\" , \"results.xml\" ) # The following line execute the application ComputeOGRLayersFeaturesStatistics . ExecuteAndWriteOutput ()"], "command": "otbcli_ComputeOGRLayersFeaturesStatistics", "parameters": [{"flag": "inshp", "parameterName": "Vector Data", "dataType": "Input vector data", "explanation": ["Name of the input shapefile."], "isInputFile": true}, {"flag": "outstats", "parameterName": "Output XML file", "dataType": "Output File name", "explanation": ["XML file containing mean and variance of each feature."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "feat", "parameterName": "Feature", "dataType": "List", "explanation": ["List of features to consider for statistics."]}], "description": "\n   \n Compute statistics (mean and standard deviation) of the features in a set of OGR Layers, and write them in an XML file. This XML file can then be used by the training application. \n"},
{"name": "SARPolarSynth", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SARPolarSynth.html", "label": "SARPolarSynth", "category": "SAR", "definition": "Gives, for each pixel, the power that would have been received by a SAR system with a basis different from the classical (H,V) one (polarimetric synthetis).", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SARPolarSynth - in sar . tif - psii 15. - khii 5. - psir - 25. - khir 10. - out newbasis . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SARPolarSynth application SARPolarSynth = otbApplication . Registry . CreateApplication ( \"SARPolarSynth\" ) # The following lines set all the application parameters: SARPolarSynth . SetParameterString ( \"in\" , \"sar.tif\" ) SARPolarSynth . SetParameterFloat ( \"psii\" , 15. ) SARPolarSynth . SetParameterFloat ( \"khii\" , 5. ) SARPolarSynth . SetParameterFloat ( \"psir\" , - 25. ) SARPolarSynth . SetParameterFloat ( \"khir\" , 10. ) SARPolarSynth . SetParameterString ( \"out\" , \"newbasis.tif\" ) # The following line execute the application SARPolarSynth . ExecuteAndWriteOutput ()"], "command": "otbcli_SARPolarSynth", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["Input image."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "psii", "parameterName": "psii", "dataType": "Float", "explanation": ["Orientation (transmitting antenna)."]}, {"flag": "khii", "parameterName": "khii", "dataType": "Float", "explanation": ["Ellipticity (transmitting antenna)."]}, {"flag": "psir", "parameterName": "psir", "dataType": "Float", "explanation": ["Orientation (receiving antenna)."]}, {"flag": "khir", "parameterName": "khir", "dataType": "Float", "explanation": ["Ellipticity (receiving antenna)."]}, {"flag": "emissionh", "parameterName": "Emission H", "dataType": "Int", "explanation": ["This parameter is useful in determining the polarization architecture (dual polarization case)."]}, {"flag": "emissionv", "parameterName": "Emission V", "dataType": "Int", "explanation": ["This parameter is useful in determining the polarization architecture (dual polarization case)."]}, {"flag": "mode", "parameterName": "Forced mode", "dataType": "Choices", "availableChoices": [{"choice": "none", "description": ["Copolarization."]}, {"choice": "co", "description": []}, {"choice": "cross", "description": ["Crosspolarization."]}], "explanation": [" Available choices are:"]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application gives, for each pixel, the power that would have been received by a SAR system with a basis different from the classical (H,V) one (polarimetric synthetis).\nThe new basis A and B are indicated through two Jones vectors, defined by the user thanks to orientation (psi) and ellipticity (khi) parameters.\nThese parameters are namely psii, khii, psir and khir. The suffixes (i) and (r) refer to the transmitting antenna and the receiving antenna respectively.\nOrientations and ellipticities are given in degrees, and are between -90/90 degrees and -45/45 degrees respectively. \n Four polarization architectures can be processed : \n \n HH_HV_VH_VV : full polarization, general bistatic case. \n HH_HV_VV or HH_VH_VV : full polarization, monostatic case (transmitter and receiver are co-located). \n HH_HV : dual polarization. \n VH_VV : dual polarization. \n \n The application takes a complex vector image as input, where each band correspond to a particular emission/reception polarization scheme.\nUser must comply with the band order given above, since the bands are used to build the Sinclair matrix. \n In order to determine the architecture, the application first relies on the number of bands of the input image. \n \n Architecture HH_HV_VH_VV is the only one with four bands, there is no possible confusion. \n Concerning HH_HV_VV and HH_VH_VV architectures, both correspond to a three channels image. But they are processed in the same way, as the Sinclair matrix is symmetric in the monostatic case. \n Finally, the two last architectures (dual polarizations), can\u2019t be distinguished only by the number of bands of the input image. User must then use the parameters emissionh and emissionv to indicate the architecture of the system : emissionh=1 and emissionv=0 \u2013> HH_HV,  emissionh=0 and emissionv=1 \u2013> VH_VV. \n \n Note : if the architecture is HH_HV, khii and psii are automatically both set to 0 degree; if the architecture is VH_VV, khii and psii are automatically set to 0 degree and 90 degrees respectively. \n It is also possible to force the calculation to co-polar or cross-polar modes.\nIn the co-polar case, values for psir and khir will be ignored and forced to psii and khii; same as the cross-polar mode, where khir and psir will be forced to (psii + 90 degrees) and -khii. \n Finally, the result of the polarimetric synthetis is expressed in the power domain, through a one-band scalar image.\nNote: this application doesn\u2019t take into account the terms which do not depend on the polarization of the antennas.\nThe parameter gain can be used for this purpose. \n More details can be found in the OTB CookBook (SAR processing chapter). \n"},
{"name": "SARPolarMatrixConvert", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SARPolarMatrixConvert.html", "label": "SARPolarMatrixConvert", "category": "SAR", "definition": "This applications allows converting classical polarimetric matrices to each other.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SARPolarMatrixConvert - inhh HH . tif - invh VH . tif - invv VV . tif - conv msinclairtocoherency - outc mcoherency . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SARPolarMatrixConvert application SARPolarMatrixConvert = otbApplication . Registry . CreateApplication ( \"SARPolarMatrixConvert\" ) # The following lines set all the application parameters: SARPolarMatrixConvert . SetParameterString ( \"inhh\" , \"HH.tif\" ) SARPolarMatrixConvert . SetParameterString ( \"invh\" , \"VH.tif\" ) SARPolarMatrixConvert . SetParameterString ( \"invv\" , \"VV.tif\" ) SARPolarMatrixConvert . SetParameterString ( \"conv\" , \"msinclairtocoherency\" ) SARPolarMatrixConvert . SetParameterString ( \"outc\" , \"mcoherency.tif\" ) # The following line execute the application SARPolarMatrixConvert . ExecuteAndWriteOutput ()"], "command": "otbcli_SARPolarMatrixConvert", "parameters": [{"flag": "inc", "parameterName": "Input : multi-band complex image", "dataType": "Input image", "explanation": ["Input : multi-band complex image."], "isInputFile": true}, {"flag": "inf", "parameterName": "Input : multi-band real image", "dataType": "Input image", "explanation": ["Input : multi-band real image."], "isInputFile": true}, {"flag": "inhh", "parameterName": "Input : one-band complex image (HH)", "dataType": "Input image", "explanation": ["Input : one-band complex image (HH)."], "isInputFile": true}, {"flag": "inhv", "parameterName": "Input : one-band complex image (HV)", "dataType": "Input image", "explanation": ["Input : one-band complex image (HV)."], "isInputFile": true}, {"flag": "invh", "parameterName": "Input : one-band complex image (VH)", "dataType": "Input image", "explanation": ["Input : one-band complex image (VH)."], "isInputFile": true}, {"flag": "invv", "parameterName": "Input : one-band complex image (VV)", "dataType": "Input image", "explanation": ["Input : one-band complex image (VV)."], "isInputFile": true}, {"flag": "outc", "parameterName": "Output Complex Image", "dataType": "Output image", "explanation": ["Output Complex image."], "isOutputFile": true}, {"flag": "outf", "parameterName": "Output Real Image", "dataType": "Output image", "explanation": ["Output Real image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "conv", "parameterName": "Conversion", "dataType": "Choices", "availableChoices": [{"choice": "msinclairtocoherency", "description": ["1 Monostatic :Sinclair matrix to coherency matrix (complex output)."]}, {"choice": "msinclairtocovariance", "description": ["2 Monostatic : Sinclair matrix to covariance matrix (complex output)."]}, {"choice": "msinclairtocircovariance", "description": ["3 Monostatic : Sinclair matrix to circular covariance matrix (complex output)."]}, {"choice": "mcoherencytomueller", "description": ["4 Monostatic : Coherency matrix to Mueller matrix."]}, {"choice": "mcovariancetocoherencydegree", "description": ["5 Monostatic : Covariance matrix to coherency degree ."]}, {"choice": "mcovariancetocoherency", "description": ["6 Monostatic : Covariance matrix to coherency matrix (complex output)."]}, {"choice": "mlinearcovariancetocircularcovariance", "description": ["7 Monostatic : Covariance matrix to circular covariance matrix (complex output)."]}, {"choice": "muellertomcovariance", "description": ["8 Bi/mono : Mueller matrix to monostatic covariance matrix."]}, {"choice": "bsinclairtocoherency", "description": ["9 Bistatic : Sinclair matrix to coherency matrix (complex output)."]}, {"choice": "bsinclairtocovariance", "description": ["10 Bistatic : Sinclair matrix to covariance matrix (complex output)."]}, {"choice": "bsinclairtocircovariance", "description": ["11 Bistatic : Sinclair matrix to circular covariance matrix (complex output)."]}, {"choice": "sinclairtomueller", "description": ["12 Bi/mono : Sinclair matrix to Mueller matrix."]}, {"choice": "muellertopoldegandpower", "description": ["13 Bi/mono : Mueller matrix to polarisation degree and power."]}], "explanation": [" Available choices are:"]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application allows converting classical polarimetric matrices to each other.\nFor instance, it is possible to get the coherency matrix from the Sinclar one, or the Mueller matrix from the coherency one.\nThe filters used in this application never handle matrices, but images where each band is related to their elements.\nAs most of the time SAR polarimetry handles symmetric/hermitian matrices, only the relevant elements are stored, so that the images representing them have a minimal number of bands.\nFor instance, the coherency matrix size is 3x3 in the monostatic case, and 4x4 in the bistatic case : it will thus be stored in a 6-band or a 10-band complex image (the diagonal and the upper elements of the matrix). \n The Sinclair matrix is a special case : it is always represented as 3 or 4 one-band complex images (for mono- or bistatic case).\nThe available conversions are listed below: \n \u2014 Monostatic case \u2014\n1 msinclairtocoherency \u2013> Sinclair matrix to coherency matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)\n2 msinclairtocovariance \u2013> Sinclair matrix to covariance matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)\n3 msinclairtocircovariance \u2013> Sinclair matrix to circular covariance matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)\n4 mcoherencytomueller \u2013> Coherency matrix to Mueller matrix (input : 6 complex channels | 16 real channels)\n5 mcovariancetocoherencydegree \u2013> Covariance matrix to coherency degree (input : 6 complex channels | 3 complex channels)\n6 mcovariancetocoherency \u2013> Covariance matrix to coherency matrix (input : 6 complex channels | 6 complex channels)\n7 mlinearcovariancetocircularcovariance \u2013> Covariance matrix to circular covariance matrix (input : 6 complex channels | output : 6 complex channels) \n \u2014 Bistatic case \u2014\n8 bsinclairtocoherency \u2013> Sinclair matrix to coherency matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | 10 complex channels)\n9 bsinclairtocovariance \u2013> Sinclair matrix to covariance matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 10 complex channels)\n10 bsinclairtocircovariance \u2013> Sinclair matrix to circular covariance matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 10 complex channels) \n \u2014 Both cases \u2014\n11 sinclairtomueller \u2013> Sinclair matrix to Mueller matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 16 real channels)\n12 muellertomcovariance \u2013> Mueller matrix to covariance matrix (input : 16 real channels | output : 6 complex channels)\n13 muellertopoldegandpower \u2013> Mueller matrix to polarization degree and power (input : 16 real channels | output : 4 real channels) \n"},
{"name": "SARDecompositions", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SARDecompositions.html", "label": "SARDecompositions", "category": "SAR", "definition": "From one-band complex images (each one related to an element of the Sinclair matrix), returns the selected decomposition.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SARDecompositions - inhh HH . tif - invh VH . tif - invv VV . tif - decomp haa - out HaA . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SARDecompositions application SARDecompositions = otbApplication . Registry . CreateApplication ( \"SARDecompositions\" ) # The following lines set all the application parameters: SARDecompositions . SetParameterString ( \"inhh\" , \"HH.tif\" ) SARDecompositions . SetParameterString ( \"invh\" , \"VH.tif\" ) SARDecompositions . SetParameterString ( \"invv\" , \"VV.tif\" ) SARDecompositions . SetParameterString ( \"decomp\" , \"haa\" ) SARDecompositions . SetParameterString ( \"out\" , \"HaA.tif\" ) # The following line execute the application SARDecompositions . ExecuteAndWriteOutput ()"], "command": "otbcli_SARDecompositions", "parameters": [{"flag": "inhh", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inhv", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "invh", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "invv", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "decomp", "parameterName": "Decompositions", "dataType": "Choices", "availableChoices": [{"choice": "haa", "description": ["H-alpha-A incoherent decomposition."]}, {"choice": "barnes", "description": ["Barnes incoherent decomposition."]}, {"choice": "huynen", "description": ["Huynen incoherent decomposition."]}, {"choice": "pauli", "description": ["Pauli coherent decomposition."]}], "explanation": []}, {"flag": "inco.kernelsize", "parameterName": "Kernel size for spatial incoherent averaging.", "dataType": "Int", "explanation": ["Minute (0-59)."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n From one-band complex images (HH, HV, VH, VV), returns the selected decomposition. \n All the decompositions implemented are intended for the mono-static case (transmitter and receiver are co-located).\nThere are two kinds of decomposition : coherent ones and incoherent ones.\nIn the coherent case, only the Pauli decomposition is available.\nIn the incoherent case, there the decompositions available : Huynen, Barnes, and H-alpha-A.\nUser must provide three one-band complex images HH, HV or VH, and VV (mono-static case <=> HV = VH).\nIncoherent decompositions consist in averaging 3x3 complex coherency/covariance matrices; the user must provide the size of the averaging window, thanks to the parameter inco.kernelsize. \n"},
{"name": "SARDeburst", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SARDeburst.html", "label": "SAR Deburst", "category": "SAR", "definition": "This application performs deburst of Sentinel1 IW SLC images by removing redundant lines.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SARDeburst - in s1_iw_slc . tif - out s1_iw_slc_deburst . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SARDeburst application SARDeburst = otbApplication . Registry . CreateApplication ( \"SARDeburst\" ) # The following lines set all the application parameters: SARDeburst . SetParameterString ( \"in\" , \"s1_iw_slc.tif\" ) SARDeburst . SetParameterString ( \"out\" , \"s1_iw_slc_deburst.tif\" ) # The following line execute the application SARDeburst . ExecuteAndWriteOutput ()"], "command": "otbcli_SARDeburst", "parameters": [{"flag": "in", "parameterName": "Input Sentinel1 IW SLC Image", "dataType": "Input image", "explanation": ["Raw Sentinel1 IW SLC image, or any extract of such made by OTB (geom file needed)."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Deburst image, with updated geom file that can be further used by Orthorectification application. If the input image is a raw Sentinel1 product, uint16 output type should be used (encoding of S1 product). Otherwise, output type should match type of input image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n Sentinel1 IW SLC products are composed of several burst overlapping in azimuth time for each subswath, separated by black lines [1]. The deburst operation consist in generating a continuous image in terms of azimuth time, by removing black separation lines as well as redundant lines between bursts. \n Note that the output sensor model is updated accordingly. This deburst operation is the perfect preprocessing step to orthorectify S1 IW SLC product with OTB [2] without suffering from artifacts caused by bursts separation. \n"},
{"name": "ComputeModulusAndPhase", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ComputeModulusAndPhase.html", "label": "Compute Modulus And Phase", "category": "SAR", "definition": "This application computes the modulus and the phase of a complex SAR image.", "authors": "This application has been written by Alexia Mondot (", "limitations": null, "example": ["otbcli_ComputeModulusAndPhase - in monobandComplexFloat . tif - modulus modulus . tif - phase phase . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ComputeModulusAndPhase application ComputeModulusAndPhase = otbApplication . Registry . CreateApplication ( \"ComputeModulusAndPhase\" ) # The following lines set all the application parameters: ComputeModulusAndPhase . SetParameterString ( \"in\" , \"monobandComplexFloat.tif\" ) ComputeModulusAndPhase . SetParameterString ( \"modulus\" , \"modulus.tif\" ) ComputeModulusAndPhase . SetParameterString ( \"phase\" , \"phase.tif\" ) # The following line execute the application ComputeModulusAndPhase . ExecuteAndWriteOutput ()"], "command": "otbcli_ComputeModulusAndPhase", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["Input image (complex single band)."], "isInputFile": true}, {"flag": "modulus", "parameterName": "Modulus", "dataType": "Output image", "explanation": ["Modulus of the input image computes with the following formula: "], "isOutputFile": true}, {"flag": "phase", "parameterName": "Phase", "dataType": "Output image", "explanation": ["Phase of the input image computes with the following formula:  "], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application computes the modulus and the phase of a complex SAR image. The input should be a single band image with complex pixels. \n"},
{"name": "TileFusion", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_TileFusion.html", "label": "Image Tile Fusion", "category": "Image Manipulation", "definition": "Fusion of an image made of several tile files.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_TileFusion - il Scene_R1C1 . tif Scene_R1C2 . tif Scene_R2C1 . tif Scene_R2C2 . tif - cols 2 - rows 2 - out EntireImage . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the TileFusion application TileFusion = otbApplication . Registry . CreateApplication ( \"TileFusion\" ) # The following lines set all the application parameters: TileFusion . SetParameterStringList ( \"il\" , [ 'Scene_R1C1.tif' , 'Scene_R1C2.tif' , 'Scene_R2C1.tif' , 'Scene_R2C2.tif' ]) TileFusion . SetParameterInt ( \"cols\" , 2 ) TileFusion . SetParameterInt ( \"rows\" , 2 ) TileFusion . SetParameterString ( \"out\" , \"EntireImage.tif\" ) # The following line execute the application TileFusion . ExecuteAndWriteOutput ()"], "command": "otbcli_TileFusion", "parameters": [{"flag": "il", "parameterName": "Input Tile Images", "dataType": "Input image list", "explanation": ["Input images to concatenate (in lexicographic order, for instance : (0,0) (1,0) (0,1) (1,1))."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output entire image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "cols", "parameterName": "Number of tile columns", "dataType": "Int", "explanation": ["Number of columns in the tile array."]}, {"flag": "rows", "parameterName": "Number of tile rows", "dataType": "Int", "explanation": ["Number of rows in the tile array."]}], "description": "\n   \n Automatically mosaic a set of non overlapping tile files into a single image. Images must have a matching number of bands and they must be listed in lexicographic order. \n"},
{"name": "SplitImage", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SplitImage.html", "label": "Split Image", "category": "Image Manipulation", "definition": "Split a N multiband image into N images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SplitImage - in VegetationIndex . hd - out splitImage . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SplitImage application SplitImage = otbApplication . Registry . CreateApplication ( \"SplitImage\" ) # The following lines set all the application parameters: SplitImage . SetParameterString ( \"in\" , \"VegetationIndex.hd\" ) SplitImage . SetParameterString ( \"out\" , \"splitImage.tif\" ) # The following line execute the application SplitImage . ExecuteAndWriteOutput ()"], "command": "otbcli_SplitImage", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["Input multiband image filename."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output filename will be used to get the prefix an the extension of the output written\u2019s image. For example with outimage.tif as output filename, the generated images will had an indice (corresponding at each bands) between the prefix and the extension, such as: outimage_0.tif  and outimage_1.tif (if 2 bands)."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application splits a N-bands image into N mono-band images. The output images filename will be generated from the output parameter. Thus, if the input image has 2 channels, and the user has set as output parameter, outimage.tif, the generated images will be outimage_0.tif and outimage_1.tif. \n"},
{"name": "ReadImageInfo", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ReadImageInfo.html", "label": "Read image information", "category": "Image Manipulation", "definition": "Get information about the image", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ReadImageInfo - in QB_Toulouse_Ortho_XS . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ReadImageInfo application ReadImageInfo = otbApplication . Registry . CreateApplication ( \"ReadImageInfo\" ) # The following lines set all the application parameters: ReadImageInfo . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) # The following line execute the application ReadImageInfo . ExecuteAndWriteOutput ()"], "command": "otbcli_ReadImageInfo", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "outkwl", "parameterName": "Write the OSSIM keywordlist to a geom file", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "keywordlist", "parameterName": "Display the OSSIM keywordlist", "dataType": "Boolean", "explanation": []}, {"flag": "indexx", "parameterName": "Start index X", "dataType": "Int", "explanation": []}, {"flag": "indexy", "parameterName": "Start index Y", "dataType": "Int", "explanation": []}, {"flag": "sizex", "parameterName": "Size X", "dataType": "Int", "explanation": []}, {"flag": "sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": []}, {"flag": "spacingx", "parameterName": "Pixel Size X", "dataType": "Float", "explanation": []}, {"flag": "spacingy", "parameterName": "Pixel Size Y", "dataType": "Float", "explanation": []}, {"flag": "originx", "parameterName": "Image Origin X", "dataType": "Float", "explanation": []}, {"flag": "originy", "parameterName": "Image Origin Y", "dataType": "Float", "explanation": []}, {"flag": "estimatedgroundspacingx", "parameterName": "Estimated ground spacing X", "dataType": "Float", "explanation": []}, {"flag": "estimatedgroundspacingy", "parameterName": "Estimated ground spacing Y", "dataType": "Float", "explanation": []}, {"flag": "numberbands", "parameterName": "Number Of Bands", "dataType": "Int", "explanation": []}, {"flag": "sensor", "parameterName": "Sensor id", "dataType": "String", "explanation": []}, {"flag": "id", "parameterName": "Image id", "dataType": "String", "explanation": []}, {"flag": "time", "parameterName": "Acquisition time", "dataType": "String", "explanation": []}, {"flag": "ullat", "parameterName": "Upper left latitude", "dataType": "Float", "explanation": []}, {"flag": "ullon", "parameterName": "Upper left longitude", "dataType": "Float", "explanation": []}, {"flag": "urlat", "parameterName": "Upper right latitude", "dataType": "Float", "explanation": []}, {"flag": "urlon", "parameterName": "Upper right longitude", "dataType": "Float", "explanation": []}, {"flag": "lrlat", "parameterName": "Lower right latitude", "dataType": "Float", "explanation": []}, {"flag": "lrlon", "parameterName": "Lower right longitude", "dataType": "Float", "explanation": []}, {"flag": "lllat", "parameterName": "Lower left latitude", "dataType": "Float", "explanation": []}, {"flag": "lllon", "parameterName": "Lower left longitude", "dataType": "Float", "explanation": []}, {"flag": "town", "parameterName": "Nearest town", "dataType": "String", "explanation": []}, {"flag": "country", "parameterName": "Country", "dataType": "String", "explanation": []}, {"flag": "rgb.r", "parameterName": "Red Band", "dataType": "Int", "explanation": ["Red band Number."]}, {"flag": "rgb.g", "parameterName": "Green Band", "dataType": "Int", "explanation": ["Green band Number."]}, {"flag": "rgb.b", "parameterName": "Blue Band", "dataType": "Int", "explanation": ["Blue band Number."]}, {"flag": "projectionref", "parameterName": "Projection", "dataType": "String", "explanation": []}, {"flag": "keyword", "parameterName": "Keywordlist", "dataType": "String", "explanation": []}, {"flag": "gcp.count", "parameterName": "GCPs Number", "dataType": "Int", "explanation": ["Number of GCPs."]}, {"flag": "gcp.proj", "parameterName": "GCP Projection", "dataType": "String", "explanation": ["Projection Coordinate System for GCPs."]}, {"flag": "gcp.ids", "parameterName": "GCPs Id", "dataType": "String list", "explanation": ["GCPs identifier."]}, {"flag": "gcp.info", "parameterName": "GCPs Info", "dataType": "String list", "explanation": ["GCPs Information."]}, {"flag": "gcp.imcoord", "parameterName": "GCPs Image Coordinates", "dataType": "String list", "explanation": ["GCPs Image coordinates."]}, {"flag": "gcp.geocoord", "parameterName": "GCPs Geographic Coordinates", "dataType": "String list", "explanation": ["GCPs Geographic Coordinates."]}], "description": "\n   \n Display information about the input image like: image size, origin, spacing, metadata, projections... \n"},
{"name": "Quicklook", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Quicklook.html", "label": "Quick Look", "category": "Image Manipulation", "definition": "Generates a subsampled version of an image extract", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Quicklook - in qb_RoadExtract . tif - out quicklookImage . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Quicklook application Quicklook = otbApplication . Registry . CreateApplication ( \"Quicklook\" ) # The following lines set all the application parameters: Quicklook . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) Quicklook . SetParameterString ( \"out\" , \"quicklookImage.tif\" ) # The following line execute the application Quicklook . ExecuteAndWriteOutput ()"], "command": "otbcli_Quicklook", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The image to read."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The subsampled image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "cl", "parameterName": "Channel List", "dataType": "List", "explanation": ["Selected channels."]}, {"flag": "rox", "parameterName": "ROI Origin X", "dataType": "Int", "explanation": ["first point of ROI in x-direction."]}, {"flag": "roy", "parameterName": "ROI Origin Y", "dataType": "Int", "explanation": ["first point of ROI in y-direction."]}, {"flag": "rsx", "parameterName": "ROI Size X", "dataType": "Int", "explanation": ["size of ROI in x-direction."]}, {"flag": "rsy", "parameterName": "ROI Size Y", "dataType": "Int", "explanation": ["size of ROI in y-direction."]}, {"flag": "sr", "parameterName": "Sampling ratio", "dataType": "Int", "explanation": ["Sampling Ratio, default is 2."]}, {"flag": "sx", "parameterName": "Size X", "dataType": "Int", "explanation": ["quicklook size in x-direction (used if no sampling ration is given)."]}, {"flag": "sy", "parameterName": "Size Y", "dataType": "Int", "explanation": ["quicklook size in y-direction (used if no sampling ration is given)."]}], "description": "\n   \n \n Generates a subsampled version of an extract of an image defined by ROIStart and ROISize. \n This extract is subsampled using the ratio OR the output image Size. \n \n"},
{"name": "MultiResolutionPyramid", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MultiResolutionPyramid.html", "label": "Multi Resolution Pyramid", "category": "Image Manipulation", "definition": "Build a multi-resolution pyramid of the image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MultiResolutionPyramid - in QB_Toulouse_Ortho_XS . tif - out multiResolutionImage . tif - level 1 - sfactor 2 - vfactor 0.6 - fast false", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MultiResolutionPyramid application MultiResolutionPyramid = otbApplication . Registry . CreateApplication ( \"MultiResolutionPyramid\" ) # The following lines set all the application parameters: MultiResolutionPyramid . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) MultiResolutionPyramid . SetParameterString ( \"out\" , \"multiResolutionImage.tif\" ) MultiResolutionPyramid . SetParameterInt ( \"level\" , 1 ) MultiResolutionPyramid . SetParameterInt ( \"sfactor\" , 2 ) MultiResolutionPyramid . SetParameterFloat ( \"vfactor\" , 0.6 ) MultiResolutionPyramid . SetParameterString ( \"fast\" , \"false\" ) # The following line execute the application MultiResolutionPyramid . ExecuteAndWriteOutput ()"], "command": "otbcli_MultiResolutionPyramid", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["will be used to get the prefix and the extension of the images to write."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "level", "parameterName": "Number Of Levels", "dataType": "Int", "explanation": ["Number of levels in the pyramid (default is 1)."]}, {"flag": "sfactor", "parameterName": "Subsampling factor", "dataType": "Int", "explanation": ["Subsampling factor between each level of the pyramid (default is 2)."]}, {"flag": "vfactor", "parameterName": "Variance factor", "dataType": "Float", "explanation": ["Variance factor use in smoothing. It is multiplied by the subsampling factor of each level in the  pyramid (default is 0.6)."]}, {"flag": "fast", "parameterName": "Use Fast Scheme", "dataType": "Boolean", "explanation": ["If used, this option allows one to speed-up computation by iteratively subsampling previous level of pyramid instead of processing the full input."]}], "description": "\n   \n This application builds a multi-resolution pyramid of the input image. User can specified the number of levels of the pyramid and the subsampling factor. To speed up the process, you can use the fast scheme option \n"},
{"name": "ManageNoData", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ManageNoData.html", "label": "No Data management", "category": "Image Manipulation", "definition": "Manage No-Data", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ManageNoData - in QB_Toulouse_Ortho_XS . tif - out QB_Toulouse_Ortho_XS_nodatamask . tif uint8 - mode . buildmask . inv 255 - mode . buildmask . outv 0", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ManageNoData application ManageNoData = otbApplication . Registry . CreateApplication ( \"ManageNoData\" ) # The following lines set all the application parameters: ManageNoData . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) ManageNoData . SetParameterString ( \"out\" , \"QB_Toulouse_Ortho_XS_nodatamask.tif\" ) ManageNoData . SetParameterOutputImagePixelType ( \"out\" , 1 ) ManageNoData . SetParameterFloat ( \"mode.buildmask.inv\" , 255 ) ManageNoData . SetParameterFloat ( \"mode.buildmask.outv\" , 0 ) # The following line execute the application ManageNoData . ExecuteAndWriteOutput ()"], "command": "otbcli_ManageNoData", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "mode.apply.mask", "parameterName": "Mask image", "dataType": "Input image", "explanation": ["Mask to be applied on input image (valid pixels have non null values)."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "usenan", "parameterName": "Consider NaN as no-data", "dataType": "Boolean", "explanation": []}, {"flag": "mode", "parameterName": "No-data handling mode", "dataType": "Choices", "availableChoices": [{"choice": "buildmask", "description": []}, {"choice": "changevalue", "description": []}, {"choice": "apply", "description": ["Apply an external mask to an image using the no-data value of the input image."]}], "explanation": []}, {"flag": "mode.buildmask.inv", "parameterName": "Inside Value", "dataType": "Float", "explanation": ["Value given in the output mask to pixels that are not no data pixels."]}, {"flag": "mode.buildmask.outv", "parameterName": "Outside Value", "dataType": "Float", "explanation": ["Value given in the output mask to pixels that are no data pixels."]}, {"flag": "mode.changevalue.newv", "parameterName": "The new no-data value", "dataType": "Float", "explanation": ["The new no-data value."]}, {"flag": "mode.apply.ndval", "parameterName": "Nodata value used", "dataType": "Float", "explanation": ["No Data value used according to the mask image."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application has two modes. The first allows building a mask of no-data pixels from the no-data flags read from the image file. The second allows updating the change the no-data value of an image (pixels value and metadata). This last mode also allows replacing NaN in images with a proper no-data value. To do so, one should activate the NaN is no-data option. \n"},
{"name": "ExtractROI", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ExtractROI.html", "label": "Extract ROI", "category": "Image Manipulation", "definition": "Extract a ROI defined by the user.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ExtractROI - in VegetationIndex . hd - mode extent - mode . extent . ulx 40 - mode . extent . uly 40 - mode . extent . lrx 150 - mode . extent . lry 150 - out ExtractROI . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ExtractROI application ExtractROI = otbApplication . Registry . CreateApplication ( \"ExtractROI\" ) # The following lines set all the application parameters: ExtractROI . SetParameterString ( \"in\" , \"VegetationIndex.hd\" ) ExtractROI . SetParameterString ( \"mode\" , \"extent\" ) ExtractROI . SetParameterFloat ( \"mode.extent.ulx\" , 40 ) ExtractROI . SetParameterFloat ( \"mode.extent.uly\" , 40 ) ExtractROI . SetParameterFloat ( \"mode.extent.lrx\" , 150 ) ExtractROI . SetParameterFloat ( \"mode.extent.lry\" , 150 ) ExtractROI . SetParameterString ( \"out\" , \"ExtractROI.tif\" ) # The following line execute the application ExtractROI . ExecuteAndWriteOutput ()"], "command": "otbcli_ExtractROI", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "mode.fit.im", "parameterName": "Reference image", "dataType": "Input image", "explanation": ["Reference image to define the ROI."], "isInputFile": true}, {"flag": "mode.fit.vect", "parameterName": "Reference vector", "dataType": "Input vector data", "explanation": ["The extent of the input vector file is computed and then gives a region of interest that will be extracted."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "mode", "parameterName": "Extraction mode", "dataType": "Choices", "availableChoices": [{"choice": "standard", "description": ["In standard mode extraction is done with 2 parameters : the upper left corner and the size of the region, decomposed in X and Y coordinates."]}, {"choice": "fit", "description": ["In fit mode, extract is made from a reference : image or vector dataset."]}, {"choice": "extent", "description": ["In extent mode, the ROI is defined by two points, the upper left corner and the lower right corner, decomposed in 2 coordinates : X and Y. The unit for those coordinates can be set."]}, {"choice": "radius", "description": ["This is the radius parameter of the radius mode."]}], "explanation": []}, {"flag": "mode.extent.ulx", "parameterName": "X coordinate of the Upper left corner", "dataType": "Float", "explanation": ["X coordinate of upper left corner point."]}, {"flag": "mode.extent.uly", "parameterName": "Y coordinate of Upper Left corner point.", "dataType": "Float", "explanation": ["Y coordinate of upper left corner point."]}, {"flag": "mode.extent.lrx", "parameterName": "X coordinate of Lower Right corner point.", "dataType": "Float", "explanation": ["X coordinate of lower right corner point."]}, {"flag": "mode.extent.lry", "parameterName": "Y coordinate of Lower Right corner point.", "dataType": "Float", "explanation": ["Y coordinate of lower right corner point."]}, {"flag": "mode.extent.unit", "parameterName": "Unit", "dataType": "Choices", "availableChoices": [{"choice": "pxl", "description": ["The unit for the center coordinates will be the pixel."]}, {"choice": "phy", "description": ["The unit for the center coordinates will be the physical measure of the image."]}, {"choice": "lonlat", "description": ["The unit for the parameters coordinates will be the longitude and the latitude."]}], "explanation": [" Available choices are:"]}, {"flag": "mode.radius.r", "parameterName": "Radius", "dataType": "Float", "explanation": ["This is the radius parameter of the radius mode."]}, {"flag": "mode.radius.unitr", "parameterName": "Radius unit", "dataType": "Choices", "availableChoices": [{"choice": "pxl", "description": ["The unit for the center coordinates will be the pixel."]}, {"choice": "phy", "description": ["The unit for the center coordinates will be the physical measure of the image."]}], "explanation": [" Available choices are:"]}, {"flag": "mode.radius.cx", "parameterName": "X coordinate of the center", "dataType": "Float", "explanation": ["This is the center coordinate of the radius mode, it will be either an ordinate or a latitude."]}, {"flag": "mode.radius.cy", "parameterName": "Y coordinate of the center", "dataType": "Float", "explanation": []}, {"flag": "mode.radius.unitc", "parameterName": "Center unit", "dataType": "Choices", "availableChoices": [{"choice": "pxl", "description": ["The unit for the center coordinates will be the pixel."]}, {"choice": "phy", "description": ["The unit for the center coordinates will be the physical measure of the image."]}, {"choice": "lonlat", "description": ["The unit for the center coordinates will be the longitude and the latitude."]}], "explanation": [" Available choices are:"]}, {"flag": "startx", "parameterName": "Start X", "dataType": "Int", "explanation": []}, {"flag": "starty", "parameterName": "Start Y", "dataType": "Int", "explanation": []}, {"flag": "sizex", "parameterName": "Size X", "dataType": "Int", "explanation": []}, {"flag": "sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": []}, {"flag": "cl", "parameterName": "Output Image channels", "dataType": "List", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application extracts a Region Of Interest with user parameters. There are four mode of extraction. The standard mode allows the user to enter one point (upper left corner of the region to extract) and a size. The extent mode needs two points (upper left corner and lower right) and the radius mode need the center of the region and the radius : it will extract the rectangle containing the circle defined and limited by the image dimension. The fit mode needs a reference image or vector and the dimension of the extracted region will be the same as the extent of the reference. Different units are available such as pixel, image physical space or longitude and latitude. \n"},
{"name": "DEMConvert", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DEMConvert.html", "label": "DEM Conversion", "category": "Image Manipulation", "definition": "Converts a geo-referenced DEM image into a general raster file compatible with OTB DEM handling.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DEMConvert - in QB_Toulouse_Ortho_Elev . tif - out outputDEM", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DEMConvert application DEMConvert = otbApplication . Registry . CreateApplication ( \"DEMConvert\" ) # The following lines set all the application parameters: DEMConvert . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_Elev.tif\" ) DEMConvert . SetParameterString ( \"out\" , \"outputDEM\" ) # The following line execute the application DEMConvert . ExecuteAndWriteOutput ()"], "command": "otbcli_DEMConvert", "parameters": [{"flag": "in", "parameterName": "Input geo-referenced DEM", "dataType": "Input image", "explanation": ["Input geo-referenced DEM to convert to general raster format."], "isInputFile": true}, {"flag": "out", "parameterName": "Prefix of the output files", "dataType": "Output File name", "explanation": ["will be used to get the prefix (name withtout extensions) of the files to write. Three files - prefix.geom, prefix.omd and prefix.ras - will be generated."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [], "description": "\n   \n In order to be understood by the Orfeo ToolBox and the underlying OSSIM library, a geo-referenced Digital Elevation Model image can be converted into a general raster image, which consists in 3 files with the following extensions: .ras, .geom and .omd. Once converted, you have to place these files in a separate directory, and you can then use this directory to set the \u201cDEM Directory\u201d parameter of a DEM based OTB application or filter. \n"},
{"name": "DynamicConvert", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DynamicConvert.html", "label": "Dynamic Conversion", "category": "Image Manipulation", "definition": "Change the pixel type and rescale the image\u2019s dynamic", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DynamicConvert - in QB_Toulouse_Ortho_XS . tif - out otbConvertWithScalingOutput . png - type linear - channels rgb - outmin 0 - outmax 255", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DynamicConvert application DynamicConvert = otbApplication . Registry . CreateApplication ( \"DynamicConvert\" ) # The following lines set all the application parameters: DynamicConvert . SetParameterString ( \"in\" , \"QB_Toulouse_Ortho_XS.tif\" ) DynamicConvert . SetParameterString ( \"out\" , \"otbConvertWithScalingOutput.png\" ) DynamicConvert . SetParameterString ( \"type\" , \"linear\" ) DynamicConvert . SetParameterString ( \"channels\" , \"rgb\" ) DynamicConvert . SetParameterFloat ( \"outmin\" , 0 ) DynamicConvert . SetParameterFloat ( \"outmax\" , 255 ) # The following line execute the application DynamicConvert . ExecuteAndWriteOutput ()"], "command": "otbcli_DynamicConvert", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "mask", "parameterName": "Input mask", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "type", "parameterName": "Rescale type", "dataType": "Choices", "availableChoices": [{"choice": "linear", "description": []}, {"choice": "log2", "description": []}], "explanation": []}, {"flag": "type.linear.gamma", "parameterName": "Gamma correction factor", "dataType": "Float", "explanation": ["Gamma correction factor."]}, {"flag": "quantile.high", "parameterName": "High cut quantile", "dataType": "Float", "explanation": ["Quantiles to cut from histogram high values before computing min/max rescaling (in percent, 2 by default)."]}, {"flag": "quantile.low", "parameterName": "Low cut quantile", "dataType": "Float", "explanation": ["Quantiles to cut from histogram low values before computing min/max rescaling (in percent, 2 by default)."]}, {"flag": "channels", "parameterName": "Channels selection", "dataType": "Choices", "availableChoices": [{"choice": "all", "description": ["Select all bands in the input image, (1,...,n)."]}, {"choice": "grayscale", "description": ["Display single channel as standard color image."]}, {"choice": "rgb", "description": ["Select 3 bands in the input image (multi-bands), by default (1,2,3)."]}], "explanation": []}, {"flag": "channels.grayscale.channel", "parameterName": "Grayscale channel", "dataType": "Int", "explanation": []}, {"flag": "channels.rgb.red", "parameterName": "Red Channel", "dataType": "Int", "explanation": ["Red channel index."]}, {"flag": "channels.rgb.green", "parameterName": "Green Channel", "dataType": "Int", "explanation": ["Green channel index."]}, {"flag": "channels.rgb.blue", "parameterName": "Blue Channel", "dataType": "Int", "explanation": ["Blue channel index."]}, {"flag": "outmin", "parameterName": "Output min value", "dataType": "Float", "explanation": []}, {"flag": "outmax", "parameterName": "Output max value", "dataType": "Float", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application performs an image pixel type conversion (short, ushort, uchar, int, uint, float and double types are handled). The output image is written in the specified format (ie. that corresponds to the given extension). \n The conversion can include a rescale of the data range, by default it\u2019s set between the 2nd to the 98th percentile. The rescale can be linear or log2.\nThe choice of the output channels can be done with the extended filename, but less easy to handle. To do this, a \u2018channels\u2019 parameter allows you to select the desired bands at the output. There are 3 modes, the available choices are:\n* grayscale :  to display mono image as standard color image\n* rgb : select 3 bands in the input image (multi-bands)\n* all : keep all bands. \n \n"},
{"name": "DownloadSRTMTiles", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DownloadSRTMTiles.html", "label": "Download or list SRTM tiles related to a set of images", "category": "Image Manipulation", "definition": "Download or list SRTM tiles", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DownloadSRTMTiles - il QB_Toulouse_Ortho_XS . tif - mode list - tiledir / home / user / srtm_dir /", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DownloadSRTMTiles application DownloadSRTMTiles = otbApplication . Registry . CreateApplication ( \"DownloadSRTMTiles\" ) # The following lines set all the application parameters: DownloadSRTMTiles . SetParameterStringList ( \"il\" , [ 'QB_Toulouse_Ortho_XS.tif' ]) DownloadSRTMTiles . SetParameterString ( \"mode\" , \"list\" ) DownloadSRTMTiles . SetParameterString ( \"tiledir\" , \"/home/user/srtm_dir/\" ) # The following line execute the application DownloadSRTMTiles . ExecuteAndWriteOutput ()"], "command": "otbcli_DownloadSRTMTiles", "parameters": [{"flag": "il", "parameterName": "Input images list", "dataType": "Input image list", "explanation": ["List of images on which you want to determine corresponding SRTM tiles."], "isInputFile": true}, {"flag": "vl", "parameterName": "Input vector data list", "dataType": "Input vector data list", "explanation": ["List of vector data files on which you want to determine corresponding SRTM tiles."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "names", "parameterName": "Input tile names", "dataType": "String list", "explanation": ["List of SRTM tile names to download. This list is added to the tiles derived from input images or vectors.The names should follow the SRTM tile naming convention, for instance N43E001."]}, {"flag": "tiledir", "parameterName": "Tiles directory", "dataType": "Directory", "explanation": ["Directory where SRTM tiles are stored. In download mode, the zipped archives will be downloaded to this directory. You\u2019ll need to unzip all tile files before using them in your application. In any case, this directory will be inspected to check which tiles are already downloaded."]}, {"flag": "mode", "parameterName": "Download/List corresponding SRTM tiles.", "dataType": "Choices", "availableChoices": [{"choice": "download", "description": ["Download corresponding tiles on USGE server."]}, {"choice": "list", "description": ["List tiles in an existing local directory."]}], "explanation": [" Available choices are:"]}], "description": "\n   \n This application allows selecting the appropriate SRTM tiles that covers a list of images. It builds a list of the required tiles. Two modes are available: the first one download those tiles from the USGS SRTM3 website ( http://dds.cr.usgs.gov/srtm/version2_1/SRTM3/ ), the second one list those tiles in a local directory. In both cases, you need to indicate the directory in which directory  tiles will be download or the location of local SRTM files. \n"},
{"name": "ConcatenateImages", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ConcatenateImages.html", "label": "Images Concatenation", "category": "Image Manipulation", "definition": "Concatenate a list of images of the same size into a single multi-channel one.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ConcatenateImages - il GomaAvant . png GomaApres . png - out otbConcatenateImages . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ConcatenateImages application ConcatenateImages = otbApplication . Registry . CreateApplication ( \"ConcatenateImages\" ) # The following lines set all the application parameters: ConcatenateImages . SetParameterStringList ( \"il\" , [ 'GomaAvant.png' , 'GomaApres.png' ]) ConcatenateImages . SetParameterString ( \"out\" , \"otbConcatenateImages.tif\" ) # The following line execute the application ConcatenateImages . ExecuteAndWriteOutput ()"], "command": "otbcli_ConcatenateImages", "parameters": [{"flag": "il", "parameterName": "Input images list", "dataType": "Input image list", "explanation": ["The list of images to concatenate, must have the same size."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The concatenated output image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application performs images channels concatenation. It reads the input image list (single or multi-channel) and generates a single multi-channel image. The channel order is the same as the list. \n"},
{"name": "ColorMapping", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ColorMapping.html", "label": "Color Mapping", "category": "Image Manipulation", "definition": "Maps an input label image to 8-bits RGB using look-up tables.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ColorMapping - in ROI_QB_MUL_1_SVN_CLASS_MULTI . png - method custom - method . custom . lut ROI_QB_MUL_1_SVN_CLASS_MULTI_PNG_ColorTable . txt - out Colorized_ROI_QB_MUL_1_SVN_CLASS_MULTI . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ColorMapping application ColorMapping = otbApplication . Registry . CreateApplication ( \"ColorMapping\" ) # The following lines set all the application parameters: ColorMapping . SetParameterString ( \"in\" , \"ROI_QB_MUL_1_SVN_CLASS_MULTI.png\" ) ColorMapping . SetParameterString ( \"method\" , \"custom\" ) ColorMapping . SetParameterString ( \"method.custom.lut\" , \"ROI_QB_MUL_1_SVN_CLASS_MULTI_PNG_ColorTable.txt\" ) ColorMapping . SetParameterString ( \"out\" , \"Colorized_ROI_QB_MUL_1_SVN_CLASS_MULTI.tif\" ) # The following line execute the application ColorMapping . ExecuteAndWriteOutput ()"], "command": "otbcli_ColorMapping", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "method.custom.lut", "parameterName": "Look-up table file", "dataType": "Input File name", "explanation": ["An ASCII file containing the look-up table with one color per line (for instance the line \u20181 255 0 0\u2019 means that all pixels with label 1 will be replaced by RGB color 255 0 0) Lines beginning with a # are ignored."], "isInputFile": true}, {"flag": "method.image.in", "parameterName": "Support Image", "dataType": "Input image", "explanation": ["Support image filename. For each label, the LUT is calculated from the mean pixel value in the support image, over the corresponding labeled areas. First of all, the support image is normalized with extrema rejection."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "op", "parameterName": "Operation", "dataType": "Choices", "availableChoices": [{"choice": "labeltocolor", "description": []}, {"choice": "colortolabel", "description": []}], "explanation": []}, {"flag": "op.colortolabel.notfound", "parameterName": "Not Found Label", "dataType": "Int", "explanation": ["Label to use for unknown colors."]}, {"flag": "method", "parameterName": "Color mapping method", "dataType": "Choices", "availableChoices": [{"choice": "custom", "description": ["Apply a user-defined look-up table to a labeled image. Look-up table is loaded from a text file."]}, {"choice": "continuous", "description": ["Apply a continuous look-up table to a range of input values."]}, {"choice": "optimal", "description": ["[label to color] Compute an optimal look-up table such that neighboring labels in a segmentation are mapped to highly contrasted colors. [color to label] Searching all the colors present in the image to compute a continuous label list."]}, {"choice": "image", "description": []}], "explanation": []}, {"flag": "method.continuous.lut", "parameterName": "Look-up tables", "dataType": "Choices", "availableChoices": [{"choice": "red", "description": []}, {"choice": "green", "description": []}, {"choice": "blue", "description": []}, {"choice": "grey", "description": []}, {"choice": "hot", "description": []}, {"choice": "cool", "description": []}, {"choice": "spring", "description": []}, {"choice": "summer", "description": []}, {"choice": "autumn", "description": []}, {"choice": "winter", "description": []}, {"choice": "copper", "description": []}, {"choice": "jet", "description": []}, {"choice": "hsv", "description": []}, {"choice": "overunder", "description": []}, {"choice": "relief", "description": []}], "explanation": ["Available look-up tables. Available choices are:"]}, {"flag": "method.continuous.min", "parameterName": "Mapping range lower value", "dataType": "Float", "explanation": ["Set the lower input value of the mapping range."]}, {"flag": "method.continuous.max", "parameterName": "Mapping range higher value", "dataType": "Float", "explanation": ["Set the higher input value of the mapping range."]}, {"flag": "method.optimal.background", "parameterName": "Background label", "dataType": "Int", "explanation": ["Value of the background label."]}, {"flag": "method.image.nodatavalue", "parameterName": "NoData value", "dataType": "Float", "explanation": ["NoData value for each channel of the support image, which will not be handled in the LUT estimation. If NOT checked, ALL the pixel values of the support image will be handled in the LUT estimation."]}, {"flag": "method.image.low", "parameterName": "lower quantile", "dataType": "Int", "explanation": ["lower quantile for image normalization."]}, {"flag": "method.image.up", "parameterName": "upper quantile", "dataType": "Int", "explanation": ["upper quantile for image normalization."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application allows one to map a label image to a 8-bits RGB image (in both ways) using different methods. \n -The custom method allows one to use a custom look-up table. The look-up table is loaded from a text file where each line describes an entry. The typical use of this method is to colorise a classification map.\n-The continuous method allows mapping a range of values in a scalar input image to a colored image using continuous look-up table, in order to enhance image interpretation. Several look-up tables can been chosen with different color ranges. \n -The optimal method computes an optimal look-up table. When processing a segmentation label image (label to color), the color difference between adjacent segmented regions is maximized. When processing an unknown color image (color to label), all the present colors are mapped to a continuous label list. \n \n The support image method uses a color support image to associate an average color to each region. \n \n \n \n"},
{"name": "VectorDimensionalityReduction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDimensionalityReduction.html", "label": "Vector Dimensionality Reduction", "category": "Learning", "definition": "Performs dimensionality reduction of the input vector data according to a model file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDimensionalityReduction - in vectorData . shp - instat meanVar . xml - model model . txt - out vectorDataOut . shp - feat perimeter area width", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDimensionalityReduction application VectorDimensionalityReduction = otbApplication . Registry . CreateApplication ( \"VectorDimensionalityReduction\" ) # The following lines set all the application parameters: VectorDimensionalityReduction . SetParameterString ( \"in\" , \"vectorData.shp\" ) VectorDimensionalityReduction . SetParameterString ( \"instat\" , \"meanVar.xml\" ) VectorDimensionalityReduction . SetParameterString ( \"model\" , \"model.txt\" ) VectorDimensionalityReduction . SetParameterString ( \"out\" , \"vectorDataOut.shp\" ) # The following line execute the application VectorDimensionalityReduction . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDimensionalityReduction", "parameters": [{"flag": "in", "parameterName": "Name of the input vector data", "dataType": "Input vector data", "explanation": [], "isInputFile": true}, {"flag": "instat", "parameterName": "Statistics file", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "model", "parameterName": "Model file", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output vector data file containing the reduced vector", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "feat", "parameterName": "Input features to use for reduction.", "dataType": "List", "explanation": []}, {"flag": "featout", "parameterName": "Output feature", "dataType": "Choices", "availableChoices": [{"choice": "prefix", "description": ["Use a name prefix."]}, {"choice": "list", "description": ["Use a list with all names."]}], "explanation": []}, {"flag": "featout.prefix.name", "parameterName": "Feature name prefix", "dataType": "String", "explanation": ["Name prefix for output features. This prefix is followed by the numeric index of each output feature."]}, {"flag": "featout.list.names", "parameterName": "Feature name list", "dataType": "String list", "explanation": ["List of field names for the output features which result from the reduction."]}, {"flag": "pcadim", "parameterName": "Principal component dimension", "dataType": "Int", "explanation": []}, {"flag": "mode", "parameterName": "Writing mode", "dataType": "Choices", "availableChoices": [{"choice": "overwrite", "description": ["Overwrite mode."]}, {"choice": "update", "description": ["Update mode."]}], "explanation": []}], "description": "\n   \n This application performs a vector data dimensionality reduction based on a model file produced by the TrainDimensionalityReduction application. \n"},
{"name": "VectorClassifier", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorClassifier.html", "label": "Vector Classification", "category": "Learning", "definition": "Performs a classification of the input vector data according to a model file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorClassifier - in vectorData . shp - instat meanVar . xml - model svmModel . svm - out vectorDataLabeledVector . shp - feat perimeter area width - cfield predicted", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorClassifier application VectorClassifier = otbApplication . Registry . CreateApplication ( \"VectorClassifier\" ) # The following lines set all the application parameters: VectorClassifier . SetParameterString ( \"in\" , \"vectorData.shp\" ) VectorClassifier . SetParameterString ( \"instat\" , \"meanVar.xml\" ) VectorClassifier . SetParameterString ( \"model\" , \"svmModel.svm\" ) VectorClassifier . SetParameterString ( \"out\" , \"vectorDataLabeledVector.shp\" ) # The following line execute the application VectorClassifier . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorClassifier", "parameters": [{"flag": "in", "parameterName": "Name of the input vector data", "dataType": "Input vector data", "explanation": ["The input vector data file to classify."], "isInputFile": true}, {"flag": "instat", "parameterName": "Statistics file", "dataType": "Input File name", "explanation": ["A XML file containing mean and standard deviation to centerand reduce samples before classification, produced by ComputeImagesStatistics application."], "isInputFile": true}, {"flag": "model", "parameterName": "Model file", "dataType": "Input File name", "explanation": ["Model file produced by TrainVectorClassifier application."], "isInputFile": true}, {"flag": "out", "parameterName": "Output vector data file containing class labels", "dataType": "Output File name", "explanation": ["Output vector data file storing sample values (OGR format).If not given, the input vector data file is updated."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "cfield", "parameterName": "Field class", "dataType": "String", "explanation": ["Field containing the predicted class.Only geometries with this field available will be taken into account. The field is added either in the input file (if \u2018out\u2019 off) or in the output file. Caution, the \u2018cfield\u2019 must not exist in the input file if you are updating the file."]}, {"flag": "feat", "parameterName": "Field names to be calculated.", "dataType": "List", "explanation": ["List of field names in the input vector data used as features for training. Put the same field names as the TrainVectorClassifier application."]}, {"flag": "confmap", "parameterName": "Confidence map", "dataType": "Boolean", "explanation": ["Confidence map of the produced classification. The confidence index depends on the model :    - LibSVM : difference between the two highest probabilities (needs a model with probability estimates, so that classes probabilities can be computed for each sample)   - OpenCV     * Boost : sum of votes     * DecisionTree : (not supported)     * GradientBoostedTree : (not supported)     * KNearestNeighbors : number of neighbors with the same label     * NeuralNetwork : difference between the two highest responses     * NormalBayes : (not supported)     * RandomForest : Confidence (proportion of votes for the majority class). Margin (normalized difference of the votes of the 2 majority classes) is not available for now.     * SVM : distance to margin (only works for 2-class models). ."]}], "description": "\n   \n This application performs a vector data classification based on a model file produced by the TrainVectorClassifier application.Features of the vector data output will contain the class labels decided by the classifier (maximal class label = 65535).\nThere are two modes:\n1) Update mode: add of the \u2018cfield\u2019 field containing the predicted class in the input file.\n2) Write mode: copies the existing fields of the input file in the output file  and add the \u2018cfield\u2019 field containing the predicted class.\nIf you have declared the output file, the write mode applies. Otherwise, the input file update mode will be applied. \n"},
{"name": "TrainVectorClassifier", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_TrainVectorClassifier.html", "label": "Train Vector Classifier", "category": "Learning", "definition": "Train a classifier based on labeled geometries and a list of features to consider.", "authors": "This application has been written by OTB Team.", "limitations": null, "example": ["otbcli_TrainVectorClassifier - io . vd vectorData . shp - io . stats meanVar . xml - io . out svmModel . svm - feat perimeter area width - cfield predicted", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the TrainVectorClassifier application TrainVectorClassifier = otbApplication . Registry . CreateApplication ( \"TrainVectorClassifier\" ) # The following lines set all the application parameters: TrainVectorClassifier . SetParameterStringList ( \"io.vd\" , [ 'vectorData.shp' ]) TrainVectorClassifier . SetParameterString ( \"io.stats\" , \"meanVar.xml\" ) TrainVectorClassifier . SetParameterString ( \"io.out\" , \"svmModel.svm\" ) # The following line execute the application TrainVectorClassifier . ExecuteAndWriteOutput ()"], "command": "otbcli_TrainVectorClassifier", "parameters": [{"flag": "io.vd", "parameterName": "Input Vector Data", "dataType": "Input vector data list", "explanation": ["Input geometries used for training (note : all geometries from the layer will be used)."], "isInputFile": true}, {"flag": "io.stats", "parameterName": "Input XML image statistics file", "dataType": "Input File name", "explanation": ["XML file containing mean and variance of each feature."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output model", "dataType": "Output File name", "explanation": ["Output file containing the model estimated (.txt format)."], "isOutputFile": true}, {"flag": "io.confmatout", "parameterName": "Output confusion matrix or contingency table", "dataType": "Output File name", "explanation": ["Output file containing the confusion matrix or contingency table (.csv format).The contingency table is output when we unsupervised algorithms is used otherwise the confusion matrix is output."], "isOutputFile": true}, {"flag": "valid.vd", "parameterName": "Validation Vector Data", "dataType": "Input vector data list", "explanation": ["Geometries used for validation (must contain the same fields used for training, all geometries from the layer will be used)."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": ["Index of the layer to use in the validation vector file."]}, {"flag": "feat", "parameterName": "Field names for training features.", "dataType": "List", "explanation": []}, {"flag": "valid.layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": ["Index of the layer to use in the validation vector file."]}, {"flag": "cfield", "parameterName": "Field containing the class integer label for supervision", "dataType": "List", "explanation": []}, {"flag": "v", "parameterName": "Verbose mode", "dataType": "Boolean", "explanation": []}, {"flag": "classifier", "parameterName": "Classifier to use for the training", "dataType": "Choices", "availableChoices": [{"choice": "libsvm", "description": ["This group of parameters allows setting SVM classifier parameters."]}, {"choice": "boost", "description": ["This group of parameters allows setting Boost classifier parameters. See complete documentation here url{"]}, {"choice": "dt", "description": ["This group of parameters allows setting Decision Tree classifier parameters. See complete documentation here url{"]}, {"choice": "gbt", "description": ["This group of parameters allows setting Gradient Boosted Tree classifier parameters. See complete documentation here url{"]}, {"choice": "ann", "description": ["This group of parameters allows setting Artificial Neural Network classifier parameters. See complete documentation here url{"]}, {"choice": "bayes", "description": ["Use a Normal Bayes Classifier. See complete documentation here url{"]}, {"choice": "rf", "description": ["This group of parameters allows setting Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "knn", "description": ["This group of parameters allows setting KNN classifier parameters. See complete documentation here url{"]}, {"choice": "sharkrf", "description": ["This group of parameters allows setting Shark Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "sharkkm", "description": ["This group of parameters allows setting Shark kMeans classifier parameters. See complete documentation here url{"]}], "explanation": []}, {"flag": "classifier.libsvm.k", "parameterName": "SVM Kernel Type", "dataType": "Choices", "availableChoices": [{"choice": "linear", "description": ["Linear Kernel, no mapping is done, this is the fastest option."]}, {"choice": "rbf", "description": ["This kernel is a good choice in most of the case. It is an exponential function of the euclidian distance between the vectors."]}, {"choice": "poly", "description": ["Polynomial Kernel, the mapping is a polynomial function."]}, {"choice": "sigmoid", "description": ["The kernel is a hyperbolic tangente function of the vectors."]}], "explanation": ["SVM Kernel Type. Available choices are:"]}, {"flag": "classifier.libsvm.m", "parameterName": "SVM Model Type", "dataType": "Choices", "availableChoices": [{"choice": "csvc", "description": ["This formulation allows imperfect separation of classes. The penalty is set through the cost parameter C."]}, {"choice": "nusvc", "description": ["This formulation allows imperfect separation of classes. The penalty is set through the cost parameter Nu. As compared to C, Nu is harder to optimize, and may not be as fast."]}, {"choice": "oneclass", "description": ["All the training data are from the same class, SVM builds a boundary that separates the class from the rest of the feature space."]}], "explanation": ["Type of SVM formulation. Available choices are:"]}, {"flag": "classifier.libsvm.c", "parameterName": "Cost parameter C", "dataType": "Float", "explanation": ["SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins."]}, {"flag": "classifier.libsvm.nu", "parameterName": "Cost parameter Nu", "dataType": "Float", "explanation": ["Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision."]}, {"flag": "classifier.libsvm.opt", "parameterName": "Parameters optimization", "dataType": "Boolean", "explanation": ["SVM parameters optimization flag."]}, {"flag": "classifier.libsvm.prob", "parameterName": "Probability estimation", "dataType": "Boolean", "explanation": ["Probability estimation flag."]}, {"flag": "classifier.boost.t", "parameterName": "Boost Type", "dataType": "Choices", "availableChoices": [{"choice": "discrete", "description": ["This procedure trains the classifiers on weighted versions of the training sample, giving higher weight to cases that are currently misclassified. This is done for a sequence of weighter samples, and then the final classifier is defined as a linear combination of the classifier from each stage."]}, {"choice": "real", "description": ["Adaptation of the Discrete Adaboost algorithm with Real value."]}, {"choice": "logit", "description": ["This procedure is an adaptive Newton algorithm for fitting an additive logistic regression model. Beware it can produce numeric instability."]}, {"choice": "gentle", "description": ["A modified version of the Real Adaboost algorithm, using Newton stepping rather than exact optimization at each step."]}], "explanation": ["Type of Boosting algorithm. Available choices are:"]}, {"flag": "classifier.boost.w", "parameterName": "Weak count", "dataType": "Int", "explanation": ["The number of weak classifiers."]}, {"flag": "classifier.boost.r", "parameterName": "Weight Trim Rate", "dataType": "Float", "explanation": ["A threshold between 0 and 1 used to save computational time. Samples with summary weight <= (1 - weight_trim_rate) do not participate in the next iteration of training. Set this parameter to 0 to turn off this functionality."]}, {"flag": "classifier.boost.m", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.dt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.dt.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.dt.ra", "parameterName": "Termination criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.dt.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.dt.f", "parameterName": "K-fold cross-validations", "dataType": "Int", "explanation": ["If cv_folds > 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds."]}, {"flag": "classifier.dt.r", "parameterName": "Set Use1seRule flag to false", "dataType": "Boolean", "explanation": ["If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate."]}, {"flag": "classifier.dt.t", "parameterName": "Set TruncatePrunedTree flag to false", "dataType": "Boolean", "explanation": ["If true, then pruned branches are physically removed from the tree."]}, {"flag": "classifier.gbt.w", "parameterName": "Number of boosting algorithm iterations", "dataType": "Int", "explanation": ["Number \u201cw\u201d of boosting algorithm iterations, with w*K being the total number of trees in the GBT model, where K is the output number of classes."]}, {"flag": "classifier.gbt.s", "parameterName": "Regularization parameter", "dataType": "Float", "explanation": ["Regularization parameter."]}, {"flag": "classifier.gbt.p", "parameterName": "Portion of the whole training set used for each algorithm iteration", "dataType": "Float", "explanation": ["Portion of the whole training set used for each algorithm iteration. The subset is generated randomly."]}, {"flag": "classifier.gbt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.ann.t", "parameterName": "Train Method Type", "dataType": "Choices", "availableChoices": [{"choice": "back", "description": ["Method to compute the gradient of the loss function and adjust weights in the network to optimize the result."]}, {"choice": "reg", "description": ["Almost the same as the Back-prop algorithm except that it does not take into account the magnitude of the partial derivative (coordinate of the gradient) but only its sign."]}], "explanation": ["Type of training method for the multilayer perceptron (MLP) neural network. Available choices are:"]}, {"flag": "classifier.ann.sizes", "parameterName": "Number of neurons in each intermediate layer", "dataType": "String list", "explanation": ["The number of neurons in each intermediate layer (excluding input and output layers)."]}, {"flag": "classifier.ann.f", "parameterName": "Neuron activation function type", "dataType": "Choices", "availableChoices": [{"choice": "ident", "description": []}, {"choice": "sig", "description": []}, {"choice": "gau", "description": []}], "explanation": ["This function determine whether the output of the node is positive or not depending on the output of the transfert function. Available choices are:"]}, {"flag": "classifier.ann.a", "parameterName": "Alpha parameter of the activation function", "dataType": "Float", "explanation": ["Alpha parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.b", "parameterName": "Beta parameter of the activation function", "dataType": "Float", "explanation": ["Beta parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.bpdw", "parameterName": "Strength of the weight gradient term in the BACKPROP method", "dataType": "Float", "explanation": ["Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1."]}, {"flag": "classifier.ann.bpms", "parameterName": "Strength of the momentum term (the difference between weights on the 2 previous iterations)", "dataType": "Float", "explanation": ["Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough."]}, {"flag": "classifier.ann.rdw", "parameterName": "Initial value Delta_0 of update-values Delta_{ij} in RPROP method", "dataType": "Float", "explanation": ["Initial value Delta_0 of update-values Delta_{ij} in RPROP method (default = 0.1)."]}, {"flag": "classifier.ann.rdwm", "parameterName": "Update-values lower limit Delta_{min} in RPROP method", "dataType": "Float", "explanation": ["Update-values lower limit Delta_{min} in RPROP method. It must be positive (default = 1e-7)."]}, {"flag": "classifier.ann.term", "parameterName": "Termination criteria", "dataType": "Choices", "availableChoices": [{"choice": "iter", "description": ["Set the number of iterations allowed to the network for its training. Training will stop regardless of the result when this number is reached."]}, {"choice": "eps", "description": ["Training will focus on result and will stop once the precision isat most epsilon."]}, {"choice": "all", "description": ["Both termination criteria are used. Training stop at the first reached."]}], "explanation": ["Termination criteria. Available choices are:"]}, {"flag": "classifier.ann.eps", "parameterName": "Epsilon value used in the Termination criteria", "dataType": "Float", "explanation": ["Epsilon value used in the Termination criteria."]}, {"flag": "classifier.ann.iter", "parameterName": "Maximum number of iterations used in the Termination criteria", "dataType": "Int", "explanation": ["Maximum number of iterations used in the Termination criteria."]}, {"flag": "classifier.rf.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.rf.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.rf.ra", "parameterName": "Termination Criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.rf.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.rf.var", "parameterName": "Size of the randomly selected subset of features at each tree node", "dataType": "Int", "explanation": ["The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features."]}, {"flag": "classifier.rf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.rf.acc", "parameterName": "Sufficient accuracy (OOB error)", "dataType": "Float", "explanation": ["Sufficient accuracy (OOB error)."]}, {"flag": "classifier.knn.k", "parameterName": "Number of Neighbors", "dataType": "Int", "explanation": ["The number of neighbors to use."]}, {"flag": "classifier.sharkrf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.sharkrf.nodesize", "parameterName": "Min size of the node for a split", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.sharkrf.mtry", "parameterName": "Number of features tested at each node", "dataType": "Int", "explanation": ["The number of features (variables) which will be tested at each node in order to compute the split. If set to zero, the square root of the number of features is used."]}, {"flag": "classifier.sharkrf.oobr", "parameterName": "Out of bound ratio", "dataType": "Float", "explanation": ["Set the fraction of the original training dataset to use as the out of bag sample.A good default value is 0.66. ."]}, {"flag": "classifier.sharkkm.maxiter", "parameterName": "Maximum number of iteration for the kmeans algorithm.", "dataType": "Int", "explanation": ["The maximum number of iteration for the kmeans algorithm. 0=unlimited."]}, {"flag": "classifier.sharkkm.k", "parameterName": "The number of class used for the kmeans algorithm.", "dataType": "Int", "explanation": ["The number of class used for the kmeans algorithm. Default set to 2 class."]}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n This application trains a classifier based on labeled geometries and a list of features to consider for classification.\nThis application is based on LibSVM, OpenCV Machine Learning (2.3.1 and later), and Shark ML The output of this application is a text model file, whose format corresponds to the ML model type chosen. There is no image nor vector data output. \n"},
{"name": "TrainImagesClassifier", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_TrainImagesClassifier.html", "label": "Train a classifier from multiple images", "category": "Learning", "definition": "Train a classifier from multiple pairs of images and training vector data.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_TrainImagesClassifier - io . il QB_1_ortho . tif - io . vd VectorData_QB1 . shp - io . imstat EstimateImageStatisticsQB1 . xml - sample . mv 100 - sample . mt 100 - sample . vtr 0.5 - sample . vfn Class - classifier libsvm - classifier . libsvm . k linear - classifier . libsvm . c 1 - classifier . libsvm . opt false - io . out svmModelQB1 . txt - io . confmatout svmConfusionMatrixQB1 . csv", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the TrainImagesClassifier application TrainImagesClassifier = otbApplication . Registry . CreateApplication ( \"TrainImagesClassifier\" ) # The following lines set all the application parameters: TrainImagesClassifier . SetParameterStringList ( \"io.il\" , [ 'QB_1_ortho.tif' ]) TrainImagesClassifier . SetParameterStringList ( \"io.vd\" , [ 'VectorData_QB1.shp' ]) TrainImagesClassifier . SetParameterString ( \"io.imstat\" , \"EstimateImageStatisticsQB1.xml\" ) TrainImagesClassifier . SetParameterInt ( \"sample.mv\" , 100 ) TrainImagesClassifier . SetParameterInt ( \"sample.mt\" , 100 ) TrainImagesClassifier . SetParameterFloat ( \"sample.vtr\" , 0.5 ) # The following line execute the application TrainImagesClassifier . ExecuteAndWriteOutput ()"], "command": "otbcli_TrainImagesClassifier", "parameters": [{"flag": "io.il", "parameterName": "Input Image List", "dataType": "Input image list", "explanation": ["A list of input images."], "isInputFile": true}, {"flag": "io.vd", "parameterName": "Input Vector Data List", "dataType": "Input vector data list", "explanation": ["A list of vector data to select the training samples."], "isInputFile": true}, {"flag": "io.valid", "parameterName": "Validation Vector Data List", "dataType": "Input vector data list", "explanation": ["A list of vector data to select the validation samples."], "isInputFile": true}, {"flag": "io.imstat", "parameterName": "Input XML image statistics file", "dataType": "Input File name", "explanation": ["XML file containing mean and variance of each feature."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output model", "dataType": "Output File name", "explanation": ["Output file containing the model estimated (.txt format)."], "isOutputFile": true}, {"flag": "io.confmatout", "parameterName": "Output confusion matrix or contingency table", "dataType": "Output File name", "explanation": ["Output file containing the confusion matrix or contingency table (.csv format).The contingency table is output when we unsupervised algorithms is used otherwise the confusion matrix is output."], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "cleanup", "parameterName": "Temporary files cleaning", "dataType": "Boolean", "explanation": []}, {"flag": "sample.mt", "parameterName": "Maximum training sample size per class", "dataType": "Int", "explanation": ["Maximum size per class (in pixels) of the training sample list (default = 1000) (no limit = -1). If equal to -1, then the maximal size of the available training sample list per class will be equal to the surface area of the smallest class multiplied by the training sample ratio."]}, {"flag": "sample.mv", "parameterName": "Maximum validation sample size per class", "dataType": "Int", "explanation": ["Maximum size per class (in pixels) of the validation sample list (default = 1000) (no limit = -1). If equal to -1, then the maximal size of the available validation sample list per class will be equal to the surface area of the smallest class multiplied by the validation sample ratio."]}, {"flag": "sample.bm", "parameterName": "Bound sample number by minimum", "dataType": "Int", "explanation": ["Bound the number of samples for each class by the number of available samples by the smaller class. Proportions between training and validation are respected. Default is true (=1)."]}, {"flag": "sample.vtr", "parameterName": "Training and validation sample ratio", "dataType": "Float", "explanation": ["Ratio between training and validation samples (0.0 = all training, 1.0 = all validation) (default = 0.5)."]}, {"flag": "sample.vfn", "parameterName": "Field containing the class integer label for supervision", "dataType": "List", "explanation": ["Field containing the class id for supervision. The values in this field shall be cast into integers."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "classifier", "parameterName": "Classifier to use for the training", "dataType": "Choices", "availableChoices": [{"choice": "libsvm", "description": ["This group of parameters allows setting SVM classifier parameters."]}, {"choice": "boost", "description": ["This group of parameters allows setting Boost classifier parameters. See complete documentation here url{"]}, {"choice": "dt", "description": ["This group of parameters allows setting Decision Tree classifier parameters. See complete documentation here url{"]}, {"choice": "gbt", "description": ["This group of parameters allows setting Gradient Boosted Tree classifier parameters. See complete documentation here url{"]}, {"choice": "ann", "description": ["This group of parameters allows setting Artificial Neural Network classifier parameters. See complete documentation here url{"]}, {"choice": "bayes", "description": ["Use a Normal Bayes Classifier. See complete documentation here url{"]}, {"choice": "rf", "description": ["This group of parameters allows setting Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "knn", "description": ["This group of parameters allows setting KNN classifier parameters. See complete documentation here url{"]}, {"choice": "sharkrf", "description": ["This group of parameters allows setting Shark Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "sharkkm", "description": ["This group of parameters allows setting Shark kMeans classifier parameters. See complete documentation here url{"]}], "explanation": []}, {"flag": "classifier.libsvm.k", "parameterName": "SVM Kernel Type", "dataType": "Choices", "availableChoices": [{"choice": "linear", "description": ["Linear Kernel, no mapping is done, this is the fastest option."]}, {"choice": "rbf", "description": ["This kernel is a good choice in most of the case. It is an exponential function of the euclidian distance between the vectors."]}, {"choice": "poly", "description": ["Polynomial Kernel, the mapping is a polynomial function."]}, {"choice": "sigmoid", "description": ["The kernel is a hyperbolic tangente function of the vectors."]}], "explanation": ["SVM Kernel Type. Available choices are:"]}, {"flag": "classifier.libsvm.m", "parameterName": "SVM Model Type", "dataType": "Choices", "availableChoices": [{"choice": "csvc", "description": ["This formulation allows imperfect separation of classes. The penalty is set through the cost parameter C."]}, {"choice": "nusvc", "description": ["This formulation allows imperfect separation of classes. The penalty is set through the cost parameter Nu. As compared to C, Nu is harder to optimize, and may not be as fast."]}, {"choice": "oneclass", "description": ["All the training data are from the same class, SVM builds a boundary that separates the class from the rest of the feature space."]}], "explanation": ["Type of SVM formulation. Available choices are:"]}, {"flag": "classifier.libsvm.c", "parameterName": "Cost parameter C", "dataType": "Float", "explanation": ["SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins."]}, {"flag": "classifier.libsvm.nu", "parameterName": "Cost parameter Nu", "dataType": "Float", "explanation": ["Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision."]}, {"flag": "classifier.libsvm.opt", "parameterName": "Parameters optimization", "dataType": "Boolean", "explanation": ["SVM parameters optimization flag."]}, {"flag": "classifier.libsvm.prob", "parameterName": "Probability estimation", "dataType": "Boolean", "explanation": ["Probability estimation flag."]}, {"flag": "classifier.boost.t", "parameterName": "Boost Type", "dataType": "Choices", "availableChoices": [{"choice": "discrete", "description": ["This procedure trains the classifiers on weighted versions of the training sample, giving higher weight to cases that are currently misclassified. This is done for a sequence of weighter samples, and then the final classifier is defined as a linear combination of the classifier from each stage."]}, {"choice": "real", "description": ["Adaptation of the Discrete Adaboost algorithm with Real value."]}, {"choice": "logit", "description": ["This procedure is an adaptive Newton algorithm for fitting an additive logistic regression model. Beware it can produce numeric instability."]}, {"choice": "gentle", "description": ["A modified version of the Real Adaboost algorithm, using Newton stepping rather than exact optimization at each step."]}], "explanation": ["Type of Boosting algorithm. Available choices are:"]}, {"flag": "classifier.boost.w", "parameterName": "Weak count", "dataType": "Int", "explanation": ["The number of weak classifiers."]}, {"flag": "classifier.boost.r", "parameterName": "Weight Trim Rate", "dataType": "Float", "explanation": ["A threshold between 0 and 1 used to save computational time. Samples with summary weight <= (1 - weight_trim_rate) do not participate in the next iteration of training. Set this parameter to 0 to turn off this functionality."]}, {"flag": "classifier.boost.m", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.dt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.dt.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.dt.ra", "parameterName": "Termination criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.dt.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.dt.f", "parameterName": "K-fold cross-validations", "dataType": "Int", "explanation": ["If cv_folds > 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds."]}, {"flag": "classifier.dt.r", "parameterName": "Set Use1seRule flag to false", "dataType": "Boolean", "explanation": ["If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate."]}, {"flag": "classifier.dt.t", "parameterName": "Set TruncatePrunedTree flag to false", "dataType": "Boolean", "explanation": ["If true, then pruned branches are physically removed from the tree."]}, {"flag": "classifier.gbt.w", "parameterName": "Number of boosting algorithm iterations", "dataType": "Int", "explanation": ["Number \u201cw\u201d of boosting algorithm iterations, with w*K being the total number of trees in the GBT model, where K is the output number of classes."]}, {"flag": "classifier.gbt.s", "parameterName": "Regularization parameter", "dataType": "Float", "explanation": ["Regularization parameter."]}, {"flag": "classifier.gbt.p", "parameterName": "Portion of the whole training set used for each algorithm iteration", "dataType": "Float", "explanation": ["Portion of the whole training set used for each algorithm iteration. The subset is generated randomly."]}, {"flag": "classifier.gbt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.ann.t", "parameterName": "Train Method Type", "dataType": "Choices", "availableChoices": [{"choice": "back", "description": ["Method to compute the gradient of the loss function and adjust weights in the network to optimize the result."]}, {"choice": "reg", "description": ["Almost the same as the Back-prop algorithm except that it does not take into account the magnitude of the partial derivative (coordinate of the gradient) but only its sign."]}], "explanation": ["Type of training method for the multilayer perceptron (MLP) neural network. Available choices are:"]}, {"flag": "classifier.ann.sizes", "parameterName": "Number of neurons in each intermediate layer", "dataType": "String list", "explanation": ["The number of neurons in each intermediate layer (excluding input and output layers)."]}, {"flag": "classifier.ann.f", "parameterName": "Neuron activation function type", "dataType": "Choices", "availableChoices": [{"choice": "ident", "description": []}, {"choice": "sig", "description": []}, {"choice": "gau", "description": []}], "explanation": ["This function determine whether the output of the node is positive or not depending on the output of the transfert function. Available choices are:"]}, {"flag": "classifier.ann.a", "parameterName": "Alpha parameter of the activation function", "dataType": "Float", "explanation": ["Alpha parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.b", "parameterName": "Beta parameter of the activation function", "dataType": "Float", "explanation": ["Beta parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.bpdw", "parameterName": "Strength of the weight gradient term in the BACKPROP method", "dataType": "Float", "explanation": ["Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1."]}, {"flag": "classifier.ann.bpms", "parameterName": "Strength of the momentum term (the difference between weights on the 2 previous iterations)", "dataType": "Float", "explanation": ["Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough."]}, {"flag": "classifier.ann.rdw", "parameterName": "Initial value Delta_0 of update-values Delta_{ij} in RPROP method", "dataType": "Float", "explanation": ["Initial value Delta_0 of update-values Delta_{ij} in RPROP method (default = 0.1)."]}, {"flag": "classifier.ann.rdwm", "parameterName": "Update-values lower limit Delta_{min} in RPROP method", "dataType": "Float", "explanation": ["Update-values lower limit Delta_{min} in RPROP method. It must be positive (default = 1e-7)."]}, {"flag": "classifier.ann.term", "parameterName": "Termination criteria", "dataType": "Choices", "availableChoices": [{"choice": "iter", "description": ["Set the number of iterations allowed to the network for its training. Training will stop regardless of the result when this number is reached."]}, {"choice": "eps", "description": ["Training will focus on result and will stop once the precision isat most epsilon."]}, {"choice": "all", "description": ["Both termination criteria are used. Training stop at the first reached."]}], "explanation": ["Termination criteria. Available choices are:"]}, {"flag": "classifier.ann.eps", "parameterName": "Epsilon value used in the Termination criteria", "dataType": "Float", "explanation": ["Epsilon value used in the Termination criteria."]}, {"flag": "classifier.ann.iter", "parameterName": "Maximum number of iterations used in the Termination criteria", "dataType": "Int", "explanation": ["Maximum number of iterations used in the Termination criteria."]}, {"flag": "classifier.rf.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.rf.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.rf.ra", "parameterName": "Termination Criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.rf.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.rf.var", "parameterName": "Size of the randomly selected subset of features at each tree node", "dataType": "Int", "explanation": ["The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features."]}, {"flag": "classifier.rf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.rf.acc", "parameterName": "Sufficient accuracy (OOB error)", "dataType": "Float", "explanation": ["Sufficient accuracy (OOB error)."]}, {"flag": "classifier.knn.k", "parameterName": "Number of Neighbors", "dataType": "Int", "explanation": ["The number of neighbors to use."]}, {"flag": "classifier.sharkrf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.sharkrf.nodesize", "parameterName": "Min size of the node for a split", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.sharkrf.mtry", "parameterName": "Number of features tested at each node", "dataType": "Int", "explanation": ["The number of features (variables) which will be tested at each node in order to compute the split. If set to zero, the square root of the number of features is used."]}, {"flag": "classifier.sharkrf.oobr", "parameterName": "Out of bound ratio", "dataType": "Float", "explanation": ["Set the fraction of the original training dataset to use as the out of bag sample.A good default value is 0.66. ."]}, {"flag": "classifier.sharkkm.maxiter", "parameterName": "Maximum number of iteration for the kmeans algorithm.", "dataType": "Int", "explanation": ["The maximum number of iteration for the kmeans algorithm. 0=unlimited."]}, {"flag": "classifier.sharkkm.k", "parameterName": "The number of class used for the kmeans algorithm.", "dataType": "Int", "explanation": ["The number of class used for the kmeans algorithm. Default set to 2 class."]}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application performs a classifier training from multiple pairs of input images and training vector data. Samples are composed of pixel values in each band optionally centered and reduced using an XML statistics file produced by the ComputeImagesStatistics application. \n The training vector data must contain polygons with a positive integer field representing the class label. The name of this field can be set using the \u201cClass label field\u201d parameter. Training and validation sample lists are built such that each class is equally represented in both lists. One parameter allows controlling the ratio between the number of samples in training and validation sets. Two parameters allow managing the size of the training and validation sets per class and per image.\nSeveral classifier parameters can be set depending on the chosen classifier. In the validation process, the confusion matrix is organized the following way: rows = reference labels, columns = produced labels. In the header of the optional confusion matrix output file, the validation (reference) and predicted (produced) class labels are ordered according to the rows/columns of the confusion matrix.\nThis application is based on LibSVM, OpenCV Machine Learning (2.3.1 and later), and Shark ML. The output of this application is a text model file, whose format corresponds to the ML model type chosen. There is no image nor vector data output. \n \n"},
{"name": "TrainRegression", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_TrainRegression.html", "label": "Train a regression model", "category": "Learning", "definition": "Train a classifier from multiple images to perform regression.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_TrainRegression - io . il training_dataset . tif - io . out regression_model . txt - io . imstat training_statistics . xml - classifier libsvm", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the TrainRegression application TrainRegression = otbApplication . Registry . CreateApplication ( \"TrainRegression\" ) # The following lines set all the application parameters: TrainRegression . SetParameterStringList ( \"io.il\" , [ 'training_dataset.tif' ]) TrainRegression . SetParameterString ( \"io.out\" , \"regression_model.txt\" ) TrainRegression . SetParameterString ( \"io.imstat\" , \"training_statistics.xml\" ) TrainRegression . SetParameterString ( \"classifier\" , \"libsvm\" ) # The following line execute the application TrainRegression . ExecuteAndWriteOutput ()"], "command": "otbcli_TrainRegression", "parameters": [{"flag": "io.il", "parameterName": "Input Image List", "dataType": "Input image list", "explanation": ["A list of input images. First (n-1) bands should contain the predictor. The last band should contain the output value to predict."], "isInputFile": true}, {"flag": "io.csv", "parameterName": "Input CSV file", "dataType": "Input File name", "explanation": ["Input CSV file containing the predictors, and the output values in last column. Only used when no input image is given."], "isInputFile": true}, {"flag": "io.imstat", "parameterName": "Input XML image statistics file", "dataType": "Input File name", "explanation": ["Input XML file containing the mean and the standard deviation of the input images."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output regression model", "dataType": "Output File name", "explanation": ["Output file containing the model estimated (.txt format)."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "io.mse", "parameterName": "Mean Square Error", "dataType": "Float", "explanation": ["Mean square error computed with the validation predictors."]}, {"flag": "sample.mt", "parameterName": "Maximum training predictors", "dataType": "Int", "explanation": ["Maximum number of training predictors (default = 1000) (no limit = -1)."]}, {"flag": "sample.mv", "parameterName": "Maximum validation predictors", "dataType": "Int", "explanation": ["Maximum number of validation predictors (default = 1000) (no limit = -1)."]}, {"flag": "sample.vtr", "parameterName": "Training and validation sample ratio", "dataType": "Float", "explanation": ["Ratio between training and validation samples (0.0 = all training, 1.0 = all validation) (default = 0.5)."]}, {"flag": "classifier", "parameterName": "Classifier to use for the training", "dataType": "Choices", "availableChoices": [{"choice": "libsvm", "description": ["This group of parameters allows setting SVM classifier parameters."]}, {"choice": "dt", "description": ["This group of parameters allows setting Decision Tree classifier parameters. See complete documentation here url{"]}, {"choice": "gbt", "description": ["This group of parameters allows setting Gradient Boosted Tree classifier parameters. See complete documentation here url{"]}, {"choice": "ann", "description": ["This group of parameters allows setting Artificial Neural Network classifier parameters. See complete documentation here url{"]}, {"choice": "rf", "description": ["This group of parameters allows setting Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "knn", "description": ["This group of parameters allows setting KNN classifier parameters. See complete documentation here url{"]}, {"choice": "sharkrf", "description": ["This group of parameters allows setting Shark Random Forests classifier parameters. See complete documentation here url{"]}, {"choice": "sharkkm", "description": ["This group of parameters allows setting Shark kMeans classifier parameters. See complete documentation here url{"]}], "explanation": []}, {"flag": "classifier.libsvm.k", "parameterName": "SVM Kernel Type", "dataType": "Choices", "availableChoices": [{"choice": "linear", "description": ["Linear Kernel, no mapping is done, this is the fastest option."]}, {"choice": "rbf", "description": ["This kernel is a good choice in most of the case. It is an exponential function of the euclidian distance between the vectors."]}, {"choice": "poly", "description": ["Polynomial Kernel, the mapping is a polynomial function."]}, {"choice": "sigmoid", "description": ["The kernel is a hyperbolic tangente function of the vectors."]}], "explanation": ["SVM Kernel Type. Available choices are:"]}, {"flag": "classifier.libsvm.m", "parameterName": "SVM Model Type", "dataType": "Choices", "availableChoices": [{"choice": "epssvr", "description": ["The distance between feature vectors from the training set and the fitting hyper-plane must be less than Epsilon. For outliers the penalty multiplier C is used ."]}, {"choice": "nusvr", "description": ["Same as the epsilon regression except that this time the bounded parameter nu is used instead of epsilon."]}], "explanation": ["Type of SVM formulation. Available choices are:"]}, {"flag": "classifier.libsvm.c", "parameterName": "Cost parameter C", "dataType": "Float", "explanation": ["SVM models have a cost parameter C (1 by default) to control the trade-off between training errors and forcing rigid margins."]}, {"flag": "classifier.libsvm.nu", "parameterName": "Cost parameter Nu", "dataType": "Float", "explanation": ["Cost parameter Nu, in the range 0..1, the larger the value, the smoother the decision."]}, {"flag": "classifier.libsvm.opt", "parameterName": "Parameters optimization", "dataType": "Boolean", "explanation": ["SVM parameters optimization flag."]}, {"flag": "classifier.libsvm.prob", "parameterName": "Probability estimation", "dataType": "Boolean", "explanation": ["Probability estimation flag."]}, {"flag": "classifier.libsvm.eps", "parameterName": "Epsilon", "dataType": "Float", "explanation": ["Training will focus on result and will stop once the precision isat most epsilon."]}, {"flag": "classifier.dt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.dt.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.dt.ra", "parameterName": "Termination criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.dt.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.dt.f", "parameterName": "K-fold cross-validations", "dataType": "Int", "explanation": ["If cv_folds > 1, then it prunes a tree with K-fold cross-validation where K is equal to cv_folds."]}, {"flag": "classifier.dt.r", "parameterName": "Set Use1seRule flag to false", "dataType": "Boolean", "explanation": ["If true, then a pruning will be harsher. This will make a tree more compact and more resistant to the training data noise but a bit less accurate."]}, {"flag": "classifier.dt.t", "parameterName": "Set TruncatePrunedTree flag to false", "dataType": "Boolean", "explanation": ["If true, then pruned branches are physically removed from the tree."]}, {"flag": "classifier.gbt.t", "parameterName": "Loss Function Type", "dataType": "Choices", "availableChoices": [{"choice": "sqr", "description": []}, {"choice": "abs", "description": []}, {"choice": "hub", "description": []}], "explanation": ["Type of loss functionused for training. Available choices are:"]}, {"flag": "classifier.gbt.w", "parameterName": "Number of boosting algorithm iterations", "dataType": "Int", "explanation": ["Number \u201cw\u201d of boosting algorithm iterations, with w*K being the total number of trees in the GBT model, where K is the output number of classes."]}, {"flag": "classifier.gbt.s", "parameterName": "Regularization parameter", "dataType": "Float", "explanation": ["Regularization parameter."]}, {"flag": "classifier.gbt.p", "parameterName": "Portion of the whole training set used for each algorithm iteration", "dataType": "Float", "explanation": ["Portion of the whole training set used for each algorithm iteration. The subset is generated randomly."]}, {"flag": "classifier.gbt.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.ann.t", "parameterName": "Train Method Type", "dataType": "Choices", "availableChoices": [{"choice": "back", "description": ["Method to compute the gradient of the loss function and adjust weights in the network to optimize the result."]}, {"choice": "reg", "description": ["Almost the same as the Back-prop algorithm except that it does not take into account the magnitude of the partial derivative (coordinate of the gradient) but only its sign."]}], "explanation": ["Type of training method for the multilayer perceptron (MLP) neural network. Available choices are:"]}, {"flag": "classifier.ann.sizes", "parameterName": "Number of neurons in each intermediate layer", "dataType": "String list", "explanation": ["The number of neurons in each intermediate layer (excluding input and output layers)."]}, {"flag": "classifier.ann.f", "parameterName": "Neuron activation function type", "dataType": "Choices", "availableChoices": [{"choice": "ident", "description": []}, {"choice": "sig", "description": []}, {"choice": "gau", "description": []}], "explanation": ["This function determine whether the output of the node is positive or not depending on the output of the transfert function. Available choices are:"]}, {"flag": "classifier.ann.a", "parameterName": "Alpha parameter of the activation function", "dataType": "Float", "explanation": ["Alpha parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.b", "parameterName": "Beta parameter of the activation function", "dataType": "Float", "explanation": ["Beta parameter of the activation function (used only with sigmoid and gaussian functions)."]}, {"flag": "classifier.ann.bpdw", "parameterName": "Strength of the weight gradient term in the BACKPROP method", "dataType": "Float", "explanation": ["Strength of the weight gradient term in the BACKPROP method. The recommended value is about 0.1."]}, {"flag": "classifier.ann.bpms", "parameterName": "Strength of the momentum term (the difference between weights on the 2 previous iterations)", "dataType": "Float", "explanation": ["Strength of the momentum term (the difference between weights on the 2 previous iterations). This parameter provides some inertia to smooth the random fluctuations of the weights. It can vary from 0 (the feature is disabled) to 1 and beyond. The value 0.1 or so is good enough."]}, {"flag": "classifier.ann.rdw", "parameterName": "Initial value Delta_0 of update-values Delta_{ij} in RPROP method", "dataType": "Float", "explanation": ["Initial value Delta_0 of update-values Delta_{ij} in RPROP method (default = 0.1)."]}, {"flag": "classifier.ann.rdwm", "parameterName": "Update-values lower limit Delta_{min} in RPROP method", "dataType": "Float", "explanation": ["Update-values lower limit Delta_{min} in RPROP method. It must be positive (default = 1e-7)."]}, {"flag": "classifier.ann.term", "parameterName": "Termination criteria", "dataType": "Choices", "availableChoices": [{"choice": "iter", "description": ["Set the number of iterations allowed to the network for its training. Training will stop regardless of the result when this number is reached."]}, {"choice": "eps", "description": ["Training will focus on result and will stop once the precision isat most epsilon."]}, {"choice": "all", "description": ["Both termination criteria are used. Training stop at the first reached."]}], "explanation": ["Termination criteria. Available choices are:"]}, {"flag": "classifier.ann.eps", "parameterName": "Epsilon value used in the Termination criteria", "dataType": "Float", "explanation": ["Epsilon value used in the Termination criteria."]}, {"flag": "classifier.ann.iter", "parameterName": "Maximum number of iterations used in the Termination criteria", "dataType": "Int", "explanation": ["Maximum number of iterations used in the Termination criteria."]}, {"flag": "classifier.rf.max", "parameterName": "Maximum depth of the tree", "dataType": "Int", "explanation": ["The depth of the tree. A low value will likely underfit and conversely a high value will likely overfit. The optimal value can be obtained using cross validation or other suitable methods."]}, {"flag": "classifier.rf.min", "parameterName": "Minimum number of samples in each node", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.rf.ra", "parameterName": "Termination Criteria for regression tree", "dataType": "Float", "explanation": ["If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split further.", "If all absolute differences between an estimated value in a node and the values of the train samples in this node are smaller than this regression accuracy parameter, then the node will not be split."]}, {"flag": "classifier.rf.cat", "parameterName": "Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split", "dataType": "Int", "explanation": ["Cluster possible values of a categorical variable into K <= cat clusters to find a suboptimal split."]}, {"flag": "classifier.rf.var", "parameterName": "Size of the randomly selected subset of features at each tree node", "dataType": "Int", "explanation": ["The size of the subset of features, randomly selected at each tree node, that are used to find the best split(s). If you set it to 0, then the size will be set to the square root of the total number of features."]}, {"flag": "classifier.rf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.rf.acc", "parameterName": "Sufficient accuracy (OOB error)", "dataType": "Float", "explanation": ["Sufficient accuracy (OOB error)."]}, {"flag": "classifier.knn.k", "parameterName": "Number of Neighbors", "dataType": "Int", "explanation": ["The number of neighbors to use."]}, {"flag": "classifier.knn.rule", "parameterName": "Decision rule", "dataType": "Choices", "availableChoices": [{"choice": "mean", "description": ["Returns the mean of neighbors values."]}, {"choice": "median", "description": ["Returns the median of neighbors values."]}], "explanation": ["Decision rule for regression output. Available choices are:"]}, {"flag": "classifier.sharkrf.nbtrees", "parameterName": "Maximum number of trees in the forest", "dataType": "Int", "explanation": ["The maximum number of trees in the forest. Typically, the more trees you have, the better the accuracy. However, the improvement in accuracy generally diminishes and reaches an asymptote for a certain number of trees. Also to keep in mind, increasing the number of trees increases the prediction time linearly."]}, {"flag": "classifier.sharkrf.nodesize", "parameterName": "Min size of the node for a split", "dataType": "Int", "explanation": ["If the number of samples in a node is smaller than this parameter, then the node will not be split. A reasonable value is a small percentage of the total data e.g. 1 percent."]}, {"flag": "classifier.sharkrf.mtry", "parameterName": "Number of features tested at each node", "dataType": "Int", "explanation": ["The number of features (variables) which will be tested at each node in order to compute the split. If set to zero, the square root of the number of features is used."]}, {"flag": "classifier.sharkrf.oobr", "parameterName": "Out of bound ratio", "dataType": "Float", "explanation": ["Set the fraction of the original training dataset to use as the out of bag sample.A good default value is 0.66. ."]}, {"flag": "classifier.sharkkm.maxiter", "parameterName": "Maximum number of iteration for the kmeans algorithm.", "dataType": "Int", "explanation": ["The maximum number of iteration for the kmeans algorithm. 0=unlimited."]}, {"flag": "classifier.sharkkm.k", "parameterName": "The number of class used for the kmeans algorithm.", "dataType": "Int", "explanation": ["The number of class used for the kmeans algorithm. Default set to 2 class."]}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application trains a classifier from multiple input images or a csv file, in order to perform regression. Predictors are composed of pixel values in each band optionally centered and reduced using an XML statistics file produced by the ComputeImagesStatistics application. \n The output value for each predictor is assumed to be the last band (or the last column for CSV files). Training and validation predictor lists are built such that their size is inferior to maximum bounds given by the user, and the proportion corresponds to the balance parameter. Several classifier parameters can be set depending on the chosen classifier. In the validation process, the mean square error is computed between the ground truth and the estimated model.\nThis application is based on LibSVM and on OpenCV Machine Learning classifiers, and is compatible with OpenCV 2.3.1 and later. \n \n"},
{"name": "SampleExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SampleExtraction.html", "label": "Sample Extraction", "category": "Learning", "definition": "Extracts samples values from an image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SampleExtraction - in support_image . tif - vec sample_positions . sqlite - outfield prefix - outfield . prefix . name band_ - field label - out sample_values . sqlite", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SampleExtraction application SampleExtraction = otbApplication . Registry . CreateApplication ( \"SampleExtraction\" ) # The following lines set all the application parameters: SampleExtraction . SetParameterString ( \"in\" , \"support_image.tif\" ) SampleExtraction . SetParameterString ( \"vec\" , \"sample_positions.sqlite\" ) SampleExtraction . SetParameterString ( \"outfield\" , \"prefix\" ) SampleExtraction . SetParameterString ( \"outfield.prefix.name\" , \"band_\" ) # The following line execute the application SampleExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_SampleExtraction", "parameters": [{"flag": "in", "parameterName": "InputImage", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "vec", "parameterName": "Input sampling positions", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output samples", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "outfield", "parameterName": "Output field names", "dataType": "Choices", "availableChoices": [{"choice": "prefix", "description": ["Use a prefix and an incremental counter."]}, {"choice": "list", "description": ["Use the given name list."]}], "explanation": ["Full list of output field names."]}, {"flag": "outfield.prefix.name", "parameterName": "Output field prefix", "dataType": "String", "explanation": ["Prefix used to form the field names thatwill contain the extracted values."]}, {"flag": "outfield.list.names", "parameterName": "Output field names", "dataType": "String list", "explanation": ["Full list of output field names."]}, {"flag": "field", "parameterName": "Field Name", "dataType": "List", "explanation": []}, {"flag": "layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n The application extracts samples values from animage using positions contained in a vector data file. \n"},
{"name": "TrainDimensionalityReduction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_TrainDimensionalityReduction.html", "label": "Train Dimensionality Reduction", "category": "Learning", "definition": "Train a dimensionality reduction model", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_TrainDimensionalityReduction - io . vd cuprite_samples . sqlite - io . out mode . ae - algorithm pca - algorithm . pca . dim 8 - feat value_0 value_1 value_2 value_3 value_4 value_5 value_6 value_7 value_8 value_9", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the TrainDimensionalityReduction application TrainDimensionalityReduction = otbApplication . Registry . CreateApplication ( \"TrainDimensionalityReduction\" ) # The following lines set all the application parameters: TrainDimensionalityReduction . SetParameterString ( \"io.vd\" , \"cuprite_samples.sqlite\" ) TrainDimensionalityReduction . SetParameterString ( \"io.out\" , \"mode.ae\" ) TrainDimensionalityReduction . SetParameterString ( \"algorithm\" , \"pca\" ) TrainDimensionalityReduction . SetParameterInt ( \"algorithm.pca.dim\" , 8 ) TrainDimensionalityReduction . SetParameterStringList ( \"feat\" , [ 'value_0' , 'value_1' , 'value_2' , 'value_3' , 'value_4' , 'value_5' , 'value_6' , 'value_7' , 'value_8' , 'value_9' ]) # The following line execute the application TrainDimensionalityReduction . ExecuteAndWriteOutput ()"], "command": "otbcli_TrainDimensionalityReduction", "parameters": [{"flag": "io.vd", "parameterName": "Input Vector Data", "dataType": "Input vector data", "explanation": ["Input geometries used for training (note : all geometries from the layer will be used)."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output model", "dataType": "Output File name", "explanation": ["Output file containing the estimated model (.txt format)."], "isOutputFile": true}, {"flag": "io.stats", "parameterName": "Input XML image statistics file", "dataType": "Input File name", "explanation": ["XML file containing mean and variance of each feature."], "isInputFile": true}, {"flag": "algorithm.autoencoder.learningcurve", "parameterName": "Learning curve", "dataType": "Output File name", "explanation": ["Learning error values."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "feat", "parameterName": "Field names to be used for training.", "dataType": "String list", "explanation": []}, {"flag": "algorithm", "parameterName": "algorithm to use for the training", "dataType": "Choices", "availableChoices": [{"choice": "som", "description": ["This group of parameters allows setting SOM parameters. ."]}, {"choice": "autoencoder", "description": ["This group of parameters allows setting Shark autoencoder parameters. ."]}, {"choice": "pca", "description": ["This group of parameters allows setting Shark PCA parameters. ."]}], "explanation": []}, {"flag": "algorithm.som.s", "parameterName": "Map size", "dataType": "String list", "explanation": ["Sizes of the SOM map (one per dimension). For instance, [12;15] means a 2D map of size 12x15. Support2D to 5D maps."]}, {"flag": "algorithm.som.n", "parameterName": "Neighborhood sizes", "dataType": "String list", "explanation": ["Sizes of the initial neighborhood in the SOM map (one per dimension). The number of sizes should be the same as the map sizes."]}, {"flag": "algorithm.som.ni", "parameterName": "NumberIteration", "dataType": "Int", "explanation": ["Number of iterations for SOM learning."]}, {"flag": "algorithm.som.bi", "parameterName": "BetaInit", "dataType": "Float", "explanation": ["Initial learning coefficient."]}, {"flag": "algorithm.som.bf", "parameterName": "BetaFinal", "dataType": "Float", "explanation": ["Final learning coefficient."]}, {"flag": "algorithm.som.iv", "parameterName": "InitialValue", "dataType": "Float", "explanation": ["Maximum initial neuron weight."]}, {"flag": "algorithm.autoencoder.nbiter", "parameterName": "Maximum number of iterations during training", "dataType": "Int", "explanation": ["The maximum number of iterations used during fine tuning of the whole network."]}, {"flag": "algorithm.autoencoder.nbiterfinetuning", "parameterName": "Maximum number of iterations during training", "dataType": "Int", "explanation": ["The maximum number of iterations used during fine tuning of the whole network."]}, {"flag": "algorithm.autoencoder.epsilon", "parameterName": "Epsilon", "dataType": "Float", "explanation": ["Epsilon."]}, {"flag": "algorithm.autoencoder.initfactor", "parameterName": "Weight initialization factor", "dataType": "Float", "explanation": ["Parameter that control the weight initialization of the autoencoder."]}, {"flag": "algorithm.autoencoder.nbneuron", "parameterName": "Size", "dataType": "String list", "explanation": ["The number of neurons in each hidden layer."]}, {"flag": "algorithm.autoencoder.regularization", "parameterName": "Strength of the regularization", "dataType": "String list", "explanation": ["Strength of the L2 regularization used during training."]}, {"flag": "algorithm.autoencoder.noise", "parameterName": "Strength of the noise", "dataType": "String list", "explanation": ["Strength of the noise."]}, {"flag": "algorithm.autoencoder.rho", "parameterName": "Sparsity parameter", "dataType": "String list", "explanation": ["Sparsity parameter."]}, {"flag": "algorithm.autoencoder.beta", "parameterName": "Sparsity regularization strength", "dataType": "String list", "explanation": ["Sparsity regularization strength."]}, {"flag": "algorithm.pca.dim", "parameterName": "Dimension of the output of the pca transformation", "dataType": "Int", "explanation": ["Dimension of the output of the pca transformation."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n Trainer for dimensionality reduction algorithms (autoencoders, PCA, SOM). All input samples are used to compute the model, like other machine learning models.\nThe model can be used in the ImageDimensionalityReduction and VectorDimensionalityReduction applications. \n"},
{"name": "SampleSelection", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SampleSelection.html", "label": "Sample Selection", "category": "Learning", "definition": "Selects samples from a training vector data set.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SampleSelection - in support_image . tif - vec variousVectors . sqlite - field label - instats apTvClPolygonClassStatisticsOut . xml - out resampledVectors . sqlite", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SampleSelection application SampleSelection = otbApplication . Registry . CreateApplication ( \"SampleSelection\" ) # The following lines set all the application parameters: SampleSelection . SetParameterString ( \"in\" , \"support_image.tif\" ) SampleSelection . SetParameterString ( \"vec\" , \"variousVectors.sqlite\" ) # The following line execute the application SampleSelection . ExecuteAndWriteOutput ()"], "command": "otbcli_SampleSelection", "parameters": [{"flag": "in", "parameterName": "InputImage", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "mask", "parameterName": "InputMask", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "vec", "parameterName": "Input vectors", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output vectors", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "instats", "parameterName": "Input Statistics", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "outrates", "parameterName": "Output rates", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "strategy.byclass.in", "parameterName": "Number of samples by class", "dataType": "Input File name", "explanation": ["Number of samples by class (CSV format with class name in 1st column and required samples in the 2nd."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "sampler", "parameterName": "Sampler type", "dataType": "Choices", "availableChoices": [{"choice": "periodic", "description": ["Takes samples regularly spaced."]}, {"choice": "random", "description": ["The positions to select are randomly shuffled."]}], "explanation": []}, {"flag": "sampler.periodic.jitter", "parameterName": "Jitter amplitude", "dataType": "Int", "explanation": ["Jitter amplitude added during sample selection (0 = no jitter)."]}, {"flag": "strategy", "parameterName": "Sampling strategy", "dataType": "Choices", "availableChoices": [{"choice": "byclass", "description": ["Set samples count for each class."]}, {"choice": "constant", "description": ["Set the same samples counts for all classes."]}, {"choice": "percent", "description": ["Use a percentage of the samples available for each class."]}, {"choice": "total", "description": ["Set the total number of samples to generate, and use class proportions."]}, {"choice": "smallest", "description": ["Set same number of samples for all classes, with the smallest class fully sampled."]}, {"choice": "all", "description": ["Take all samples."]}], "explanation": []}, {"flag": "strategy.constant.nb", "parameterName": "Number of samples for all classes", "dataType": "Int", "explanation": ["Number of samples for all classes."]}, {"flag": "strategy.percent.p", "parameterName": "The percentage to use", "dataType": "Float", "explanation": ["The percentage to use."]}, {"flag": "strategy.total.v", "parameterName": "The number of samples to generate", "dataType": "Int", "explanation": ["The number of samples to generate."]}, {"flag": "field", "parameterName": "Field Name", "dataType": "List", "explanation": []}, {"flag": "layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n The application selects a set of samples from geometries intended for training (they should have a field giving the associated class). \n First of all, the geometries must be analyzed by the PolygonClassStatistics application to compute statistics about the geometries, which are summarized in an xml file.\nThen, this xml file must be given as input to this application (parameter instats). \n The input support image and the input training vectors shall be given in parameters \u2018in\u2019 and \u2018vec\u2019 respectively. Only the sampling grid (origin, size, spacing)will be read in the input image.\nThere are several strategies to select samples (parameter strategy) : \n \n \n smallest (default) : select the same number of sample in each class so that the smallest one is fully sampled. \n constant : select the same number of samples N in each class (with N below or equal to the size of the smallest class). \n byclass : set the required number for each class manually, with an input CSV file (first column is class name, second one is the required samples number). \n percent: set a target global percentage of samples to use. Class proportions will be respected. \n total: set a target total number of samples to use. Class proportions will be respected. \n \n \n There is also a choice on the sampling type to performs : \n \n \n periodic : select samples uniformly distributed \n random : select samples randomly distributed \n \n \n Once the strategy and type are selected, the application outputs samples positions(parameter out). \n The other parameters to look at are : \n \n \n layer : index specifying from which layer to pick geometries. \n field : set the field name containing the class. \n mask : an optional raster mask can be used to discard samples. \n outrates : allows outputting a CSV file that summarizes the sampling rates for each class. \n \n \n As with the PolygonClassStatistics application, different types  of geometry are supported : polygons, lines, points.\nThe behavior of this application is different for each type of geometry : \n \n \n polygon: select points whose center is inside the polygon \n lines  : select points intersecting the line \n points : select closest point to the provided point \n \n \n"},
{"name": "SampleAugmentation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SampleAugmentation.html", "label": "Sample Augmentation", "category": "Learning", "definition": "Generates synthetic samples from a sample data file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SampleAugmentation application SampleAugmentation = otbApplication . Registry . CreateApplication ( \"SampleAugmentation\" ) # The following lines set all the application parameters: SampleAugmentation . SetParameterString ( \"in\" , \"samples.sqlite\" ) # The following line execute the application SampleAugmentation . ExecuteAndWriteOutput ()"], "command": null, "parameters": [{"flag": "in", "parameterName": "Input samples", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output samples", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "field", "parameterName": "Field Name", "dataType": "List", "explanation": []}, {"flag": "layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": []}, {"flag": "label", "parameterName": "Label of the class to be augmented", "dataType": "Int", "explanation": []}, {"flag": "samples", "parameterName": "Number of generated samples", "dataType": "Int", "explanation": []}, {"flag": "exclude", "parameterName": "Field names for excluded features.", "dataType": "List", "explanation": []}, {"flag": "strategy", "parameterName": "Augmentation strategy", "dataType": "Choices", "availableChoices": [{"choice": "replicate", "description": ["The new samples are generated by replicating input samples which are randomly selected with replacement."]}, {"choice": "jitter", "description": ["The new samples are generated by adding gaussian noise to input samples which are randomly selected with replacement."]}, {"choice": "smote", "description": ["The new samples are generated by using the SMOTE algorithm ("]}], "explanation": []}, {"flag": "strategy.jitter.stdfactor", "parameterName": "Factor for dividing the standard deviation of each feature", "dataType": "Float", "explanation": ["The noise added to the input samples will have the standard deviation of the input features divided by the value of this parameter. ."]}, {"flag": "strategy.smote.neighbors", "parameterName": "Number of nearest neighbors.", "dataType": "Int", "explanation": ["Number of nearest neighbors to be used in the SMOTE algorithm."]}, {"flag": "seed", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n The application takes a sample data file as generated by the SampleExtraction application and generates synthetic samples to increase the number of available samples. \n"},
{"name": "SOMClassification", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SOMClassification.html", "label": "SOM Classification", "category": "Learning", "definition": "SOM image classification.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SOMClassification - in QB_1_ortho . tif - out SOMClassification . tif - tp 1.0 - ts 16384 - sx 32 - sy 32 - nx 10 - ny 10 - ni 5 - bi 1.0 - bf 0.1 - iv 0", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SOMClassification application SOMClassification = otbApplication . Registry . CreateApplication ( \"SOMClassification\" ) # The following lines set all the application parameters: SOMClassification . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) SOMClassification . SetParameterString ( \"out\" , \"SOMClassification.tif\" ) SOMClassification . SetParameterFloat ( \"tp\" , 1.0 ) SOMClassification . SetParameterInt ( \"ts\" , 16384 ) SOMClassification . SetParameterInt ( \"sx\" , 32 ) SOMClassification . SetParameterInt ( \"sy\" , 32 ) SOMClassification . SetParameterInt ( \"nx\" , 10 ) SOMClassification . SetParameterInt ( \"ny\" , 10 ) SOMClassification . SetParameterInt ( \"ni\" , 5 ) SOMClassification . SetParameterFloat ( \"bi\" , 1.0 ) SOMClassification . SetParameterFloat ( \"bf\" , 0.1 ) SOMClassification . SetParameterFloat ( \"iv\" , 0 ) # The following line execute the application SOMClassification . ExecuteAndWriteOutput ()"], "command": "otbcli_SOMClassification", "parameters": [{"flag": "in", "parameterName": "InputImage", "dataType": "Input image", "explanation": ["Input image to classify."], "isInputFile": true}, {"flag": "out", "parameterName": "OutputImage", "dataType": "Output image", "explanation": ["Output classified image (each pixel contains the index of its corresponding vector in the SOM)."], "isOutputFile": true}, {"flag": "vm", "parameterName": "ValidityMask", "dataType": "Input image", "explanation": ["Validity mask (only pixels corresponding to a mask value greater than 0 will be used for learning)."], "isInputFile": true}, {"flag": "som", "parameterName": "SOM Map", "dataType": "Output image", "explanation": ["Output image containing the Self-Organizing Map."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "tp", "parameterName": "TrainingProbability", "dataType": "Float", "explanation": ["Probability for a sample to be selected in the training set."]}, {"flag": "ts", "parameterName": "TrainingSetSize", "dataType": "Int", "explanation": ["Maximum training set size (in pixels)."]}, {"flag": "sx", "parameterName": "SizeX", "dataType": "Int", "explanation": ["X size of the SOM map."]}, {"flag": "sy", "parameterName": "SizeY", "dataType": "Int", "explanation": ["Y size of the SOM map."]}, {"flag": "nx", "parameterName": "NeighborhoodX", "dataType": "Int", "explanation": ["X size of the initial neighborhood in the SOM map."]}, {"flag": "ny", "parameterName": "NeighborhoodY", "dataType": "Int", "explanation": ["Y size of the initial neighborhood in the SOM map."]}, {"flag": "ni", "parameterName": "NumberIteration", "dataType": "Int", "explanation": ["Number of iterations for SOM learning."]}, {"flag": "bi", "parameterName": "BetaInit", "dataType": "Float", "explanation": ["Initial learning coefficient."]}, {"flag": "bf", "parameterName": "BetaFinal", "dataType": "Float", "explanation": ["Final learning coefficient."]}, {"flag": "iv", "parameterName": "InitialValue", "dataType": "Float", "explanation": ["Maximum initial neuron weight."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": ["Set specific seed. with integer value."]}], "description": "\n   \n Unsupervised Self Organizing Map image classification. \n"},
{"name": "PredictRegression", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_PredictRegression.html", "label": "Predict Regression", "category": "Learning", "definition": "Performs a prediction of the input image according to a regression model file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_PredictRegression - in QB_1_ortho . tif - imstat EstimateImageStatisticsQB1 . xml - model clsvmModelQB1 . svm - out clLabeledImageQB1 . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the PredictRegression application PredictRegression = otbApplication . Registry . CreateApplication ( \"PredictRegression\" ) # The following lines set all the application parameters: PredictRegression . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) PredictRegression . SetParameterString ( \"imstat\" , \"EstimateImageStatisticsQB1.xml\" ) PredictRegression . SetParameterString ( \"model\" , \"clsvmModelQB1.svm\" ) PredictRegression . SetParameterString ( \"out\" , \"clLabeledImageQB1.tif\" ) # The following line execute the application PredictRegression . ExecuteAndWriteOutput ()"], "command": "otbcli_PredictRegression", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to predict."], "isInputFile": true}, {"flag": "mask", "parameterName": "Input Mask", "dataType": "Input image", "explanation": ["The mask allow restricting classification of the input image to the area where mask pixel values are greater than 0."], "isInputFile": true}, {"flag": "model", "parameterName": "Model file", "dataType": "Input File name", "explanation": ["A regression model file (produced by TrainRegression application)."], "isInputFile": true}, {"flag": "imstat", "parameterName": "Statistics file", "dataType": "Input File name", "explanation": ["A XML file containing mean and standard deviation to center and reduce samples before prediction (produced by ComputeImagesStatistics application). If this file containsone more band than the sample size, the last stat of last band will beapplied to expand the output predicted value."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image containing predicted values."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application predict output values from an input image, based on a regression model file produced by the TrainRegression application. Pixels of the output image will contain the predicted values fromthe regression model (single band). The input pixels can be optionally centered and reduced according to the statistics file produced by the ComputeImagesStatistics application. An optional input mask can be provided, in which case only input image pixels whose corresponding mask value is greater than 0 will be processed. The remaining of pixels will be given the value 0 in the output image. \n"},
{"name": "MultiImageSamplingRate", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MultiImageSamplingRate.html", "label": "Multi", "category": "Learning", "definition": "Compute sampling rate for an input set of images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MultiImageSamplingRate - il stats_1 . xml stats_2 . xml - out rates . csv - strategy smallest - mim proportional", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MultiImageSamplingRate application MultiImageSamplingRate = otbApplication . Registry . CreateApplication ( \"MultiImageSamplingRate\" ) # The following lines set all the application parameters: MultiImageSamplingRate . SetParameterString ( \"out\" , \"rates.csv\" ) MultiImageSamplingRate . SetParameterString ( \"strategy\" , \"smallest\" ) MultiImageSamplingRate . SetParameterString ( \"mim\" , \"proportional\" ) # The following line execute the application MultiImageSamplingRate . ExecuteAndWriteOutput ()"], "command": "otbcli_MultiImageSamplingRate", "parameters": [{"flag": "il", "parameterName": "Input statistics", "dataType": "Input File name list", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output sampling rates", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "strategy.byclass.in", "parameterName": "Number of samples by class", "dataType": "Input File name list", "explanation": ["Number of samples by class (CSV format with class name in 1st column and required samples in the 2nd).In the case of the custom multi-image mode, several inputs may be given for each image."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "strategy", "parameterName": "Sampling strategy", "dataType": "Choices", "availableChoices": [{"choice": "byclass", "description": ["Set samples count for each class."]}, {"choice": "constant", "description": ["Set the same samples counts for all classes."]}, {"choice": "smallest", "description": ["Set same number of samples for all classes, with the smallest class fully sampled."]}, {"choice": "percent", "description": ["Use a percentage of the samples available for each class."]}, {"choice": "total", "description": ["Set the total number of samples to generate, and use class proportions."]}, {"choice": "all", "description": ["Take all samples."]}], "explanation": []}, {"flag": "strategy.constant.nb", "parameterName": "Number of samples for all classes", "dataType": "String", "explanation": ["Number of samples for all classes.In the case of the custom multi-image mode, several values can be given for each image."]}, {"flag": "strategy.percent.p", "parameterName": "The percentage(s) to use", "dataType": "String", "explanation": ["The percentage(s) to use In the case of the custom multi-image mode, several values can be given for each image."]}, {"flag": "strategy.total.v", "parameterName": "The number of samples to generate", "dataType": "String", "explanation": ["The number of samples to generateIn the case of the custom multi-image mode, several values can be given for each image."]}, {"flag": "mim", "parameterName": "Multi-Image Mode", "dataType": "Choices", "availableChoices": [{"choice": "proportional", "description": ["Split proportionally the required number of samples."]}, {"choice": "equal", "description": ["Split equally the required number of samples."]}, {"choice": "custom", "description": ["Split the required number of samples following user choice."]}], "explanation": []}], "description": "\n   \n The application computes sampling rates for a set of input images. Before calling this application, each pair of image and training vectors has to be analysed with the application PolygonClassStatistics. The statistics file is then used to compute the sampling rates for each class in each image. Several types of sampling  are implemented. Each one is a combination of a mono-image strategy and a multi-image mode. The mono-image strategies are : \n \n \n smallest (default) : select the same number of sample in each class so that the smallest one is fully sampled. \n constant : select the same number of samples N in each class (with N below or equal to the size of the smallest class). \n byclass : set the required number for each class manually, with an input CSV file (first column is class name, second one is the required samples number). \n \n \n \n The multi-image modes (mim) are proportional, equal and custom. The custom mode lets the users choose the distribution of samples among the images. The different behaviours are described below. Ti(c) and Ni(c)  refers resp. to the total number and needed number of samples in image i for class c. Let\u2019s call L the total number of images. \n \n strategy = all \n Same behaviour for all modes : take all samples \n \n \n strategy = constant : let\u2019s call M the global number of samples required per class. For each image i and each class c: \n if mim = proportional, then Ni( c ) = M * Ti( c ) / sum_k( Tk(c) ) \n if mim = equal       , then Ni( c ) = M / L \n if mim = custom      , then Ni( c ) = Mi where Mi is the custom requested number of samples for image i \n \n \n strategy = byClass : let\u2019s call M(c) the global number of samples for class c). For each image i and each class c: \n if mim = proportional, then Ni( c ) = M(c) * Ti( c ) / sum_k( Tk(c) ) \n if mim = equal       , then Ni( c ) = M(c) / L \n if mim = custom      , then Ni( c ) = Mi(c) where Mi(c) is the custom requested number of samples for image i and class c \n \n \n strategy = percent : For each image i and each class c: \n if mim = proportional, then Ni( c ) = p * Ti( c ) where p is the global percentage of samples \n if mim = equal       , then Ni( c ) = p * sum_k(Tk(c)]/L where p is the global percentage of samples \n if mim = custom      , then Ni( c ) = p(i) * Ti(c) where p(i) is the percentage of samples for image i. c \n \n \n strategy = total : For each image i and each class c: \n if mim = proportional, then Ni( c ) = total * (sum_k(Ti(k))/sum_kl(Tl(k))) * (Ti(c)/sum_k(Ti(k))) where total is the total number of samples specified. \n if mim = equal       , then Ni( c ) = (total / L) * (Ti(c)/sum_k(Ti(k))) where total is the total number of samples specified. \n if mim = custom      , then Ni( c ) = total(i) * (Ti(c)/sum_k(Ti(k))) where total(i) is the total number of samples specified for image i. \n \n \n strategy = smallest class \n if mim = proportional, then the smallest class size (computed globally) is used for the strategy constant+proportional. \n if mim = equal       , then the smallest class size (computed globally) is used for the strategy constant+equal. \n if mim = custom      , then the smallest class is computed and used for each image separately. \n \n \n \n \n \n"},
{"name": "PolygonClassStatistics", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_PolygonClassStatistics.html", "label": "Polygon Class Statistics", "category": "Learning", "definition": "Computes statistics on a training polygon set.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_PolygonClassStatistics - in support_image . tif - vec variousVectors . sqlite - field label - out polygonStat . xml", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the PolygonClassStatistics application PolygonClassStatistics = otbApplication . Registry . CreateApplication ( \"PolygonClassStatistics\" ) # The following lines set all the application parameters: PolygonClassStatistics . SetParameterString ( \"in\" , \"support_image.tif\" ) PolygonClassStatistics . SetParameterString ( \"vec\" , \"variousVectors.sqlite\" ) # The following line execute the application PolygonClassStatistics . ExecuteAndWriteOutput ()"], "command": "otbcli_PolygonClassStatistics", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "mask", "parameterName": "Input validity mask", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "vec", "parameterName": "Input vectors", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output XML statistics file", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "field", "parameterName": "Field Name", "dataType": "List", "explanation": []}, {"flag": "layer", "parameterName": "Layer Index", "dataType": "Int", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n The application processes a set of geometries intended for training (they should have a field giving the associated class). The geometries are analyzed against a support image to compute statistics : \n \n number of samples per class \n number of samples per geometry \n \n \n An optional raster mask can be used to discard samples. Different types of geometry are supported \n  :   polygons, lines, points. The behaviour is different for each type of geometry : \n polygon: select pixels whose center is inside the polygon \n lines  : select pixels intersecting the line \n points : select closest pixel to the point \n \n \n \n"},
{"name": "KMeansClassification", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_KMeansClassification.html", "label": "Unsupervised KMeans image classification", "category": "Learning", "definition": "Unsupervised KMeans image classification", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_KMeansClassification - in QB_1_ortho . tif - ts 1000 - nc 5 - maxit 1000 - out ClassificationFilterOutput . tif uint8", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the KMeansClassification application KMeansClassification = otbApplication . Registry . CreateApplication ( \"KMeansClassification\" ) # The following lines set all the application parameters: KMeansClassification . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) KMeansClassification . SetParameterInt ( \"ts\" , 1000 ) KMeansClassification . SetParameterInt ( \"nc\" , 5 ) KMeansClassification . SetParameterInt ( \"maxit\" , 1000 ) KMeansClassification . SetParameterString ( \"out\" , \"ClassificationFilterOutput.tif\" ) KMeansClassification . SetParameterOutputImagePixelType ( \"out\" , 1 ) # The following line execute the application KMeansClassification . ExecuteAndWriteOutput ()"], "command": "otbcli_KMeansClassification", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "outmeans", "parameterName": "Centroid filename", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "vm", "parameterName": "Validity Mask", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "nc", "parameterName": "Number of classes", "dataType": "Int", "explanation": []}, {"flag": "ts", "parameterName": "Training set size", "dataType": "Int", "explanation": []}, {"flag": "maxit", "parameterName": "Maximum number of iterations", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "sampler", "parameterName": "Sampler type", "dataType": "Choices", "availableChoices": [{"choice": "periodic", "description": ["Takes samples regularly spaced."]}, {"choice": "random", "description": ["The positions to select are randomly shuffled."]}], "explanation": []}, {"flag": "sampler.periodic.jitter", "parameterName": "Jitter amplitude", "dataType": "Int", "explanation": ["Jitter amplitude added during sample selection (0 = no jitter)."]}, {"flag": "nodatalabel", "parameterName": "Label mask value", "dataType": "Int", "explanation": []}, {"flag": "cleanup", "parameterName": "Temporary files cleaning", "dataType": "Boolean", "explanation": []}, {"flag": "rand", "parameterName": "set user defined seed", "dataType": "Int", "explanation": []}], "description": "\n   \n Performs unsupervised KMeans image classification.KMeansClassification is a composite application, using an existing training and classification application.The SharkKMeans model is used.\nKMeansClassification application is only available if OTB is compiled with Shark support(CMake option OTB_USE_SHARK=ON)\nThe steps of this composite application :\n1) ImageEnveloppe : create a shapefile (1 polygon),\n2) PolygonClassStatistics : compute the statistics,\n3) SampleSelection : select the samples by constant strategy in the shapefile (1000000 samples max),\n4) SamplesExtraction : extract the samples descriptors (update of SampleSelection output file),\n5) ComputeImagesStatistics : compute images second order statistics,\n6) TrainVectorClassifier : train the SharkKMeans model,\n7) ImageClassifier : performs the classification of the input image according to a model file. \n It\u2019s possible to choice random/periodic modes of the SampleSelection application.\nIf you want keep the temporary files (sample selected, model file, ...), initialize cleanup parameter.\nFor more information on shark KMeans algorithm [1]. \n"},
{"name": "ImageClassifier", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ImageClassifier.html", "label": "Image Classification", "category": "Learning", "definition": "Performs a classification of the input image according to a model file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ImageClassifier - in QB_1_ortho . tif - imstat EstimateImageStatisticsQB1 . xml - model clsvmModelQB1 . svm - out clLabeledImageQB1 . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ImageClassifier application ImageClassifier = otbApplication . Registry . CreateApplication ( \"ImageClassifier\" ) # The following lines set all the application parameters: ImageClassifier . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) ImageClassifier . SetParameterString ( \"imstat\" , \"EstimateImageStatisticsQB1.xml\" ) ImageClassifier . SetParameterString ( \"model\" , \"clsvmModelQB1.svm\" ) ImageClassifier . SetParameterString ( \"out\" , \"clLabeledImageQB1.tif\" ) # The following line execute the application ImageClassifier . ExecuteAndWriteOutput ()"], "command": "otbcli_ImageClassifier", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to classify."], "isInputFile": true}, {"flag": "mask", "parameterName": "Input Mask", "dataType": "Input image", "explanation": ["The mask allows restricting classification of the input image to the area where mask pixel values are greater than 0."], "isInputFile": true}, {"flag": "model", "parameterName": "Model file", "dataType": "Input File name", "explanation": ["A model file (produced by TrainImagesClassifier application, maximal class label = 65535)."], "isInputFile": true}, {"flag": "imstat", "parameterName": "Statistics file", "dataType": "Input File name", "explanation": ["A XML file containing mean and standard deviation to center and reduce samples before classification (produced by ComputeImagesStatistics application)."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image containing class labels."], "isOutputFile": true}, {"flag": "confmap", "parameterName": "Confidence map", "dataType": "Output image", "explanation": ["Confidence map of the produced classification. The confidence index depends on the model :    - LibSVM : difference between the two highest probabilities (needs a model with probability estimates, so that classes probabilities can be computed for each sample)   - OpenCV     * Boost : sum of votes     * DecisionTree : (not supported)     * GradientBoostedTree : (not supported)     * KNearestNeighbors : number of neighbors with the same label     * NeuralNetwork : difference between the two highest responses     * NormalBayes : (not supported)     * RandomForest : Confidence (proportion of votes for the majority class). Margin (normalized difference of the votes of the 2 majority classes) is not available for now.     * SVM : distance to margin (only works for 2-class models) ."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "nodatalabel", "parameterName": "Label mask value", "dataType": "Int", "explanation": ["By default, hidden pixels will have the assigned label 0 in the output image. It\u2019s possible to define the label mask by another value, but be careful to not take a label from another class (max. 65535)."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application performs an image classification based on a model file produced by the TrainImagesClassifier application. Pixels of the output image will contain the class labels decided by the classifier (maximal class label = 65535). The input pixels can be optionally centered and reduced according to the statistics file produced by the ComputeImagesStatistics application. An optional input mask can be provided, in which case only input image pixels whose corresponding mask value is greater than 0 will be classified. By default, the remaining of pixels will be given the label 0 in the output image. \n"},
{"name": "ImageDimensionalityReduction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ImageDimensionalityReduction.html", "label": "Image Dimensionality Reduction", "category": "Learning", "definition": "Performs dimensionality reduction of the input image according to a dimensionality reduction model file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ImageDimensionalityReduction - in QB_1_ortho . tif - imstat EstimateImageStatisticsQB1 . xml - model clsvmModelQB1 . model - out ReducedImageQB1 . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ImageDimensionalityReduction application ImageDimensionalityReduction = otbApplication . Registry . CreateApplication ( \"ImageDimensionalityReduction\" ) # The following lines set all the application parameters: ImageDimensionalityReduction . SetParameterString ( \"in\" , \"QB_1_ortho.tif\" ) ImageDimensionalityReduction . SetParameterString ( \"imstat\" , \"EstimateImageStatisticsQB1.xml\" ) ImageDimensionalityReduction . SetParameterString ( \"model\" , \"clsvmModelQB1.model\" ) ImageDimensionalityReduction . SetParameterString ( \"out\" , \"ReducedImageQB1.tif\" ) # The following line execute the application ImageDimensionalityReduction . ExecuteAndWriteOutput ()"], "command": "otbcli_ImageDimensionalityReduction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to predict."], "isInputFile": true}, {"flag": "mask", "parameterName": "Input Mask", "dataType": "Input image", "explanation": ["The mask allow restricting classification of the input image to the area where mask pixel values are greater than 0."], "isInputFile": true}, {"flag": "model", "parameterName": "Model file", "dataType": "Input File name", "explanation": ["A dimensionality reduction model file (produced by TrainRegression application)."], "isInputFile": true}, {"flag": "imstat", "parameterName": "Statistics file", "dataType": "Input File name", "explanation": ["A XML file containing mean and standard deviation to center and reduce samples before prediction (produced by ComputeImagesStatistics application). If this file containsone more bands than the sample size, the last stat of last band will beapplied to expand the output predicted value."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["Output image containing reduced values."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application reduces the dimension of an input image, based on a machine learning model file produced by the TrainDimensionalityReduction application. Pixels of the output image will contain the reduced values fromthe model. The input pixels can be optionally centered and reduced according to the statistics file produced by the ComputeImagesStatistics application. \n"},
{"name": "FusionOfClassifications", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_FusionOfClassifications.html", "label": "Fusion of Classifications", "category": "Learning", "definition": "Fuses several classifications maps of the same image on the basis of class labels.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_FusionOfClassifications - il classification1 . tif classification2 . tif classification3 . tif - method dempstershafer - method . dempstershafer . cmfl classification1 . csv classification2 . csv classification3 . csv - method . dempstershafer . mob precision - nodatalabel 0 - undecidedlabel 10 - out classification_fused . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the FusionOfClassifications application FusionOfClassifications = otbApplication . Registry . CreateApplication ( \"FusionOfClassifications\" ) # The following lines set all the application parameters: FusionOfClassifications . SetParameterStringList ( \"il\" , [ 'classification1.tif' , 'classification2.tif' , 'classification3.tif' ]) FusionOfClassifications . SetParameterString ( \"method\" , \"dempstershafer\" ) FusionOfClassifications . SetParameterString ( \"method.dempstershafer.mob\" , \"precision\" ) FusionOfClassifications . SetParameterInt ( \"nodatalabel\" , 0 ) FusionOfClassifications . SetParameterInt ( \"undecidedlabel\" , 10 ) FusionOfClassifications . SetParameterString ( \"out\" , \"classification_fused.tif\" ) # The following line execute the application FusionOfClassifications . ExecuteAndWriteOutput ()"], "command": "otbcli_FusionOfClassifications", "parameters": [{"flag": "il", "parameterName": "Input classifications", "dataType": "Input image list", "explanation": [], "isInputFile": true}, {"flag": "method.dempstershafer.cmfl", "parameterName": "Confusion Matrices", "dataType": "Input File name list", "explanation": ["A list of confusion matrix files (*.CSV format) to define the masses of belief and the class labels. Each file should be formatted the following way: the first line, beginning with a \u2018#\u2019 symbol, should be a list of the class labels present in the corresponding input classification image, organized in the same order as the confusion matrix rows/columns."], "isInputFile": true}, {"flag": "out", "parameterName": "The output classification image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "method", "parameterName": "Fusion method", "dataType": "Choices", "availableChoices": [{"choice": "majorityvoting", "description": ["Fusion of classification maps by majority voting for each output pixel."]}, {"choice": "dempstershafer", "description": ["Fusion of classification maps by the Dempster Shafer combination method for each output pixel."]}], "explanation": []}, {"flag": "method.dempstershafer.mob", "parameterName": "Mass of belief measurement", "dataType": "Choices", "availableChoices": [{"choice": "precision", "description": ["Masses of belief = Precision rates of each classifier (one rate per class label)."]}, {"choice": "recall", "description": ["Masses of belief = Recall rates of each classifier (one rate per class label)."]}, {"choice": "accuracy", "description": ["Mass of belief = Overall Accuracy of each classifier (one unique value for all the class labels)."]}, {"choice": "kappa", "description": ["Mass of belief = Kappa coefficient of each classifier (one unique value for all the class labels)."]}], "explanation": ["Type of confusion matrix measurement used to compute the masses of belief of each classifier. Available choices are:"]}, {"flag": "nodatalabel", "parameterName": "Label for the NoData class", "dataType": "Int", "explanation": []}, {"flag": "undecidedlabel", "parameterName": "Label for the Undecided class", "dataType": "Int", "explanation": []}], "description": "\n   \n This application allows you to fuse several classification maps and produces a single more robust classification map. Fusion is done either by mean of Majority Voting, or with the Dempster Shafer combination method on class labels. \n \n \n MAJORITY VOTING: for each pixel, the class with the highest number of votes is selected. \n DEMPSTER SHAFER: for each pixel, the class label for which the Belief Function is maximal is selected. This Belief Function is calculated by mean of the Dempster Shafer combination of Masses of Belief, and indicates the belief that each input classification map presents for each label value. Moreover, the Masses of Belief are based on the input confusion matrices of each classification map, either by using the PRECISION or RECALL rates, or the OVERALL ACCURACY, or the KAPPA coefficient. Thus, each input classification map needs to be associated with its corresponding input confusion matrix file for the Dempster Shafer fusion. \n Input pixels with the NODATA label are not handled in the fusion of classification maps. Moreover, pixels for which all the input classifiers are set to NODATA keep this value in the output fused image. \n In case of number of votes equality, the UNDECIDED label is attributed to the pixel. \n \n \n"},
{"name": "ComputeConfusionMatrix", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ComputeConfusionMatrix.html", "label": "Confusion matrix Computation", "category": "Learning", "definition": "Computes the confusion matrix of a classification", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ComputeConfusionMatrix - in clLabeledImageQB1 . tif - out ConfusionMatrix . csv - ref vector - ref . vector . in VectorData_QB1_bis . shp - ref . vector . field Class - ref . vector . nodata 255", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ComputeConfusionMatrix application ComputeConfusionMatrix = otbApplication . Registry . CreateApplication ( \"ComputeConfusionMatrix\" ) # The following lines set all the application parameters: ComputeConfusionMatrix . SetParameterString ( \"in\" , \"clLabeledImageQB1.tif\" ) ComputeConfusionMatrix . SetParameterString ( \"out\" , \"ConfusionMatrix.csv\" ) ComputeConfusionMatrix . SetParameterString ( \"ref\" , \"vector\" ) ComputeConfusionMatrix . SetParameterString ( \"ref.vector.in\" , \"VectorData_QB1_bis.shp\" ) # The following line execute the application ComputeConfusionMatrix . ExecuteAndWriteOutput ()"], "command": "otbcli_ComputeConfusionMatrix", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Matrix output", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "ref.raster.in", "parameterName": "Input reference image", "dataType": "Input image", "explanation": ["Input image containing the ground truth labels."], "isInputFile": true}, {"flag": "ref.vector.in", "parameterName": "Input reference vector data", "dataType": "Input File name", "explanation": ["Input vector data of the ground truth."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "format", "parameterName": "set the output format to contingency table or confusion matrix", "dataType": "Choices", "availableChoices": [{"choice": "confusionmatrix", "description": []}, {"choice": "contingencytable", "description": []}], "explanation": []}, {"flag": "ref", "parameterName": "Ground truth", "dataType": "Choices", "availableChoices": [{"choice": "raster", "description": []}, {"choice": "vector", "description": []}], "explanation": []}, {"flag": "ref.raster.nodata", "parameterName": "Value for nodata pixels in ref raster", "dataType": "Int", "explanation": ["Label to be treated as no data in ref raster."]}, {"flag": "ref.vector.field", "parameterName": "Field name", "dataType": "List", "explanation": ["Field name containing the label values."]}, {"flag": "ref.vector.nodata", "parameterName": "Value for nodata pixels in ref vector", "dataType": "Int", "explanation": ["Label to be treated as no data in ref vector. Please note that this value is always used in vector mode, to generate default values. Please set it to a value that does not correspond to a class label."]}, {"flag": "nodatalabel", "parameterName": "Value for nodata pixels in input image", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application computes the confusion matrix of a classification map relative to a ground truth dataset. This ground truth can be given as a raster or a vector data. Only reference and produced pixels with values different from NoData are handled in the calculation of the confusion matrix. The confusion matrix is organized the following way: rows = reference labels, columns = produced labels. In the header of the output file, the reference and produced class labels are ordered according to the rows/columns of the confusion matrix. \n"},
{"name": "ComputeImagesStatistics", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ComputeImagesStatistics.html", "label": "Compute Images second order statistics", "category": "Learning", "definition": "Computes global mean and standard deviation for each band from a set of images and optionally saves the results in an XML file.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ComputeImagesStatistics - il QB_1_ortho . tif - out EstimateImageStatisticsQB1 . xml", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ComputeImagesStatistics application ComputeImagesStatistics = otbApplication . Registry . CreateApplication ( \"ComputeImagesStatistics\" ) # The following lines set all the application parameters: ComputeImagesStatistics . SetParameterStringList ( \"il\" , [ 'QB_1_ortho.tif' ]) ComputeImagesStatistics . SetParameterString ( \"out\" , \"EstimateImageStatisticsQB1.xml\" ) # The following line execute the application ComputeImagesStatistics . ExecuteAndWriteOutput ()"], "command": "otbcli_ComputeImagesStatistics", "parameters": [{"flag": "il", "parameterName": "Input images", "dataType": "Input image list", "explanation": ["List of input image filenames."], "isInputFile": true}, {"flag": "out", "parameterName": "Output XML file", "dataType": "Output File name", "explanation": ["XML filename where the statistics are saved for future reuse."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "bv", "parameterName": "Background Value", "dataType": "Float", "explanation": ["Background value to ignore in computation of statistics."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application computes a global mean and standard deviation for each band of a set of images and optionally saves the results in an XML file. The output XML is intended to be used as an input for the TrainImagesClassifier application to normalize samples before learning. You can also normalize the image with the XML file in the ImageClassifier application. \n"},
{"name": "ClassificationMapRegularization", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ClassificationMapRegularization.html", "label": "Classification Map Regularization", "category": "Learning", "definition": "Filters the input labeled image using Majority Voting in a ball shaped neighbordhood.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ClassificationMapRegularization - io . in clLabeledImageQB123_1 . tif - io . out clLabeledImageQB123_1_CMR_r2_nodl_10_undl_7 . tif - ip . radius 2 - ip . suvbool true - ip . onlyisolatedpixels true - ip . nodatalabel 10 - ip . undecidedlabel 7", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ClassificationMapRegularization application ClassificationMapRegularization = otbApplication . Registry . CreateApplication ( \"ClassificationMapRegularization\" ) # The following lines set all the application parameters: ClassificationMapRegularization . SetParameterString ( \"io.in\" , \"clLabeledImageQB123_1.tif\" ) ClassificationMapRegularization . SetParameterString ( \"io.out\" , \"clLabeledImageQB123_1_CMR_r2_nodl_10_undl_7.tif\" ) ClassificationMapRegularization . SetParameterInt ( \"ip.radius\" , 2 ) ClassificationMapRegularization . SetParameterString ( \"ip.suvbool\" , \"true\" ) ClassificationMapRegularization . SetParameterString ( \"ip.onlyisolatedpixels\" , \"true\" ) ClassificationMapRegularization . SetParameterInt ( \"ip.nodatalabel\" , 10 ) ClassificationMapRegularization . SetParameterInt ( \"ip.undecidedlabel\" , 7 ) # The following line execute the application ClassificationMapRegularization . ExecuteAndWriteOutput ()"], "command": "otbcli_ClassificationMapRegularization", "parameters": [{"flag": "io.in", "parameterName": "Input classification image", "dataType": "Input image", "explanation": ["The input labeled image to regularize."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output regularized image", "dataType": "Output image", "explanation": ["The output regularized labeled image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ip.radius", "parameterName": "Structuring element radius (in pixels)", "dataType": "Int", "explanation": ["The radius of the ball shaped structuring element (expressed in pixels). By default, \u2018ip.radius = 1 pixel\u2019."]}, {"flag": "ip.suvbool", "parameterName": "Multiple majority: Undecided(X)/Original", "dataType": "Boolean", "explanation": ["Pixels with more than 1 majority class are marked as Undecided if this parameter is checked (true), or keep their Original labels otherwise (false). Please note that the Undecided value must be different from existing labels in the input labeled image. By default, \u2018ip.suvbool = false\u2019."]}, {"flag": "ip.nodatalabel", "parameterName": "Label for the NoData class", "dataType": "Int", "explanation": ["Label for the NoData class. Such input pixels keep their NoData label in the output image. By default, \u2018ip.nodatalabel = 0\u2019."]}, {"flag": "ip.undecidedlabel", "parameterName": "Label for the Undecided class", "dataType": "Int", "explanation": ["Label for the Undecided class. By default, \u2018ip.undecidedlabel = 0\u2019."]}, {"flag": "ip.onlyisolatedpixels", "parameterName": "Process isolated pixels only", "dataType": "Boolean", "explanation": ["Only pixels whose label is unique in the neighbordhood will be processed. By default, \u2018ip.onlyisolatedpixels = false\u2019."]}, {"flag": "ip.isolatedthreshold", "parameterName": "Threshold for isolated pixels", "dataType": "Int", "explanation": ["Maximum number of neighbours with the same label as the center pixel to consider that it is an isolated pixel. By default, \u2018ip.isolatedthreshold = 1\u2019."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n \n This application filters the input labeled image (with a maximal class label = 65535) using Majority Voting in a ball shaped neighbordhood. Majority Voting takes the more representative value of all the pixels identified by the ball shaped structuring element and then sets the center pixel to this majority label value. \n -NoData is the label of the NOT classified pixels in the input image. These input pixels keep their NoData label in the output image.\n-Pixels with more than 1 majority class are marked as Undecided if the parameter \u2018ip.suvbool == true\u2019, or keep their Original labels otherwise. \n \n"},
{"name": "Superimpose", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Superimpose.html", "label": "Superimpose sensor", "category": "Geometry", "definition": "Using available image metadata, project one image onto another one", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Superimpose - inr QB_Toulouse_Ortho_PAN . tif - inm QB_Toulouse_Ortho_XS . tif - out SuperimposedXS_to_PAN . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Superimpose application Superimpose = otbApplication . Registry . CreateApplication ( \"Superimpose\" ) # The following lines set all the application parameters: Superimpose . SetParameterString ( \"inr\" , \"QB_Toulouse_Ortho_PAN.tif\" ) Superimpose . SetParameterString ( \"inm\" , \"QB_Toulouse_Ortho_XS.tif\" ) Superimpose . SetParameterString ( \"out\" , \"SuperimposedXS_to_PAN.tif\" ) # The following line execute the application Superimpose . ExecuteAndWriteOutput ()"], "command": "otbcli_Superimpose", "parameters": [{"flag": "inr", "parameterName": "Reference input", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inm", "parameterName": "The image to reproject", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "out", "parameterName": "Output image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "lms", "parameterName": "Spacing of the deformation field", "dataType": "Float", "explanation": []}, {"flag": "fv", "parameterName": "Fill Value", "dataType": "Float", "explanation": []}, {"flag": "mode", "parameterName": "Mode", "dataType": "Choices", "availableChoices": [{"choice": "default", "description": ["Default superimposition mode : uses any projection reference or sensor model found in the images."]}, {"choice": "phr", "description": ["Pleiades superimposition mode, designed for the case of a P+XS bundle in SENSOR geometry. It uses a simple transform on the XS image : a scaling and a residual translation."]}], "explanation": []}, {"flag": "interpolator", "parameterName": "Interpolation", "dataType": "Choices", "availableChoices": [{"choice": "bco", "description": ["Bicubic interpolation leads to very good image quality but is slow."]}, {"choice": "nn", "description": ["Nearest neighbor interpolation leads to poor image quality, but it is very fast."]}, {"choice": "linear", "description": ["Linear interpolation leads to average image quality but is quite fast."]}], "explanation": []}, {"flag": "interpolator.bco.radius", "parameterName": "Radius for bicubic interpolation", "dataType": "Int", "explanation": ["This parameter allows controlling the size of the bicubic interpolation filter. If the target pixel size is higher than the input pixel size, increasing this parameter will reduce aliasing artifacts."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application performs the projection of an image into the geometry of another one. \n"},
{"name": "RigidTransformResample", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_RigidTransformResample.html", "label": "Image resampling with a rigid transform", "category": "Geometry", "definition": "Resample an image with a rigid transform", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_RigidTransformResample - in qb_toulouse_sub . tif - out rigitTransformImage . tif - transform . type rotation - transform . type . rotation . angle 20 - transform . type . rotation . scalex 2. - transform . type . rotation . scaley 2.", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the RigidTransformResample application RigidTransformResample = otbApplication . Registry . CreateApplication ( \"RigidTransformResample\" ) # The following lines set all the application parameters: RigidTransformResample . SetParameterString ( \"in\" , \"qb_toulouse_sub.tif\" ) RigidTransformResample . SetParameterString ( \"out\" , \"rigitTransformImage.tif\" ) RigidTransformResample . SetParameterString ( \"transform.type\" , \"rotation\" ) RigidTransformResample . SetParameterFloat ( \"transform.type.rotation.angle\" , 20 ) RigidTransformResample . SetParameterFloat ( \"transform.type.rotation.scalex\" , 2. ) RigidTransformResample . SetParameterFloat ( \"transform.type.rotation.scaley\" , 2. ) # The following line execute the application RigidTransformResample . ExecuteAndWriteOutput ()"], "command": "otbcli_RigidTransformResample", "parameters": [{"flag": "in", "parameterName": "Input image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "transform.type", "parameterName": "Type of transformation", "dataType": "Choices", "availableChoices": [{"choice": "id", "description": ["Spatial scaling."]}, {"choice": "translation", "description": ["translation."]}, {"choice": "rotation", "description": ["rotation."]}], "explanation": ["Type of transformation. Available transformations are spatial scaling, translation and rotation with scaling factor. Available choices are:"]}, {"flag": "transform.type.id.scalex", "parameterName": "X scaling", "dataType": "Float", "explanation": ["Scale factor between the X spacing of the rotated output image and the X spacing of the unrotated image."]}, {"flag": "transform.type.id.scaley", "parameterName": "Y scaling", "dataType": "Float", "explanation": ["Scale factor between the Y spacing of the rotated output image and the Y spacing of the unrotated image."]}, {"flag": "transform.type.translation.tx", "parameterName": "The X translation (in physical units)", "dataType": "Float", "explanation": ["The translation value along X axis (in physical units)."]}, {"flag": "transform.type.translation.ty", "parameterName": "The Y translation (in physical units)", "dataType": "Float", "explanation": ["The translation value along Y axis (in physical units)."]}, {"flag": "transform.type.translation.scalex", "parameterName": "X scaling", "dataType": "Float", "explanation": ["Scale factor between the X spacing of the rotated output image and the X spacing of the unrotated image."]}, {"flag": "transform.type.translation.scaley", "parameterName": "Y scaling", "dataType": "Float", "explanation": ["Scale factor between the Y spacing of the rotated output image and the Y spacing of the unrotated image."]}, {"flag": "transform.type.rotation.angle", "parameterName": "Rotation angle", "dataType": "Float", "explanation": ["The rotation angle in degree (values between -180 and 180)."]}, {"flag": "transform.type.rotation.scalex", "parameterName": "X scaling", "dataType": "Float", "explanation": ["Scale factor between the X spacing of the rotated output image and the X spacing of the unrotated image."]}, {"flag": "transform.type.rotation.scaley", "parameterName": "Y scaling", "dataType": "Float", "explanation": ["Scale factor between the Y spacing of the rotated output image and the Y spacing of the unrotated image."]}, {"flag": "interpolator", "parameterName": "Interpolation", "dataType": "Choices", "availableChoices": [{"choice": "nn", "description": ["Nearest neighbor interpolation leads to poor image quality, but it is very fast."]}, {"choice": "linear", "description": ["Linear interpolation leads to average image quality but is quite fast."]}, {"choice": "bco", "description": []}], "explanation": []}, {"flag": "interpolator.bco.radius", "parameterName": "Radius for bicubic interpolation", "dataType": "Int", "explanation": ["This parameter allows controlling the size of the bicubic interpolation filter. If the target pixel size is higher than the input pixel size, increasing this parameter will reduce aliasing artifacts."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application performs a parametric transform on the input image. Scaling, translation and rotation with scaling factor are handled. Parameters of the transform is expressed in physical units, thus particular attention must be paid on pixel size (value, and sign). Moreover transform is expressed from input space to output space (on the contrary ITK Transforms are expressed form output space to input space). \n"},
{"name": "Pansharpening", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_Pansharpening.html", "label": "Pansharpening", "category": "Geometry", "definition": "Perform P+XS pansharpening", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_Pansharpening - inp QB_Toulouse_Ortho_PAN . tif - inxs QB_Toulouse_Ortho_XS . tif - out Pansharpening . tif uint16", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the Pansharpening application Pansharpening = otbApplication . Registry . CreateApplication ( \"Pansharpening\" ) # The following lines set all the application parameters: Pansharpening . SetParameterString ( \"inp\" , \"QB_Toulouse_Ortho_PAN.tif\" ) Pansharpening . SetParameterString ( \"inxs\" , \"QB_Toulouse_Ortho_XS.tif\" ) Pansharpening . SetParameterString ( \"out\" , \"Pansharpening.tif\" ) Pansharpening . SetParameterOutputImagePixelType ( \"out\" , 3 ) # The following line execute the application Pansharpening . ExecuteAndWriteOutput ()"], "command": "otbcli_Pansharpening", "parameters": [{"flag": "inp", "parameterName": "Input PAN Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxs", "parameterName": "Input XS Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "method", "parameterName": "Algorithm", "dataType": "Choices", "availableChoices": [{"choice": "rcs", "description": ["Simple RCS Pan sharpening operation."]}, {"choice": "lmvm", "description": ["Local Mean and Variance Matching (LMVM) Pan sharpening."]}, {"choice": "bayes", "description": ["Bayesian fusion."]}], "explanation": []}, {"flag": "method.lmvm.radiusx", "parameterName": "X radius", "dataType": "Int", "explanation": ["Set the x radius of the sliding window."]}, {"flag": "method.lmvm.radiusy", "parameterName": "Y radius", "dataType": "Int", "explanation": ["Set the y radius of the sliding window."]}, {"flag": "method.bayes.lambda", "parameterName": "Weight", "dataType": "Float", "explanation": ["Set the weighting value."]}, {"flag": "method.bayes.s", "parameterName": "S coefficient", "dataType": "Float", "explanation": ["Set the S coefficient."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application performs P+XS pansharpening. Pansharpening is a process of merging high-resolution panchromatic and lower resolution multispectral imagery to create a single high-resolution color image. Algorithms available in the applications are: RCS, bayesian fusion and Local Mean and Variance Matching(LMVM). \n"},
{"name": "RefineSensorModel", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_RefineSensorModel.html", "label": "Refine Sensor Model", "category": "Geometry", "definition": "Perform least-square fit of a sensor model to a set of tie points", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_RefineSensorModel - ingeom input . geom - outgeom output . geom - inpoints points . txt - map epsg - map . epsg . code 32631", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the RefineSensorModel application RefineSensorModel = otbApplication . Registry . CreateApplication ( \"RefineSensorModel\" ) # The following lines set all the application parameters: RefineSensorModel . SetParameterString ( \"ingeom\" , \"input.geom\" ) RefineSensorModel . SetParameterString ( \"outgeom\" , \"output.geom\" ) RefineSensorModel . SetParameterString ( \"inpoints\" , \"points.txt\" ) RefineSensorModel . SetParameterString ( \"map\" , \"epsg\" ) RefineSensorModel . SetParameterInt ( \"map.epsg.code\" , 32631 ) # The following line execute the application RefineSensorModel . ExecuteAndWriteOutput ()"], "command": "otbcli_RefineSensorModel", "parameters": [{"flag": "ingeom", "parameterName": "Input geom file", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "outgeom", "parameterName": "Output geom file", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inpoints", "parameterName": "Input file containing tie points", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "outstat", "parameterName": "Output file containing output precision statistics", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "outvector", "parameterName": "Output vector file with residues", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n This application reads a geom file containing a sensor model and a text file containing a list of ground control point, and performs a least-square fit of the sensor model adjustable parameters to these tie points. It produces an updated geom file as output, as well as an optional ground control points based statistics file and a vector file containing residues. The output geom file can then be used to ortho-rectify the data more accurately. Plaease note that for a proper use of the application, elevation must be correctly set (including DEM and geoid file). The map parameters allows one to choose a map projection in which the accuracy will be estimated in meters. \n"},
{"name": "OrthoRectification", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_OrthoRectification.html", "label": "Ortho", "category": "Geometry", "definition": "This application allows ortho-rectifying optical and radar images from supported sensors.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_OrthoRectification - io . in QB_TOULOUSE_MUL_Extract_500_500 . tif - io . out QB_Toulouse_ortho . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the OrthoRectification application OrthoRectification = otbApplication . Registry . CreateApplication ( \"OrthoRectification\" ) # The following lines set all the application parameters: OrthoRectification . SetParameterString ( \"io.in\" , \"QB_TOULOUSE_MUL_Extract_500_500.tif\" ) OrthoRectification . SetParameterString ( \"io.out\" , \"QB_Toulouse_ortho.tif\" ) # The following line execute the application OrthoRectification . ExecuteAndWriteOutput ()"], "command": "otbcli_OrthoRectification", "parameters": [{"flag": "io.in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to ortho-rectify."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The ortho-rectified output image."], "isOutputFile": true}, {"flag": "outputs.ortho", "parameterName": "Model ortho-image", "dataType": "Input image", "explanation": ["A model ortho-image that can be used to compute size, origin and spacing of the output."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "outputs.mode", "parameterName": "Parameters estimation modes", "dataType": "Choices", "availableChoices": [{"choice": "auto", "description": ["This mode allows you to fully modify default values."]}, {"choice": "autosize", "description": ["This mode allows you to automatically compute the optimal image size from given spacing (pixel size) values."]}, {"choice": "autospacing", "description": ["This mode allows you to automatically compute the optimal image spacing (pixel size) from the given size."]}, {"choice": "outputroi", "description": ["This mode allows you to automatically compute the optimal image size from spacing (pixel size) and output corners."]}, {"choice": "orthofit", "description": ["Fit the size, origin and spacing to an existing ortho image (uses the value of outputs.ortho)."]}], "explanation": [" Available choices are:"]}, {"flag": "outputs.ulx", "parameterName": "Upper Left X", "dataType": "Float", "explanation": ["Cartographic X coordinate of upper-left corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.uly", "parameterName": "Upper Left Y", "dataType": "Float", "explanation": ["Cartographic Y coordinate of the upper-left corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.sizex", "parameterName": "Size X", "dataType": "Int", "explanation": ["Size of projected image along X (in pixels)."]}, {"flag": "outputs.sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": ["Size of projected image along Y (in pixels)."]}, {"flag": "outputs.spacingx", "parameterName": "Pixel Size X", "dataType": "Float", "explanation": ["Size of each pixel along X axis (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.spacingy", "parameterName": "Pixel Size Y", "dataType": "Float", "explanation": ["Size of each pixel along Y axis (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.lrx", "parameterName": "Lower right X", "dataType": "Float", "explanation": ["Cartographic X coordinate of the lower-right corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.lry", "parameterName": "Lower right Y", "dataType": "Float", "explanation": ["Cartographic Y coordinate of the lower-right corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "outputs.isotropic", "parameterName": "Force isotropic spacing by default", "dataType": "Boolean", "explanation": ["Default spacing (pixel size) values are estimated from the sensor modeling of the image. It can therefore result in a non-isotropic spacing. This option allows you to force default values to be isotropic (in this case, the minimum of spacing in both direction is applied. Values overridden by user are not affected by this option."]}, {"flag": "outputs.default", "parameterName": "Default pixel value", "dataType": "Float", "explanation": ["Default value to write when outside of input image."]}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "interpolator", "parameterName": "Interpolation", "dataType": "Choices", "availableChoices": [{"choice": "bco", "description": []}, {"choice": "nn", "description": ["Nearest neighbor interpolation leads to poor image quality, but it is very fast."]}, {"choice": "linear", "description": ["Linear interpolation leads to average image quality but is quite fast."]}], "explanation": []}, {"flag": "interpolator.bco.radius", "parameterName": "Radius for bicubic interpolation", "dataType": "Int", "explanation": ["This parameter allows one to control the size of the bicubic interpolation filter. If the target pixel size is higher than the input pixel size, increasing this parameter will reduce aliasing artifacts."]}, {"flag": "opt.rpc", "parameterName": "RPC modeling (points per axis)", "dataType": "Int", "explanation": ["Enabling RPC modeling allows one to speed-up SPOT5 ortho-rectification. Value is the number of control points per axis for RPC estimation."]}, {"flag": "opt.ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["This allows setting the maximum amount of RAM available for processing. As the writing task is time consuming, it is better to write large pieces of data, which can be achieved by increasing this parameter (pay attention to your system capabilities)."]}, {"flag": "opt.gridspacing", "parameterName": "Resampling grid spacing", "dataType": "Float", "explanation": ["Resampling is done according to a coordinate mapping deformation grid, whose pixel size is set by this parameter, and expressed in the coordinate system of the output image The closer to the output spacing this parameter is, the more precise will be the ortho-rectified image,but increasing this parameter will reduce processing time."]}], "description": "\n   \n This application uses inverse sensor modelling combined with a choice of interpolation functions to resample a sensor geometry image into a ground geometry regular grid. The ground geometry regular grid is defined with respect to a map projection (see map parameter). The application offers several modes to estimate the output grid parameters (origin and ground sampling distance), including automatic estimation of image size, ground sampling distance, or both, from image metadata, user-defined ROI corners, or another ortho-image.A digital Elevation Model along with a geoid file can be specified to account for terrain deformations.In case of SPOT5 images, the sensor model can be approximated by an RPC model in order to speed-up computation. \n"},
{"name": "ImageEnvelope", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ImageEnvelope.html", "label": "Image Envelope", "category": "Geometry", "definition": "Extracts an image envelope.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ImageEnvelope - in QB_TOULOUSE_MUL_Extract_500_500 . tif - out ImageEnvelope . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ImageEnvelope application ImageEnvelope = otbApplication . Registry . CreateApplication ( \"ImageEnvelope\" ) # The following lines set all the application parameters: ImageEnvelope . SetParameterString ( \"in\" , \"QB_TOULOUSE_MUL_Extract_500_500.tif\" ) ImageEnvelope . SetParameterString ( \"out\" , \"ImageEnvelope.shp\" ) # The following line execute the application ImageEnvelope . ExecuteAndWriteOutput ()"], "command": "otbcli_ImageEnvelope", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Vector Data", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "sr", "parameterName": "Sampling Rate", "dataType": "Int", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "proj", "parameterName": "Projection", "dataType": "String", "explanation": []}], "description": "\n   \n Build a vector data containing the image envelope polygon. Useful for some projection, you can set the polygon with more points with the sr parameter. This filter supports user-specified output projection. If no projection is defined, the standard WGS84 projection will be used. \n"},
{"name": "GenerateRPCSensorModel", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_GenerateRPCSensorModel.html", "label": "Generate a RPC sensor model", "category": "Geometry", "definition": "Generate a RPC sensor model from a list of Ground Control Points.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_GenerateRPCSensorModel - outgeom output . geom - inpoints points . txt - map epsg - map . epsg . code 32631", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the GenerateRPCSensorModel application GenerateRPCSensorModel = otbApplication . Registry . CreateApplication ( \"GenerateRPCSensorModel\" ) # The following lines set all the application parameters: GenerateRPCSensorModel . SetParameterString ( \"outgeom\" , \"output.geom\" ) GenerateRPCSensorModel . SetParameterString ( \"inpoints\" , \"points.txt\" ) GenerateRPCSensorModel . SetParameterString ( \"map\" , \"epsg\" ) GenerateRPCSensorModel . SetParameterInt ( \"map.epsg.code\" , 32631 ) # The following line execute the application GenerateRPCSensorModel . ExecuteAndWriteOutput ()"], "command": "otbcli_GenerateRPCSensorModel", "parameters": [{"flag": "outgeom", "parameterName": "Output geom file", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inpoints", "parameterName": "Input file containing tie points", "dataType": "Input File name", "explanation": [], "isInputFile": true}, {"flag": "outstat", "parameterName": "Output file containing output precision statistics", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "outvector", "parameterName": "Output vector file with residues", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n This application generates a RPC sensor model from a list of Ground Control Points. At least 20 points are required for estimation without elevation support, and 40 points for estimation with elevation support. Elevation support will be automatically deactivated if an insufficient amount of points is provided. The application can optionally output a file containing accuracy statistics for each point, and a vector file containing segments representing points residues. The map projection parameter allows defining a map projection in which the accuracy is evaluated. \n"},
{"name": "ConvertCartoToGeoPoint", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ConvertCartoToGeoPoint.html", "label": "Cartographic to geographic coordinates conversion", "category": "Geometry", "definition": "Convert cartographic coordinates to geographic ones.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ConvertCartoToGeoPoint - carto . x 367074.625 - carto . y 4835740 - mapproj utm - mapproj . utm . northhem true - mapproj . utm . zone 31", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ConvertCartoToGeoPoint application ConvertCartoToGeoPoint = otbApplication . Registry . CreateApplication ( \"ConvertCartoToGeoPoint\" ) # The following lines set all the application parameters: ConvertCartoToGeoPoint . SetParameterFloat ( \"carto.x\" , 367074.625 ) ConvertCartoToGeoPoint . SetParameterFloat ( \"carto.y\" , 4835740 ) ConvertCartoToGeoPoint . SetParameterString ( \"mapproj\" , \"utm\" ) ConvertCartoToGeoPoint . SetParameterString ( \"mapproj.utm.northhem\" , \"true\" ) ConvertCartoToGeoPoint . SetParameterInt ( \"mapproj.utm.zone\" , 31 ) # The following line execute the application ConvertCartoToGeoPoint . ExecuteAndWriteOutput ()"], "command": "otbcli_ConvertCartoToGeoPoint", "parameters": [{"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "carto.x", "parameterName": "X cartographic coordinates", "dataType": "Float", "explanation": ["X cartographic coordinates in the projection defined by mapproj parameter."]}, {"flag": "carto.y", "parameterName": "Y cartographic coordinates", "dataType": "Float", "explanation": ["Y cartographic coordinates in the projection defined by mapproj parameter."]}, {"flag": "mapproj", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "mapproj.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "mapproj.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "mapproj.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "long", "parameterName": "Output long", "dataType": "Float", "explanation": []}, {"flag": "lat", "parameterName": "Output lat", "dataType": "Float", "explanation": []}], "description": "\n   \n This application computes the geographic coordinates from cartographic ones. User has to give the X and Y coordinate and the cartographic projection (see mapproj parameter for details). \n"},
{"name": "GeneratePlyFile", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_GeneratePlyFile.html", "label": "Ply 3D files generation", "category": "Geometry", "definition": "Generate a 3D Ply file from a DEM and a color image.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_GeneratePlyFile - indem image_dem . tif - out out . ply - incolor image_color . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the GeneratePlyFile application GeneratePlyFile = otbApplication . Registry . CreateApplication ( \"GeneratePlyFile\" ) # The following lines set all the application parameters: GeneratePlyFile . SetParameterString ( \"indem\" , \"image_dem.tif\" ) GeneratePlyFile . SetParameterString ( \"out\" , \"out.ply\" ) GeneratePlyFile . SetParameterString ( \"incolor\" , \"image_color.tif\" ) # The following line execute the application GeneratePlyFile . ExecuteAndWriteOutput ()"], "command": "otbcli_GeneratePlyFile", "parameters": [{"flag": "indem", "parameterName": "The input DEM image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "incolor", "parameterName": "The input color image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "The output Ply file", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "mode", "parameterName": "Conversion Mode", "dataType": "Choices", "availableChoices": [{"choice": "dem", "description": ["DEM conversion mode (the projection information of the DEM is used to derive the X and Y coordinates of each point)."]}, {"choice": "3dgrid", "description": ["3D grid conversion mode."]}], "explanation": []}, {"flag": "map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "description": "\n   \n The application converts an image containing elevations into a PLY file, which is a file format to store 3D models. This format is adpated for visualization on software such as MeshLab [2] or CloudCompare [3] \n This application is part of the stereo reconstruction framework. The input data can be produced by the application DisparityMapToElevationMap. \n \n There are two types of supported input images: \n \n A DEM image, with a ground projection, containing elevation values. Each elevation value can be considered as a 3D point. \n A 3D grid image, containing 5 bands (the first 3 are the 3D coordinates of each point, the 5th is a validity mask where valid values are larger or equal to 1) \n \n \n \n The user shall also give a support image that contains color values for each 3D point. The color values will be embedded in the PLY file. \n"},
{"name": "ConvertSensorToGeoPoint", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_ConvertSensorToGeoPoint.html", "label": "Convert Sensor Point To Geographic Point", "category": "Geometry", "definition": "Sensor to geographic coordinates conversion.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_ConvertSensorToGeoPoint - in QB_TOULOUSE_MUL_Extract_500_500 . tif - input . idx 200 - input . idy 200", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the ConvertSensorToGeoPoint application ConvertSensorToGeoPoint = otbApplication . Registry . CreateApplication ( \"ConvertSensorToGeoPoint\" ) # The following lines set all the application parameters: ConvertSensorToGeoPoint . SetParameterString ( \"in\" , \"QB_TOULOUSE_MUL_Extract_500_500.tif\" ) ConvertSensorToGeoPoint . SetParameterFloat ( \"input.idx\" , 200 ) ConvertSensorToGeoPoint . SetParameterFloat ( \"input.idy\" , 200 ) # The following line execute the application ConvertSensorToGeoPoint . ExecuteAndWriteOutput ()"], "command": "otbcli_ConvertSensorToGeoPoint", "parameters": [{"flag": "in", "parameterName": "Sensor image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "input.idx", "parameterName": "X value of desired point", "dataType": "Float", "explanation": ["X coordinate of the point to transform."]}, {"flag": "input.idy", "parameterName": "Y value of desired point", "dataType": "Float", "explanation": ["Y coordinate of the point to transform."]}, {"flag": "output.idx", "parameterName": "Output Point Longitude", "dataType": "Float", "explanation": ["Output point longitude coordinate."]}, {"flag": "output.idy", "parameterName": "Output Point Latitude", "dataType": "Float", "explanation": ["Output point latitude coordinate."]}, {"flag": "output.town", "parameterName": "Main town near the coordinates computed", "dataType": "String", "explanation": ["Nearest main town of the computed geographic point."]}, {"flag": "output.country", "parameterName": "Country of the image", "dataType": "String", "explanation": ["Country of the input image."]}], "description": "\n   \n This Application converts a sensor point of an input image to a geographic point using the Forward Sensor Model of the input image. \n"},
{"name": "BundleToPerfectSensor", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_BundleToPerfectSensor.html", "label": "Bundle to perfect sensor", "category": "Geometry", "definition": "Perform P+XS pansharpening", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_BundleToPerfectSensor - inp QB_Toulouse_Ortho_PAN . tif - inxs QB_Toulouse_Ortho_XS . tif - out BundleToPerfectSensor . png uchar", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the BundleToPerfectSensor application BundleToPerfectSensor = otbApplication . Registry . CreateApplication ( \"BundleToPerfectSensor\" ) # The following lines set all the application parameters: BundleToPerfectSensor . SetParameterString ( \"inp\" , \"QB_Toulouse_Ortho_PAN.tif\" ) BundleToPerfectSensor . SetParameterString ( \"inxs\" , \"QB_Toulouse_Ortho_XS.tif\" ) BundleToPerfectSensor . SetParameterString ( \"out\" , \"BundleToPerfectSensor.png\" ) BundleToPerfectSensor . SetParameterOutputImagePixelType ( \"out\" , 1 ) # The following line execute the application BundleToPerfectSensor . ExecuteAndWriteOutput ()"], "command": "otbcli_BundleToPerfectSensor", "parameters": [{"flag": "inp", "parameterName": "Input PAN Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "inxs", "parameterName": "Input XS Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "mode", "parameterName": "Mode", "dataType": "Choices", "availableChoices": [{"choice": "default", "description": ["Default superimposition mode : uses any projection reference or sensor model found in the images."]}, {"choice": "phr", "description": ["Pleiades superimposition mode, designed for the case of a P+XS bundle in SENSOR geometry. It uses a simple transform on the XS image : a scaling and a residual translation."]}], "explanation": []}, {"flag": "method", "parameterName": "Algorithm", "dataType": "Choices", "availableChoices": [{"choice": "rcs", "description": ["Simple RCS Pan sharpening operation."]}, {"choice": "lmvm", "description": ["Local Mean and Variance Matching (LMVM) Pan sharpening."]}, {"choice": "bayes", "description": ["Bayesian fusion."]}], "explanation": []}, {"flag": "method.lmvm.radiusx", "parameterName": "X radius", "dataType": "Int", "explanation": ["Set the x radius of the sliding window."]}, {"flag": "method.lmvm.radiusy", "parameterName": "Y radius", "dataType": "Int", "explanation": ["Set the y radius of the sliding window."]}, {"flag": "method.bayes.lambda", "parameterName": "Weight", "dataType": "Float", "explanation": ["Set the weighting value."]}, {"flag": "method.bayes.s", "parameterName": "S coefficient", "dataType": "Float", "explanation": ["Set the S coefficient."]}, {"flag": "lms", "parameterName": "Spacing of the deformation field", "dataType": "Float", "explanation": []}, {"flag": "interpolator", "parameterName": "Interpolation", "dataType": "Choices", "availableChoices": [{"choice": "bco", "description": ["Bicubic interpolation leads to very good image quality but is slow."]}, {"choice": "nn", "description": ["Nearest neighbor interpolation leads to poor image quality, but it is very fast."]}, {"choice": "linear", "description": ["Linear interpolation leads to average image quality but is quite fast."]}], "explanation": []}, {"flag": "interpolator.bco.radius", "parameterName": "Radius for bicubic interpolation", "dataType": "Int", "explanation": ["This parameter allows controlling the size of the bicubic interpolation filter. If the target pixel size is higher than the input pixel size, increasing this parameter will reduce aliasing artifacts."]}, {"flag": "fv", "parameterName": "Fill Value", "dataType": "Float", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application performs P+XS pansharpening. The default mode use Pan and XS sensor models to estimate the transformation to superimpose XS over Pan before the fusion (\u201cdefault mode\u201d). The application provides also a PHR mode for Pleiades images which does not use sensor models as Pan and XS products are already coregistered but only estimate an affine transformation to superimpose XS over the Pan.Note that this option is automatically activated in case Pleiades images are detected as input. \n"},
{"name": "StereoFramework", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_StereoFramework.html", "label": "Stereo Framework", "category": "Stereo", "definition": "Compute the ground elevation based on one or multiple stereo pair(s)", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_StereoFramework - input . il sensor_stereo_left . tif sensor_stereo_right . tif - elev . default 200 - stereorect . fwdgridstep 8 - stereorect . invgridssrate 4 - postproc . med 1 - output . res 2.5 - output . out dem . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the StereoFramework application StereoFramework = otbApplication . Registry . CreateApplication ( \"StereoFramework\" ) # The following lines set all the application parameters: StereoFramework . SetParameterStringList ( \"input.il\" , [ 'sensor_stereo_left.tif' , 'sensor_stereo_right.tif' ]) StereoFramework . SetParameterFloat ( \"elev.default\" , 200 ) StereoFramework . SetParameterInt ( \"stereorect.fwdgridstep\" , 8 ) StereoFramework . SetParameterInt ( \"stereorect.invgridssrate\" , 4 ) StereoFramework . SetParameterString ( \"postproc.med\" , \"1\" ) StereoFramework . SetParameterFloat ( \"output.res\" , 2.5 ) StereoFramework . SetParameterString ( \"output.out\" , \"dem.tif\" ) # The following line execute the application StereoFramework . ExecuteAndWriteOutput ()"], "command": "otbcli_StereoFramework", "parameters": [{"flag": "input.il", "parameterName": "Input images list", "dataType": "Input image list", "explanation": ["List of images corresponding to multiple views on a single scene, in sensor geometry."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "output.out", "parameterName": "Output DSM", "dataType": "Output image", "explanation": ["Output elevation image."], "isOutputFile": true}, {"flag": "mask.left", "parameterName": "Input left mask", "dataType": "Input image", "explanation": ["Mask for left input image. Pixel with a null mask value are discarded."], "isInputFile": true}, {"flag": "mask.right", "parameterName": "Input right mask", "dataType": "Input image", "explanation": ["Mask for right input image. Pixel with a null mask value are discarded."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "input.co", "parameterName": "Couples list", "dataType": "String", "explanation": ["List of index of couples im image list. Couples must be separated by a comma (index start at 0). For example : 0 1,1 2 will process a first couple composed of the first and the second image in image list, then the second and the third image . Note that images are handled by pairs. If left empty, couples are created from input index i.e. a first couple will be composed of the first and second image, a second couple with third and fourth image etc. (in this case image list must be even)."]}, {"flag": "input.channel", "parameterName": "Input Image channel", "dataType": "Int", "explanation": ["Channel used for block matching (the same for all images)."]}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "output.res", "parameterName": "Output resolution", "dataType": "Float", "explanation": ["Spatial sampling distance of the output elevation : the cell size (in m)."]}, {"flag": "output.nodata", "parameterName": "NoData value", "dataType": "Float", "explanation": ["DSM empty cells are filled with this value (optional -32768 by default)."]}, {"flag": "output.fusionmethod", "parameterName": "Method to fuse measures in each DSM cell", "dataType": "Choices", "availableChoices": [{"choice": "max", "description": ["The cell is filled with the maximum measured elevation values."]}, {"choice": "min", "description": ["The cell is filled with the minimum measured elevation values."]}, {"choice": "mean", "description": ["The cell is filled with the mean of measured elevation values."]}, {"choice": "acc", "description": ["Accumulator mode. The cell is filled with the the number of values (for debugging purposes)."]}], "explanation": ["This parameter allows one to choose the method used to fuse elevation measurements in each output DSM cell. Available choices are:"]}, {"flag": "output.mode", "parameterName": "Parameters estimation modes", "dataType": "Choices", "availableChoices": [{"choice": "fit", "description": ["Fit the size, origin and spacing to an existing ortho image (uses the value of outputs.ortho)."]}, {"choice": "user", "description": ["This mode allows you to fully modify default values."]}], "explanation": [" Available choices are:"]}, {"flag": "output.mode.user.ulx", "parameterName": "Upper Left X", "dataType": "Float", "explanation": ["Cartographic X coordinate of upper-left corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "output.mode.user.uly", "parameterName": "Upper Left Y", "dataType": "Float", "explanation": ["Cartographic Y coordinate of the upper-left corner (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "output.mode.user.sizex", "parameterName": "Size X", "dataType": "Int", "explanation": ["Size of projected image along X (in pixels)."]}, {"flag": "output.mode.user.sizey", "parameterName": "Size Y", "dataType": "Int", "explanation": ["Size of projected image along Y (in pixels)."]}, {"flag": "output.mode.user.spacingx", "parameterName": "Pixel Size X", "dataType": "Float", "explanation": ["Size of each pixel along X axis (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "output.mode.user.spacingy", "parameterName": "Pixel Size Y", "dataType": "Float", "explanation": ["Size of each pixel along Y axis (meters for cartographic projections, degrees for geographic ones)."]}, {"flag": "map", "parameterName": "Map Projection", "dataType": "Choices", "availableChoices": [{"choice": "utm", "description": ["A system of transverse mercator projections dividing the surface of Earth between 80S and 84N latitude."]}, {"choice": "lambert2", "description": ["This is a Lambert Conformal Conic projection mainly used in France."]}, {"choice": "lambert93", "description": ["This is a Lambert 93 projection mainly used in France."]}, {"choice": "wgs", "description": ["This is a Geographical projection."]}, {"choice": "epsg", "description": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}], "explanation": []}, {"flag": "map.utm.zone", "parameterName": "Zone number", "dataType": "Int", "explanation": ["The zone number ranges from 1 to 60 and allows defining the transverse mercator projection (along with the hemisphere)."]}, {"flag": "map.utm.northhem", "parameterName": "Northern Hemisphere", "dataType": "Boolean", "explanation": ["The transverse mercator projections are defined by their zone number as well as the hemisphere. Activate this parameter if your image is in the northern hemisphere."]}, {"flag": "map.epsg.code", "parameterName": "EPSG Code", "dataType": "Int", "explanation": ["See www.spatialreference.org to find which EPSG code is associated to your projection."]}, {"flag": "stereorect.fwdgridstep", "parameterName": "Step of the displacement grid (in pixels)", "dataType": "Int", "explanation": ["Stereo-rectification displacement grid only varies slowly. Therefore, it is recommended to use a coarser grid (higher step value) in case of large images."]}, {"flag": "stereorect.invgridssrate", "parameterName": "Sub-sampling rate for epipolar grid inversion", "dataType": "Int", "explanation": ["Grid inversion is an heavy process that implies spline regression on control points. To avoid eating to much memory, this parameter allows one to first sub-sample the field to invert."]}, {"flag": "bm.metric", "parameterName": "Block-matching metric", "dataType": "Choices", "availableChoices": [{"choice": "ssdmean", "description": ["derived version of Sum of Squared Distances between pixels value in the metric window (SSD divided by mean over window)."]}, {"choice": "ssd", "description": ["Sum of squared distances between pixels value in the metric window."]}, {"choice": "ncc", "description": ["Normalized Cross-Correlation between the left and right windows."]}, {"choice": "lp", "description": ["Lp pseudo-norm between the left and right windows."]}], "explanation": ["Metric used to compute matching score. Available choices are:"]}, {"flag": "bm.metric.lp.p", "parameterName": "p value", "dataType": "Float", "explanation": ["Value of the p parameter in Lp pseudo-norm (must be positive)."]}, {"flag": "bm.radius", "parameterName": "Correlation window radius (in pixels)", "dataType": "Int", "explanation": ["The radius of blocks in Block-Matching (in pixels)."]}, {"flag": "bm.minhoffset", "parameterName": "Minimum altitude offset (in meters)", "dataType": "Float", "explanation": ["Minimum altitude below the selected elevation source (in meters)."]}, {"flag": "bm.maxhoffset", "parameterName": "Maximum altitude offset (in meters)", "dataType": "Float", "explanation": ["Maximum altitude above the selected elevation source (in meters)."]}, {"flag": "postproc.bij", "parameterName": "Use bijection consistency in block matching strategy", "dataType": "Boolean", "explanation": ["Use bijection consistency. Right to Left correlation is computed to validate Left to Right disparities. If bijection is not found, the disparity is rejected."]}, {"flag": "postproc.med", "parameterName": "Use median disparities filtering", "dataType": "Boolean", "explanation": ["Disparity map can be filtered using median post filtering (disabled by default)."]}, {"flag": "postproc.metrict", "parameterName": "Correlation metric threshold", "dataType": "Float", "explanation": ["Use block matching metric output to discard pixels with low correlation value (disabled by default, float value)."]}, {"flag": "mask.variancet", "parameterName": "Discard pixels with low local variance", "dataType": "Float", "explanation": ["This parameter allows one to discard pixels whose local variance is too small (the size of the neighborhood is given by the correlation window radius)."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n Compute the ground elevation with a stereo block matching algorithm between one or multiple stereo pair in sensor geometry. The output is projected in desired geographic or cartographic map projection (WGS84 by default). \n \n This application is chaining different processing steps. Some of them are also performed by other applications in the stereo-reconstruction framework: \n \n StereoRectificationGridGenerator [1] : for the generation of deformation grids \n GridBasedImageResampling [2] : resampling into epipolar geometry \n BlockMatching [3] : estimation of dense disparity maps \n \n \n The pipeline executes the following steps on each stereo pair: \n \n compute the epipolar displacement grids from the stereo pair (direct and inverse) \n resample the stereo pair into epipolar geometry using BCO interpolation \n create masks for each epipolar image : remove black borders and resample input masks \n compute horizontal disparities with a block matching algorithm \n refine disparities to sub-pixel precision with a dichotomy algorithm \n apply an optional median filter \n filter disparities based on the correlation score and exploration bounds \n translate disparities in sensor geometry \n convert disparity to 3D Map. \n \n \n \n Then all 3D maps are fused to produce DSM. The fusion method in each DEM cell can be chosen between maximum, minimum and average. \n"},
{"name": "StereoRectificationGridGenerator", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_StereoRectificationGridGenerator.html", "label": "Stereo", "category": "Stereo", "definition": "Generates two deformation fields to resample in epipolar geometry, a pair of stereo images up to the sensor model precision", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_StereoRectificationGridGenerator - io . inleft wv2_xs_left . tif - io . inright wv2_xs_left . tif - io . outleft wv2_xs_left_epi_field . tif - io . outright wv2_xs_right_epi_field . tif - epi . elevation . default 400", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the StereoRectificationGridGenerator application StereoRectificationGridGenerator = otbApplication . Registry . CreateApplication ( \"StereoRectificationGridGenerator\" ) # The following lines set all the application parameters: StereoRectificationGridGenerator . SetParameterString ( \"io.inleft\" , \"wv2_xs_left.tif\" ) StereoRectificationGridGenerator . SetParameterString ( \"io.inright\" , \"wv2_xs_left.tif\" ) StereoRectificationGridGenerator . SetParameterString ( \"io.outleft\" , \"wv2_xs_left_epi_field.tif\" ) StereoRectificationGridGenerator . SetParameterString ( \"io.outright\" , \"wv2_xs_right_epi_field.tif\" ) StereoRectificationGridGenerator . SetParameterFloat ( \"epi.elevation.default\" , 400 ) # The following line execute the application StereoRectificationGridGenerator . ExecuteAndWriteOutput ()"], "command": "otbcli_StereoRectificationGridGenerator", "parameters": [{"flag": "io.inleft", "parameterName": "Left input image", "dataType": "Input image", "explanation": ["The left image from the stereo pair, in sensor geometry."], "isInputFile": true}, {"flag": "io.inright", "parameterName": "Right input image", "dataType": "Input image", "explanation": ["The right image from the stereo pair, in sensor geometry."], "isInputFile": true}, {"flag": "io.outleft", "parameterName": "Left output deformation grid", "dataType": "Output image", "explanation": ["The deformation grid to resample the left image from sensor geometry to epipolar geometry."], "isOutputFile": true}, {"flag": "io.outright", "parameterName": "Right output deformation grid", "dataType": "Output image", "explanation": ["The deformation grid to resample the right image from sensor geometry to epipolar geometry."], "isOutputFile": true}, {"flag": "epi.elevation.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inverse.outleft", "parameterName": "Left inverse deformation grid", "dataType": "Output image", "explanation": ["The deformation grid to resample the left image from the epipolar geometry back into its original sensor geometry."], "isOutputFile": true}, {"flag": "inverse.outright", "parameterName": "Right inverse deformation grid", "dataType": "Output image", "explanation": ["The output deformation grid to resample the right image from the epipolar geometry back into its original sensor geometry."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "epi.elevation.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "epi.elevation.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "epi.elevation.avgdem.step", "parameterName": "Sub-sampling step", "dataType": "Int", "explanation": ["Step of sub-sampling for average elevation estimation."]}, {"flag": "epi.elevation.avgdem.value", "parameterName": "Average elevation value", "dataType": "Float", "explanation": ["Average elevation value estimated from DEM."]}, {"flag": "epi.elevation.avgdem.mindisp", "parameterName": "Minimum disparity from DEM", "dataType": "Float", "explanation": ["Disparity corresponding to estimated minimum elevation over the left image."]}, {"flag": "epi.elevation.avgdem.maxdisp", "parameterName": "Maximum disparity from DEM", "dataType": "Float", "explanation": ["Disparity corresponding to estimated maximum elevation over the left image."]}, {"flag": "epi.scale", "parameterName": "Scale of epipolar images", "dataType": "Float", "explanation": ["The scale parameter allows generating zoomed-in (scale < 1) or zoomed-out (scale > 1) epipolar images."]}, {"flag": "epi.step", "parameterName": "Step of the deformation grid (in nb. of pixels)", "dataType": "Int", "explanation": ["Stereo-rectification deformation grid only varies slowly. Therefore, it is recommended to use a coarser grid (higher step value) in case of large images."]}, {"flag": "epi.rectsizex", "parameterName": "Rectified image size X", "dataType": "Int", "explanation": ["The application computes the optimal rectified image size so that the whole left input image fits into the rectified area. However, due to the scale and step parameter, this size may not match the size of the deformation field output. In this case, one can use these output values."]}, {"flag": "epi.rectsizey", "parameterName": "Rectified image size Y", "dataType": "Int", "explanation": ["The application computes the optimal rectified image size so that the whole left input image fits into the rectified area. However, due to the scale and step parameter, this size may not match the size of the deformation field output. In this case, one can use these output values."]}, {"flag": "epi.baseline", "parameterName": "Mean baseline ratio", "dataType": "Float", "explanation": ["This parameter is the mean value, in pixels.meters^-1, of the baseline to sensor altitude ratio. It can be used to convert disparities to physical elevation, since a disparity of one pixel will correspond to an elevation offset of the invert of this value with respect to the mean elevation."]}, {"flag": "inverse.ssrate", "parameterName": "Sub-sampling rate for inversion", "dataType": "Int", "explanation": ["Grid inversion is an heavy process that implies spline regression on control points. To avoid eating to much memory, this parameter allows one to first sub-sample the field to invert."]}], "description": "\n   \n This application generates a pair of deformation grid to stereo-rectify a pair of stereo images according to sensor modelling and a mean elevation hypothesis. \n This application is the first part of the stereo reconstruction framework. The output deformation grids can be passed to the GridBasedImageResampling application for actual resampling into epipolar geometry. \n \n There are several ways to set the elevation source: \n \n An arbitrary constant elevation \n A DEM directory \n Compute an average elevation from a DEM \n \n \n \n If needed, the application can compute inverse resampling grids (from epipolar to original sensor geometry). Don\u2019t forget to check the other outputs from the application. For instance, the application gives the X and Y size of the rectified images, along with an estimated baseline ratio. \n"},
{"name": "DisparityMapToElevationMap", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_DisparityMapToElevationMap.html", "label": "Disparity map to elevation map", "category": "Stereo", "definition": "Projects a disparity map into a regular elevation map.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_DisparityMapToElevationMap - io . in disparity . tif - io . left sensor_left . tif - io . right sensor_right . tif - io . lgrid grid_epi_left . tif - io . rgrid grid_epi_right . tif - io . out dem . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the DisparityMapToElevationMap application DisparityMapToElevationMap = otbApplication . Registry . CreateApplication ( \"DisparityMapToElevationMap\" ) # The following lines set all the application parameters: DisparityMapToElevationMap . SetParameterString ( \"io.in\" , \"disparity.tif\" ) DisparityMapToElevationMap . SetParameterString ( \"io.left\" , \"sensor_left.tif\" ) DisparityMapToElevationMap . SetParameterString ( \"io.right\" , \"sensor_right.tif\" ) DisparityMapToElevationMap . SetParameterString ( \"io.lgrid\" , \"grid_epi_left.tif\" ) DisparityMapToElevationMap . SetParameterString ( \"io.rgrid\" , \"grid_epi_right.tif\" ) DisparityMapToElevationMap . SetParameterString ( \"io.out\" , \"dem.tif\" ) # The following line execute the application DisparityMapToElevationMap . ExecuteAndWriteOutput ()"], "command": "otbcli_DisparityMapToElevationMap", "parameters": [{"flag": "io.in", "parameterName": "Input disparity map", "dataType": "Input image", "explanation": ["The input disparity map (horizontal disparity in first band, vertical in second). This map can be computed by BlockMatching application."], "isInputFile": true}, {"flag": "io.left", "parameterName": "Left sensor image", "dataType": "Input image", "explanation": ["Left image in original (sensor) geometry. Only the geometric model of this image will be used, not the pixel values."], "isInputFile": true}, {"flag": "io.right", "parameterName": "Right sensor image", "dataType": "Input image", "explanation": ["Right image in original (sensor) geometry. Only the geometric model of this image will be used, not the pixel values."], "isInputFile": true}, {"flag": "io.lgrid", "parameterName": "Left Grid", "dataType": "Input image", "explanation": ["Left epipolar grid (deformation grid between left sensor et disparity spaces)."], "isInputFile": true}, {"flag": "io.rgrid", "parameterName": "Right Grid", "dataType": "Input image", "explanation": ["Right epipolar grid (deformation grid between right sensor et disparity spaces)."], "isInputFile": true}, {"flag": "io.out", "parameterName": "Output elevation map", "dataType": "Output image", "explanation": ["Output elevation map in ground projection. Elevation values are in meters. Floating point pixel type are expected."], "isOutputFile": true}, {"flag": "io.mask", "parameterName": "Disparity mask", "dataType": "Input image", "explanation": ["Masked disparity pixels won\u2019t be projected (mask values equal to zero)."], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "step", "parameterName": "DEM step", "dataType": "Float", "explanation": []}, {"flag": "hmin", "parameterName": "Minimum elevation expected", "dataType": "Float", "explanation": []}, {"flag": "hmax", "parameterName": "Maximum elevation expected", "dataType": "Float", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application uses a disparity map computed from a stereo image pair to produce an elevation map on the ground area covered by the stereo pair. \n This application is part of the stereo reconstruction pipeline. It can be used after having computed the disparity map with BlockMatching. \n \n The needed inputs are \n  :   the disparity map, the stereo pair (in original geometry) and the epipolar deformation grids. These grids (computed by StereoRectificationGridGenerator) have to contain the transform between the original geometry (stereo pair) and the epipolar geometry (disparity map). The algorithm for each disparity is the following : \n skip if position is discarded by the disparity mask \n compute left ray : transform the current position from epipolar geometry to left sensor geometry (left rectification grid) \n compute right ray : shift the current position with current disparity and transform from epipolar geometry to right sensor (right rectification grid) \n estimate best 3D intersection between left and right rays \n for the ground cell of the obtained 3D point, keep its elevation if greater than current elevation (keeps the maximum of elevations of all 3D points in each cell) \n \n \n \n Minimum and maximum elevations settings are here to bound the reconstructed DEM. \n"},
{"name": "FineRegistration", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_FineRegistration.html", "label": "Fine Registration", "category": "Stereo", "definition": "Estimate disparity map between two images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_FineRegistration - ref StereoFixed . png - sec StereoMoving . png - out FineRegistration . tif - erx 2 - ery 2 - mrx 3 - mry 3", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the FineRegistration application FineRegistration = otbApplication . Registry . CreateApplication ( \"FineRegistration\" ) # The following lines set all the application parameters: FineRegistration . SetParameterString ( \"ref\" , \"StereoFixed.png\" ) FineRegistration . SetParameterString ( \"sec\" , \"StereoMoving.png\" ) FineRegistration . SetParameterString ( \"out\" , \"FineRegistration.tif\" ) FineRegistration . SetParameterInt ( \"erx\" , 2 ) FineRegistration . SetParameterInt ( \"ery\" , 2 ) FineRegistration . SetParameterInt ( \"mrx\" , 3 ) FineRegistration . SetParameterInt ( \"mry\" , 3 ) # The following line execute the application FineRegistration . ExecuteAndWriteOutput ()"], "command": "otbcli_FineRegistration", "parameters": [{"flag": "ref", "parameterName": "Reference Image", "dataType": "Input image", "explanation": ["The reference image."], "isInputFile": true}, {"flag": "sec", "parameterName": "Secondary Image", "dataType": "Input image", "explanation": ["The secondary image."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output image contains 3 bands, for X offset, Y offset and the metric value. It may contain a 4th one with the validity mask (if used)."], "isOutputFile": true}, {"flag": "w", "parameterName": "Image To Warp", "dataType": "Input image", "explanation": ["The image to warp after disparity estimation is completed."], "isInputFile": true}, {"flag": "wo", "parameterName": "Output Warped Image", "dataType": "Output image", "explanation": ["The output warped image."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "erx", "parameterName": "Exploration Radius X", "dataType": "Int", "explanation": ["The exploration radius along x (in pixels)."]}, {"flag": "ery", "parameterName": "Exploration Radius Y", "dataType": "Int", "explanation": ["The exploration radius along y (in pixels)."]}, {"flag": "mrx", "parameterName": "Metric Radius X", "dataType": "Int", "explanation": ["Radius along x (in pixels) of the metric computation window."]}, {"flag": "mry", "parameterName": "Metric Radius Y", "dataType": "Int", "explanation": ["Radius along y (in pixels) of the metric computation window."]}, {"flag": "cox", "parameterName": "Coarse Offset X", "dataType": "Float", "explanation": ["Coarse offset along x (in physical space) between the two images, used as an initial offset for all pixels."]}, {"flag": "coy", "parameterName": "Coarse Offset Y", "dataType": "Float", "explanation": ["Coarse offset along y (in physical space) between the two images, used as an initial offset for all pixels."]}, {"flag": "ssrx", "parameterName": "Sub-Sampling Rate X", "dataType": "Float", "explanation": ["Generates a result at a coarser resolution with a given sub-sampling rate along X."]}, {"flag": "ssry", "parameterName": "Sub-Sampling Rate Y", "dataType": "Float", "explanation": ["Generates a result at a coarser resolution with a given sub-sampling rate along Y."]}, {"flag": "rgsx", "parameterName": "Reference Gaussian Smoothing X", "dataType": "Float", "explanation": ["Performs a gaussian smoothing of the reference image. Parameter is gaussian sigma (in pixels) in X direction."]}, {"flag": "rgsy", "parameterName": "Reference Gaussian Smoothing Y", "dataType": "Float", "explanation": ["Performs a gaussian smoothing of the reference image. Parameter is gaussian sigma (in pixels) in Y direction."]}, {"flag": "sgsx", "parameterName": "Secondary Gaussian Smoothing X", "dataType": "Float", "explanation": ["Performs a gaussian smoothing of the secondary image. Parameter is gaussian sigma (in pixels) in X direction."]}, {"flag": "sgsy", "parameterName": "Secondary Gaussian Smoothing Y", "dataType": "Float", "explanation": ["Performs a gaussian smoothing of the secondary image. Parameter is gaussian sigma (in pixels) in Y direction."]}, {"flag": "m", "parameterName": "Metric", "dataType": "String", "explanation": ["Choose the metric used for block matching. Available metrics are cross-correlation (CC), cross-correlation with subtracted mean (CCSM), mean-square difference (MSD), mean reciprocal square difference (MRSD) and mutual information (MI). Default is cross-correlation."]}, {"flag": "spa", "parameterName": "SubPixelAccuracy", "dataType": "Float", "explanation": ["Metric extrema location will be refined up to the given accuracy. Default is 0.01."]}, {"flag": "cva", "parameterName": "ConvergenceAccuracy", "dataType": "Float", "explanation": ["Metric extrema will be refined up to the given accuracy. Default is 0.01."]}, {"flag": "vmlt", "parameterName": "Validity Mask Lower Threshold", "dataType": "Float", "explanation": ["Lower threshold to compute the validity mask. This mask will be the 4th output band."]}, {"flag": "vmut", "parameterName": "Validity Mask Upper Threshold", "dataType": "Float", "explanation": ["Upper threshold to obtain a validity mask. This mask will be the 4th output band."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}], "description": "\n   \n This application computes a disparity map between two images that correspond to the same scene. It is intended for case where small misregistration between images should be estimated and fixed. The search is performed in 2D. \n The algorithm uses an iterative approach to estimate a best match between local patches. The typical use case is registration betwween similar bands, or between two acquisitions. The output image contains X and Y offsets, as well as the metric value. A sub-pixel accuracy can be expected. The input images should have the same size and same physical space. \n"},
{"name": "BlockMatching", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_BlockMatching.html", "label": "Pixel", "category": "Stereo", "definition": "Performs block-matching to estimate pixel-wise disparities between two images.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_BlockMatching - io . inleft StereoFixed . png - io . inright StereoMoving . png - bm . minhd - 10 - bm . maxhd 10 - mask . variancet 10 - io . out MyDisparity . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the BlockMatching application BlockMatching = otbApplication . Registry . CreateApplication ( \"BlockMatching\" ) # The following lines set all the application parameters: BlockMatching . SetParameterString ( \"io.inleft\" , \"StereoFixed.png\" ) BlockMatching . SetParameterString ( \"io.inright\" , \"StereoMoving.png\" ) BlockMatching . SetParameterInt ( \"bm.minhd\" , - 10 ) BlockMatching . SetParameterInt ( \"bm.maxhd\" , 10 ) BlockMatching . SetParameterFloat ( \"mask.variancet\" , 10 ) BlockMatching . SetParameterString ( \"io.out\" , \"MyDisparity.tif\" ) # The following line execute the application BlockMatching . ExecuteAndWriteOutput ()"], "command": "otbcli_BlockMatching", "parameters": [{"flag": "io.inleft", "parameterName": "Left input image", "dataType": "Input image", "explanation": ["The left input image (reference). It should have the same size and same physical space as the right input. This image can be generated by GridBasedImageResampling."], "isInputFile": true}, {"flag": "io.inright", "parameterName": "Right input image", "dataType": "Input image", "explanation": ["The right input (secondary). It should have the same size and same physical space as the left input. This image can be generated by GridBasedImageResampling."], "isInputFile": true}, {"flag": "io.out", "parameterName": "The output disparity map", "dataType": "Output image", "explanation": ["An image containing the estimated disparities as well as the metric values if the option is used. If no metric is output and no sub-pixel interpolation is done, pixel type canbe a signed integer. In the other cases, floating point pixel is advised."], "isOutputFile": true}, {"flag": "io.outmask", "parameterName": "The output mask corresponding to all criterions", "dataType": "Output image", "explanation": ["An output mask image corresponding to all citerions (see masking parameters). Only required if variance threshold or nodata criterions are set. Output pixel type is unsigned 8bit by default."], "isOutputFile": true}, {"flag": "mask.inleft", "parameterName": "Mask to discard left pixels", "dataType": "Input image", "explanation": ["This parameter allows providing a custom mask for the left image. Block matching will be only perform on pixels inside the mask (non-zero values)."], "isInputFile": true}, {"flag": "mask.inright", "parameterName": "Mask to discard right pixels", "dataType": "Input image", "explanation": ["This parameter allows providing a custom mask for the right image. Block matching will be perform only on pixels inside the mask (non-zero values)."], "isInputFile": true}, {"flag": "bm.initdisp.maps.hmap", "parameterName": "Horizontal initial disparity map", "dataType": "Input image", "explanation": ["Map of the initial horizontal disparities."], "isInputFile": true}, {"flag": "bm.initdisp.maps.vmap", "parameterName": "Vertical initial disparity map", "dataType": "Input image", "explanation": ["Map of the initial vertical disparities."], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "io.outmetric", "parameterName": "Flag to output optimal metric values as well", "dataType": "Boolean", "explanation": ["If enabled, the output image will have a third component with metric optimal values."]}, {"flag": "mask.nodata", "parameterName": "Discard pixels with no-data value", "dataType": "Float", "explanation": ["This parameter allows discarding pixels whose value is equal to the user-defined no-data value."]}, {"flag": "mask.variancet", "parameterName": "Discard pixels with low local variance", "dataType": "Float", "explanation": ["This parameter allows discarding pixels whose local variance is too small (the size of the neighborhood is given by the radius parameter)."]}, {"flag": "bm.metric", "parameterName": "Block-matching metric", "dataType": "Choices", "availableChoices": [{"choice": "ssd", "description": ["Sum of squared distances between pixels value in the metric window."]}, {"choice": "ncc", "description": ["Normalized Cross-Correlation between the left and right windows."]}, {"choice": "lp", "description": ["Lp pseudo-norm between the left and right windows."]}], "explanation": ["Metric to evaluate matching between two local windows. Available choices are:"]}, {"flag": "bm.metric.lp.p", "parameterName": "p value", "dataType": "Float", "explanation": ["Value of the p parameter in Lp pseudo-norm (must be positive)."]}, {"flag": "bm.radius", "parameterName": "Radius of blocks", "dataType": "Int", "explanation": ["The radius (in pixels) of blocks in Block-Matching."]}, {"flag": "bm.minhd", "parameterName": "Minimum horizontal disparity", "dataType": "Int", "explanation": ["Minimum horizontal disparity to explore (can be negative)."]}, {"flag": "bm.maxhd", "parameterName": "Maximum horizontal disparity", "dataType": "Int", "explanation": ["Maximum horizontal disparity to explore (can be negative)."]}, {"flag": "bm.minvd", "parameterName": "Minimum vertical disparity", "dataType": "Int", "explanation": ["Minimum vertical disparity to explore (can be negative)."]}, {"flag": "bm.maxvd", "parameterName": "Maximum vertical disparity", "dataType": "Int", "explanation": ["Maximum vertical disparity to explore (can be negative)."]}, {"flag": "bm.subpixel", "parameterName": "Sub-pixel interpolation", "dataType": "Choices", "availableChoices": [{"choice": "none", "description": ["No initial disparity used."]}, {"choice": "parabolic", "description": ["The metric values closest to the best match are used in order to fit a parabola to the local extremum of the metric surface. The peak position of this parabola is output."]}, {"choice": "triangular", "description": ["The metric values closest to the best match are used in order to fit a triangular peak to the local extremum of the metric surface. The peak position of this triangle is output."]}, {"choice": "dichotomy", "description": ["An iterative dichotomic search is performed to find the best sub-pixel position. The window in the right image is resampled at sub-pixel positions to estimate the match."]}], "explanation": ["Estimate disparities with sub-pixel precision. Available choices are:"]}, {"flag": "bm.step", "parameterName": "Computation step", "dataType": "Int", "explanation": ["Location step between computed disparities. Disparities will be computed every \u2018step\u2019 pixels in the left image (step for both rows and columns). For instance, a value of 1 corresponds to the classic dense disparity map."]}, {"flag": "bm.startx", "parameterName": "X start index", "dataType": "Int", "explanation": ["X start index of the subsampled grid (wrt the input image grid). See parameter bm.step."]}, {"flag": "bm.starty", "parameterName": "Y start index", "dataType": "Int", "explanation": ["Y start index of the subsampled grid (wrt the input image grid). See parameter bm.step."]}, {"flag": "bm.medianfilter.radius", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius (in pixels) for median filter."]}, {"flag": "bm.medianfilter.incoherence", "parameterName": "Incoherence threshold", "dataType": "Float", "explanation": ["Incoherence threshold between original and filtered disparity."]}, {"flag": "bm.initdisp", "parameterName": "Initial disparities", "dataType": "Choices", "availableChoices": [{"choice": "none", "description": ["No initial disparity used."]}, {"choice": "uniform", "description": ["Use an uniform initial disparity estimate."]}, {"choice": "maps", "description": ["Use initial disparity maps to define the exploration area. This area in the right image is centered on the current position shifted by the initial disparity estimate, and has a given exploration radius in horizontal and vertical directions."]}], "explanation": [" Available choices are:"]}, {"flag": "bm.initdisp.uniform.hdisp", "parameterName": "Horizontal initial disparity", "dataType": "Int", "explanation": ["Value of the uniform horizontal disparity initial estimate (in pixels)."]}, {"flag": "bm.initdisp.uniform.vdisp", "parameterName": "Vertical initial disparity", "dataType": "Int", "explanation": ["Value of the uniform vertical disparity initial estimate (in pixels)."]}, {"flag": "bm.initdisp.uniform.hrad", "parameterName": "Horizontal exploration radius", "dataType": "Int", "explanation": ["Horizontal exploration radius around the initial disparity estimate (in pixels)."]}, {"flag": "bm.initdisp.uniform.vrad", "parameterName": "Vertical exploration radius", "dataType": "Int", "explanation": ["Vertical exploration radius around the initial disparity estimate (in pixels)."]}, {"flag": "bm.initdisp.maps.hrad", "parameterName": "Horizontal exploration radius", "dataType": "Int", "explanation": ["Horizontal exploration radius around the initial disparity estimate (in pixels)."]}, {"flag": "bm.initdisp.maps.vrad", "parameterName": "Vertical exploration radius", "dataType": "Int", "explanation": ["Vertical exploration radius around the initial disparity estimate (in pixels)."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application allows one to performs block-matching to estimate pixel-wise disparities for a pair of images in epipolar geometry. \n This application is part of the stereovision pipeline. It can be used after having computed epipolar grids (with StereoRectificationGridGenerator) and resampled each input image into epipolar geometry (with GridBasedImageResampling). \n \n The application searches locally for the displacement between a reference image and a secondary image. The correspondence is evaluated for each pixel, based on a pair of local neighborhood windows. The displacement evaluated can be 1D (along lines) or 2D. Parameters allow setting the minimum and maximum disparities to search (both for horizontal and vertical directions). A winner-take-all approach is used to select the best match. There are different metrics implemented to evaluate the match between two local windows: \n \n SSD : Sum of Squared Distances \n NCC : Normalized Cross-Correlation \n Lp  : Lp pseudo norm \n \n \n \n Once the best integer disparity is found, an optional step of sub-pixel disparity estimation can be performed, with various algorithms (triangular interpolation, parabollic interpolation, dichotimic search). As post-processing, there is an optional step of median filtering on the disparities. One can chose input masks (related to the left and right input image) of pixels for which the disparity should be investigated. Additionally, two criteria can be optionally used to disable disparity investigation for some pixel: a no-data value, and a threshold on the local variance. This allows one to speed-up computation by avoiding to investigate disparities that will not be reliable anyway. For efficiency reasons, if the image of optimal metric values is desired, it will be concatenated to the output image (which will then have three bands : horizontal disparity, vertical disparity and metric value). One can split these images afterward. \n"},
{"name": "SFSTextureExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_SFSTextureExtraction.html", "label": "SFS Texture Extraction", "category": "Feature Extraction", "definition": "Computes Structural Feature Set textures on every pixel of the input image selected channel", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_SFSTextureExtraction - in qb_RoadExtract . tif - channel 1 - parameters . spethre 50.0 - parameters . spathre 100 - out SFSTextures . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the SFSTextureExtraction application SFSTextureExtraction = otbApplication . Registry . CreateApplication ( \"SFSTextureExtraction\" ) # The following lines set all the application parameters: SFSTextureExtraction . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) SFSTextureExtraction . SetParameterInt ( \"channel\" , 1 ) SFSTextureExtraction . SetParameterFloat ( \"parameters.spethre\" , 50.0 ) SFSTextureExtraction . SetParameterInt ( \"parameters.spathre\" , 100 ) SFSTextureExtraction . SetParameterString ( \"out\" , \"SFSTextures.tif\" ) # The following line execute the application SFSTextureExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_SFSTextureExtraction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Feature Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "parameters.spethre", "parameterName": "Spectral Threshold", "dataType": "Float", "explanation": ["Spectral Threshold."]}, {"flag": "parameters.spathre", "parameterName": "Spatial Threshold", "dataType": "Int", "explanation": ["Spatial Threshold."]}, {"flag": "parameters.nbdir", "parameterName": "Number of Direction", "dataType": "Int", "explanation": ["Number of Direction."]}, {"flag": "parameters.alpha", "parameterName": "Alpha", "dataType": "Float", "explanation": ["Alpha."]}, {"flag": "parameters.maxcons", "parameterName": "Ratio Maximum Consideration Number", "dataType": "Int", "explanation": ["Ratio Maximum Consideration Number."]}], "description": "\n   \n Structural Feature Set [1] are based on the histograms of the pixels in multiple directions of the image. The SFSTextureExtraction application computes the  6 following features: SFS\u2019Length, SFS\u2019Width, SFS\u2019PSI, SFS\u2019W-Mean, SFS\u2019Ratio and SFS\u2019SD (Standard Deviation). The texture indices are computed from the neighborhood of each pixel. It is possible to change the length of the calculation line (spatial threshold), as well as the maximum difference between a pixel of the line and the pixel at the center of the neighborhood (spectral threshold) [2]. \n"},
{"name": "VectorDataDSValidation", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_VectorDataDSValidation.html", "label": "Vector Data validation", "category": "Feature Extraction", "definition": "Vector data validation based on the fusion of features using Dempster-Shafer evidence theory framework.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_VectorDataDSValidation - in cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt . shp - belsup cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt . shp - descmod DSFuzzyModel . xml - out VectorDataDSValidation . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the VectorDataDSValidation application VectorDataDSValidation = otbApplication . Registry . CreateApplication ( \"VectorDataDSValidation\" ) # The following lines set all the application parameters: VectorDataDSValidation . SetParameterString ( \"in\" , \"cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt.shp\" ) VectorDataDSValidation . SetParameterStringList ( \"belsup\" , [ 'cdbTvComputePolylineFeatureFromImage_LI_NOBUIL_gt.shp' ]) VectorDataDSValidation . SetParameterString ( \"descmod\" , \"DSFuzzyModel.xml\" ) VectorDataDSValidation . SetParameterString ( \"out\" , \"VectorDataDSValidation.shp\" ) # The following line execute the application VectorDataDSValidation . ExecuteAndWriteOutput ()"], "command": "otbcli_VectorDataDSValidation", "parameters": [{"flag": "in", "parameterName": "Input Vector Data", "dataType": "Input vector data", "explanation": ["Input vector data to validate."], "isInputFile": true}, {"flag": "descmod", "parameterName": "Descriptors model filename", "dataType": "Input File name", "explanation": ["Fuzzy descriptors model (xml file)."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Vector Data", "dataType": "Output vector data", "explanation": ["Output VectorData containing only the validated samples."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "belsup", "parameterName": "Belief Support", "dataType": "String list", "explanation": ["Dempster Shafer study hypothesis to compute belief."]}, {"flag": "plasup", "parameterName": "Plausibility Support", "dataType": "String list", "explanation": ["Dempster Shafer study hypothesis to compute plausibility."]}, {"flag": "cri", "parameterName": "Criterion", "dataType": "String", "explanation": ["Dempster Shafer criterion (by default (belief+plausibility)/2)."]}, {"flag": "thd", "parameterName": "Criterion threshold", "dataType": "Float", "explanation": ["Criterion threshold (default 0.5)."]}], "description": "\n   \n This application validates or unvalidate the studied samples using the Dempster-Shafer theory. \n"},
{"name": "RadiometricIndices", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_RadiometricIndices.html", "label": "Radiometric Indices", "category": "Feature Extraction", "definition": "Compute radiometric indices.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_RadiometricIndices - in qb_RoadExtract . tif - list Vegetation : NDVI Vegetation : RVI Vegetation : IPVI - out RadiometricIndicesImage . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the RadiometricIndices application RadiometricIndices = otbApplication . Registry . CreateApplication ( \"RadiometricIndices\" ) # The following lines set all the application parameters: RadiometricIndices . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) # The following line execute the application RadiometricIndices . ExecuteAndWriteOutput ()"], "command": "otbcli_RadiometricIndices", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "channels.blue", "parameterName": "Blue Channel", "dataType": "Int", "explanation": ["Blue channel index."]}, {"flag": "channels.green", "parameterName": "Green Channel", "dataType": "Int", "explanation": ["Green channel index."]}, {"flag": "channels.red", "parameterName": "Red Channel", "dataType": "Int", "explanation": ["Red channel index."]}, {"flag": "channels.nir", "parameterName": "NIR Channel", "dataType": "Int", "explanation": ["NIR channel index."]}, {"flag": "channels.mir", "parameterName": "Mir Channel", "dataType": "Int", "explanation": ["Mir channel index."]}, {"flag": "list", "parameterName": "Available Radiometric Indices", "dataType": "List", "explanation": []}], "description": "\n   \n This application computes radiometric indices using the relevant channels of the input image. The output is a multi band image into which each channel is one of the selected indices. \n"},
{"name": "MorphologicalProfilesAnalysis", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MorphologicalProfilesAnalysis.html", "label": "Morphological Profiles Analysis", "category": "Feature Extraction", "definition": "Performs morphological profiles analysis on an input image channel.", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MorphologicalProfilesAnalysis - in ROI_IKO_PAN_LesHalles . tif - channel 1 - structype ball - profile classification - size 5 - radius 1 - step 1 - profile . classification . sigma 1 - out output . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MorphologicalProfilesAnalysis application MorphologicalProfilesAnalysis = otbApplication . Registry . CreateApplication ( \"MorphologicalProfilesAnalysis\" ) # The following lines set all the application parameters: MorphologicalProfilesAnalysis . SetParameterString ( \"in\" , \"ROI_IKO_PAN_LesHalles.tif\" ) MorphologicalProfilesAnalysis . SetParameterInt ( \"channel\" , 1 ) MorphologicalProfilesAnalysis . SetParameterString ( \"structype\" , \"ball\" ) MorphologicalProfilesAnalysis . SetParameterString ( \"profile\" , \"classification\" ) MorphologicalProfilesAnalysis . SetParameterInt ( \"size\" , 5 ) MorphologicalProfilesAnalysis . SetParameterInt ( \"radius\" , 1 ) MorphologicalProfilesAnalysis . SetParameterInt ( \"step\" , 1 ) MorphologicalProfilesAnalysis . SetParameterFloat ( \"profile.classification.sigma\" , 1 ) MorphologicalProfilesAnalysis . SetParameterString ( \"out\" , \"output.tif\" ) # The following line execute the application MorphologicalProfilesAnalysis . ExecuteAndWriteOutput ()"], "command": "otbcli_MorphologicalProfilesAnalysis", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}, {"flag": "structype", "parameterName": "Structuring Element Type", "dataType": "Choices", "availableChoices": [{"choice": "ball", "description": []}, {"choice": "cross", "description": []}], "explanation": []}, {"flag": "size", "parameterName": "Profile Size", "dataType": "Int", "explanation": []}, {"flag": "radius", "parameterName": "Initial radius", "dataType": "Int", "explanation": []}, {"flag": "step", "parameterName": "Radius step.", "dataType": "Int", "explanation": []}, {"flag": "profile", "parameterName": "Profile", "dataType": "Choices", "availableChoices": [{"choice": "opening", "description": []}, {"choice": "closing", "description": []}, {"choice": "derivativeopening", "description": []}, {"choice": "derivativeclosing", "description": []}, {"choice": "openingcharacteristics", "description": []}, {"choice": "closingcharacteristics", "description": []}, {"choice": "classification", "description": []}], "explanation": []}, {"flag": "profile.classification.sigma", "parameterName": "Sigma value for leveling tolerance", "dataType": "Float", "explanation": ["Sigma value for leveling tolerance."]}], "description": "\n   \n This algorithm is derived from the following publication: \n Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach\nfor the morphological segmentation of high resolution satellite imagery.\nIEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2,\nFebruary 2001, p. 309-320. \n Depending of the profile selection, the application provides: \n -   The   multi   scale   geodesic   morphological   opening   or   closing   profile   of   the   input   image . \n -   The   multi   scale   derivative   of   the   opening   or   closing   profile . \n -   The   parameter   ( called   characteristic )   of   the   maximum   derivative   value   of   the   multi   scale   closing   or   opening   profile   for   which   this   maxima   occurs . \n -   The   labeled   classification   of   the   input   image . \n \n \n The behavior of the classification is : \n Given   and   two membership values,\n  two labels associated, and   a tolerance\nvalue, the following decision rule is applied: \n \n The output image can be :- A   multi band image for the opening/closing normal or derivative profiles.\n- A mono band image for the opening/closing characteristics.\n- A labeled image for the classification. \n"},
{"name": "MorphologicalMultiScaleDecomposition", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MorphologicalMultiScaleDecomposition.html", "label": "Morphological Multi Scale Decomposition", "category": "Feature Extraction", "definition": "Perform a geodesic morphology based image analysis on an input image channel", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MorphologicalMultiScaleDecomposition - in ROI_IKO_PAN_LesHalles . tif - structype ball - channel 1 - radius 2 - levels 2 - step 3 - outconvex convex . tif - outconcave concave . tif - outleveling leveling . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MorphologicalMultiScaleDecomposition application MorphologicalMultiScaleDecomposition = otbApplication . Registry . CreateApplication ( \"MorphologicalMultiScaleDecomposition\" ) # The following lines set all the application parameters: MorphologicalMultiScaleDecomposition . SetParameterString ( \"in\" , \"ROI_IKO_PAN_LesHalles.tif\" ) MorphologicalMultiScaleDecomposition . SetParameterString ( \"structype\" , \"ball\" ) MorphologicalMultiScaleDecomposition . SetParameterInt ( \"channel\" , 1 ) MorphologicalMultiScaleDecomposition . SetParameterInt ( \"radius\" , 2 ) MorphologicalMultiScaleDecomposition . SetParameterInt ( \"levels\" , 2 ) MorphologicalMultiScaleDecomposition . SetParameterInt ( \"step\" , 3 ) MorphologicalMultiScaleDecomposition . SetParameterString ( \"outconvex\" , \"convex.tif\" ) MorphologicalMultiScaleDecomposition . SetParameterString ( \"outconcave\" , \"concave.tif\" ) MorphologicalMultiScaleDecomposition . SetParameterString ( \"outleveling\" , \"leveling.tif\" ) # The following line execute the application MorphologicalMultiScaleDecomposition . ExecuteAndWriteOutput ()"], "command": "otbcli_MorphologicalMultiScaleDecomposition", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to be classified."], "isInputFile": true}, {"flag": "outconvex", "parameterName": "Output Convex Image", "dataType": "Output image", "explanation": ["The output convex image with N bands."], "isOutputFile": true}, {"flag": "outconcave", "parameterName": "Output Concave Image", "dataType": "Output image", "explanation": ["The output concave concave with N bands."], "isOutputFile": true}, {"flag": "outleveling", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output leveling image with N bands."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": ["The selected channel index for input image."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "structype", "parameterName": "Structuring Element Type", "dataType": "Choices", "availableChoices": [{"choice": "ball", "description": []}, {"choice": "cross", "description": []}], "explanation": ["Choice of the structuring element type. Available choices are:"]}, {"flag": "radius", "parameterName": "Initial radius", "dataType": "Int", "explanation": ["Initial radius of the structuring element (in pixels)."]}, {"flag": "step", "parameterName": "Radius step.", "dataType": "Int", "explanation": ["Radius step along the profile (in pixels)."]}, {"flag": "levels", "parameterName": "Number of levels use for multi scale", "dataType": "Int", "explanation": ["Number of levels use for multi scale."]}], "description": "\n   \n This application recursively apply geodesic decomposition. \n This algorithm is derived from the following publication: \n Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach for the morphological segmentation of high resolution satellite imagery.\nIEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2, February 2001, p. 309-320. \n It provides a geodesic decomposition of the input image, with the following scheme. Let   denote the input image,   denote the convex membership function,   denote the concave membership function and   denote the leveling function, for a given radius   as defined in the documentation\nof the GeodesicMorphologyDecompositionImageFilter. Let   denote a range of increasing radius (or scales). The iterative decomposition is defined as follows: \n  =  \n  =  \n  =  \n The   and   are membership function for the convex\n(resp. concave) objects whose size is comprised between   and  \n Output convex, concave and leveling images with B bands, where n is the number of levels. \n"},
{"name": "MorphologicalClassification", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_MorphologicalClassification.html", "label": "Morphological Classification", "category": "Feature Extraction", "definition": "Performs morphological convex, concave and flat classification on an input image channel", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_MorphologicalClassification - in ROI_IKO_PAN_LesHalles . tif - channel 1 - structype ball - radius 5 - sigma 0.5 - out output . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the MorphologicalClassification application MorphologicalClassification = otbApplication . Registry . CreateApplication ( \"MorphologicalClassification\" ) # The following lines set all the application parameters: MorphologicalClassification . SetParameterString ( \"in\" , \"ROI_IKO_PAN_LesHalles.tif\" ) MorphologicalClassification . SetParameterInt ( \"channel\" , 1 ) MorphologicalClassification . SetParameterString ( \"structype\" , \"ball\" ) MorphologicalClassification . SetParameterInt ( \"radius\" , 5 ) MorphologicalClassification . SetParameterFloat ( \"sigma\" , 0.5 ) MorphologicalClassification . SetParameterString ( \"out\" , \"output.tif\" ) # The following line execute the application MorphologicalClassification . ExecuteAndWriteOutput ()"], "command": "otbcli_MorphologicalClassification", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to be classified."], "isInputFile": true}, {"flag": "out", "parameterName": "Output Image", "dataType": "Output image", "explanation": ["The output classified image with 3 different values (0 : Flat, 1 : Convex, 2 : Concave)."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": ["The selected channel index for input image."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "structype", "parameterName": "Structuring Element Type", "dataType": "Choices", "availableChoices": [{"choice": "ball", "description": []}, {"choice": "cross", "description": []}], "explanation": ["Choice of the structuring element type. Available choices are:"]}, {"flag": "radius", "parameterName": "Radius", "dataType": "Int", "explanation": ["Radius of the structuring element (in pixels), default value is 5."]}, {"flag": "sigma", "parameterName": "Sigma value for leveling tolerance", "dataType": "Float", "explanation": ["Sigma value for leveling tolerance, default value is 0.5."]}], "description": "\n   \n This algorithm is based on the following publication:\nMartino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach for the morphological segmentation of high resolution satellite imagery.\nIEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2, February 2001, p. 309-320. \n This application perform the following decision rule to classify a pixel between the three classes Convex, Concave and Flat. Let   denote the input image and   the geodesic leveling of   with a structuring element of size  . One can derive the following decision rule to classify   into Convex (label  ), Concave (label  ) and Flat (label  ):\n \n The output is a labeled image (0 : Flat, 1 : Convex, 2 : Concave) \n"},
{"name": "LocalStatisticExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LocalStatisticExtraction.html", "label": "Local Statistic Extraction", "category": "Feature Extraction", "definition": "Computes local statistical moments on every pixel in the selected channel of the input image", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_LocalStatisticExtraction - in qb_RoadExtract . tif - channel 1 - radius 3 - out Statistics . tif", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LocalStatisticExtraction application LocalStatisticExtraction = otbApplication . Registry . CreateApplication ( \"LocalStatisticExtraction\" ) # The following lines set all the application parameters: LocalStatisticExtraction . SetParameterString ( \"in\" , \"qb_RoadExtract.tif\" ) LocalStatisticExtraction . SetParameterInt ( \"channel\" , 1 ) LocalStatisticExtraction . SetParameterInt ( \"radius\" , 3 ) LocalStatisticExtraction . SetParameterString ( \"out\" , \"Statistics.tif\" ) # The following line execute the application LocalStatisticExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_LocalStatisticExtraction", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": ["The input image to compute the features on."], "isInputFile": true}, {"flag": "out", "parameterName": "Feature Output Image", "dataType": "Output image", "explanation": ["Output image containing the local statistical moments."], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": ["Load otb application from xml file."], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": ["Save otb application to xml file."], "isOutputFile": true}], "options": [{"flag": "channel", "parameterName": "Selected Channel", "dataType": "Int", "explanation": ["The selected channel index."]}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": ["Available memory for processing (in MB)."]}, {"flag": "radius", "parameterName": "Neighborhood radius", "dataType": "Int", "explanation": ["The computational window radius."]}], "description": "\n   \n This application computes the 4 local statistical moments on every pixel in the selected channel of the input image, over a specified neighborhood. The output image is multi band with one statistical moment (feature) per band. Thus, the 4 output features are the Mean, the Variance, the Skewness and the Kurtosis. They are provided in this exact order in the output image. \n"},
{"name": "LineSegmentDetection", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_LineSegmentDetection.html", "label": "Line segment detection", "category": "Feature Extraction", "definition": "Detect line segments in raster", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_LineSegmentDetection - in QB_Suburb . png - out LineSegmentDetection . shp", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the LineSegmentDetection application LineSegmentDetection = otbApplication . Registry . CreateApplication ( \"LineSegmentDetection\" ) # The following lines set all the application parameters: LineSegmentDetection . SetParameterString ( \"in\" , \"QB_Suburb.png\" ) LineSegmentDetection . SetParameterString ( \"out\" , \"LineSegmentDetection.shp\" ) # The following line execute the application LineSegmentDetection . ExecuteAndWriteOutput ()"], "command": "otbcli_LineSegmentDetection", "parameters": [{"flag": "in", "parameterName": "Input Image", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "out", "parameterName": "Output Detected lines", "dataType": "Output vector data", "explanation": [], "isOutputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}, {"flag": "norescale", "parameterName": "No rescaling in [0, 255]", "dataType": "Boolean", "explanation": []}, {"flag": "ram", "parameterName": "Available RAM (Mb)", "dataType": "Int", "explanation": []}], "description": "\n   \n This application detects locally straight contours in a image. It is based on Burns, Hanson, and Riseman method and use an a contrario validation approach (Desolneux, Moisan, and Morel). The algorithm was published by Rafael Gromponevon Gioi, J\u00e9r\u00e9mie Jakubowicz, Jean-Michel Morel and Gregory Randall. The given approach computes gradient and level lines of the image and detects aligned points in line support region. The application allows exporting the detected lines in a vector data. \n"},
{"name": "HomologousPointsExtraction", "manual_url": "https://www.orfeo-toolbox.org/CookBook/Applications/app_HomologousPointsExtraction.html", "label": "Homologous Points Extraction", "category": "Feature Extraction", "definition": "Compute homologous points between images using keypoints", "authors": "This application has been written by OTB-Team.", "limitations": null, "example": ["otbcli_HomologousPointsExtraction - in1 sensor_stereo_left . tif - in2 sensor_stereo_right . tif - mode full - out homologous . txt", "#!/usr/bin/python # Import the otb applications package import otbApplication # The following line creates an instance of the HomologousPointsExtraction application HomologousPointsExtraction = otbApplication . Registry . CreateApplication ( \"HomologousPointsExtraction\" ) # The following lines set all the application parameters: HomologousPointsExtraction . SetParameterString ( \"in1\" , \"sensor_stereo_left.tif\" ) HomologousPointsExtraction . SetParameterString ( \"in2\" , \"sensor_stereo_right.tif\" ) HomologousPointsExtraction . SetParameterString ( \"mode\" , \"full\" ) HomologousPointsExtraction . SetParameterString ( \"out\" , \"homologous.txt\" ) # The following line execute the application HomologousPointsExtraction . ExecuteAndWriteOutput ()"], "command": "otbcli_HomologousPointsExtraction", "parameters": [{"flag": "in1", "parameterName": "Input Image 1", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "in2", "parameterName": "Input Image 2", "dataType": "Input image", "explanation": [], "isInputFile": true}, {"flag": "elev.geoid", "parameterName": "Geoid File", "dataType": "Input File name", "explanation": ["Use a geoid grid to get the height above the ellipsoid in case there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles. A version of the geoid can be found on the OTB website("], "isInputFile": true}, {"flag": "out", "parameterName": "Output file with tie points", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "outvector", "parameterName": "Output vector file with tie points", "dataType": "Output File name", "explanation": [], "isOutputFile": true}, {"flag": "inxml", "parameterName": "Load otb application from xml file", "dataType": "XML input parameters file", "explanation": [], "isInputFile": true}, {"flag": "outxml", "parameterName": "Save otb application to xml file", "dataType": "XML output parameters file", "explanation": [], "isOutputFile": true}], "options": [{"flag": "band1", "parameterName": "Input band 1", "dataType": "Int", "explanation": []}, {"flag": "band2", "parameterName": "Input band 2", "dataType": "Int", "explanation": []}, {"flag": "algorithm", "parameterName": "Keypoints detection algorithm", "dataType": "Choices", "availableChoices": [{"choice": "surf", "description": []}, {"choice": "sift", "description": []}], "explanation": []}, {"flag": "threshold", "parameterName": "Distance threshold for matching", "dataType": "Float", "explanation": []}, {"flag": "backmatching", "parameterName": "Use back-matching to filter matches.", "dataType": "Boolean", "explanation": []}, {"flag": "mode", "parameterName": "Keypoints search mode", "dataType": "Choices", "availableChoices": [{"choice": "full", "description": ["Extract and match all keypoints, loading both images entirely into memory."]}, {"choice": "geobins", "description": ["This method allows retrieving a set of tie points regulary spread across image 1. Corresponding bins in image 2 are retrieved using sensor and geographical information if available. The first bin position takes into account the margin parameter. Bins are cropped to the largest image region shrunk by the margin parameter for both in1 and in2 images."]}], "explanation": []}, {"flag": "mode.geobins.binsize", "parameterName": "Size of bin", "dataType": "Int", "explanation": ["Radius of the spatial bin in pixels."]}, {"flag": "mode.geobins.binsizey", "parameterName": "Size of bin (y direction)", "dataType": "Int", "explanation": ["Radius of the spatial bin in pixels (y direction). If not set, the mode.geobins.binsize value is used."]}, {"flag": "mode.geobins.binstep", "parameterName": "Steps between bins", "dataType": "Int", "explanation": ["Steps between bins in pixels."]}, {"flag": "mode.geobins.binstepy", "parameterName": "Steps between bins (y direction)", "dataType": "Int", "explanation": ["Steps between bins in pixels (y direction). If not set, the mode.geobins.binstep value is used."]}, {"flag": "mode.geobins.margin", "parameterName": "Margin from image border to start/end bins (in pixels)", "dataType": "Int", "explanation": ["Margin from image border to start/end bins (in pixels)."]}, {"flag": "precision", "parameterName": "Estimated precision of the colocalisation function (in pixels).", "dataType": "Float", "explanation": []}, {"flag": "mfilter", "parameterName": "Filter points according to geographical or sensor based colocalisation", "dataType": "Boolean", "explanation": []}, {"flag": "2wgs84", "parameterName": "If enabled, points from second image will be exported in WGS84", "dataType": "Boolean", "explanation": []}, {"flag": "elev.dem", "parameterName": "DEM directory", "dataType": "Directory", "explanation": ["This parameter allows selecting a directory containing Digital Elevation Model files. Note that this directory should contain only DEM files. Unexpected behaviour might occurs if other images are found in this directory."]}, {"flag": "elev.default", "parameterName": "Default elevation", "dataType": "Float", "explanation": ["This parameter allows setting the default height above ellipsoid when there is no DEM available, no coverage for some points or pixels with no_data in the DEM tiles, and no geoid file has been set. This is also used by some application as an average elevation value."]}], "description": "\n   \n This application allows computing homologous points between images using keypoints.  SIFT or SURF keypoints can be used and the band on which keypoints are computed can be set independently for both images. The application offers two modes : the first is the full mode where keypoints are extracted from the full extent of both images (please note that in this mode large image file are not supported). The second mode, called geobins, allows one to set-up spatial binning to get fewer points spread across the entire image. In this mode, the corresponding spatial bin in the second image is estimated using geographical transform or sensor modelling, and is padded according to the user defined precision. Last, in both modes the application can filter matches whose colocalisation in first image exceed this precision. The elevation parameters are to deal more precisely with sensor modelling in case of sensor geometry data. The outvector option allows creating a vector file with segments corresponding to the localisation error between the matches. It can be useful to assess the precision of a registration for instance. The vector file is always reprojected to EPSG:4326 to allow display in a GIS. This is done via reprojection or by applying the image sensor models. \n"}
]